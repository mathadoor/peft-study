{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e45fd35-cdca-44b8-a00f-607078ee1a67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Investigating Ranks\n",
    "In the first section, I am going to investigate what an appropriate rank to consider should be. It will make sense to look at the \n",
    "ranks of a trained matrix and a randomly initialized matrix. We will start by looking at a randomly initialized matrix and then\n",
    "look at a trained matrix. Specifically, I will look at the rank of a randomly initialized matrix. I will need to consider the sizes \n",
    "that are seen in RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1397017-4851-477f-a432-2a934510e545",
   "metadata": {},
   "source": [
    "## Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2172b3-4630-4fed-8bfd-4cf8b3ea7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Appropriate Libraries\n",
    "%load_ext autoreload\n",
    "    \n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "import bisect\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# Set Logging Level\n",
    "import logging\n",
    "level = logging.DEBUG\n",
    "logging.getLogger(\"requests\").setLevel(level)\n",
    "logging.getLogger(\"urllib3\").setLevel(level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25dba68b-c775-4672-8fbf-f2bb3da6f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_principle_direction(A, exp_var):\n",
    "    U, S, V = torch.linalg.svd(A)\n",
    "    X = (torch.cumsum(S, 0) / S.sum().item()).tolist()\n",
    "    num = bisect.bisect(X, exp_var)\n",
    "    return num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35846b95-4743-425e-a2bd-ac1db674217a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Normally Initialized Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4005e5-d964-4def-94f1-41d18030aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(n=100, size=[768, 768], exp_var=0.99):\n",
    "    results = []\n",
    "    for _ in range(n):\n",
    "        A = torch.randn(size)\n",
    "        num = get_principle_direction(A, exp_var)\n",
    "        results.append(num)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86b27c30-3205-4635-b424-9e5e80078d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([51.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 49.]),\n",
       " array([515. , 515.1, 515.2, 515.3, 515.4, 515.5, 515.6, 515.7, 515.8,\n",
       "        515.9, 516. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 3))\n",
    "ax[0].hist(plot_results())\n",
    "ax[1].hist(plot_results(exp_var=0.95))\n",
    "ax[2].hist(plot_results(exp_var=0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601559f6-0a40-40bb-830e-a836a35c5a5b",
   "metadata": {},
   "source": [
    "The above results indicate the rank is very tightly distributed based on the explained variance. The reader is encouraged to play with the explained_variance and support the claim themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41538748-3d56-4a69-a5f6-aa4f2e98f146",
   "metadata": {},
   "source": [
    "## Analysis of RoBERTa pre-trained Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "373c7b6d-5ccd-447e-b545-7349e19e7e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Now let's look at how tightly the weights are distributed in RoBERTa \n",
    "from transformers import AutoModel, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a18bc9a7-0c31-41be-970e-e37992303f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract RoBERTa Configuration\n",
    "roberta_base_config = AutoConfig.from_pretrained('roberta-base')\n",
    "roberta_large_config = AutoConfig.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acf40d4d-e557-4b8c-a6ec-fe8725910263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract RoBERTa Model\n",
    "roberta_base_model = AutoModel.from_config(roberta_base_config)\n",
    "roberta_large_model = AutoModel.from_config(roberta_large_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dd7956d-48ca-4f5f-96e1-72ca43118c2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_principle_direction(model, exp_var):\n",
    "    for key, param in model.named_parameters():\n",
    "        with torch.no_grad():\n",
    "            key = \".\".join(key.split(\".\")[3:])\n",
    "            p_size = min(param.size())\n",
    "            if len(param.size()) < 2:\n",
    "                continue\n",
    "            print(key, get_principle_direction(param, exp_var), p_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6379350c-f84f-41e2-bd2e-da56058431bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Roberta Base Principle Directions \n",
      "\n",
      " 759 768\n",
      " 492 514\n",
      " 0 1\n",
      "attention.self.query.weight 687 768\n",
      "attention.self.key.weight 687 768\n",
      "attention.self.value.weight 687 768\n",
      "attention.output.dense.weight 687 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 688 768\n",
      "attention.self.key.weight 687 768\n",
      "attention.self.value.weight 687 768\n",
      "attention.output.dense.weight 688 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 688 768\n",
      "attention.self.key.weight 688 768\n",
      "attention.self.value.weight 687 768\n",
      "attention.output.dense.weight 688 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 688 768\n",
      "attention.self.key.weight 688 768\n",
      "attention.self.value.weight 687 768\n",
      "attention.output.dense.weight 687 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 687 768\n",
      "attention.self.key.weight 688 768\n",
      "attention.self.value.weight 687 768\n",
      "attention.output.dense.weight 687 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 687 768\n",
      "attention.self.key.weight 687 768\n",
      "attention.self.value.weight 687 768\n",
      "attention.output.dense.weight 688 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 688 768\n",
      "attention.self.key.weight 687 768\n",
      "attention.self.value.weight 688 768\n",
      "attention.output.dense.weight 688 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 687 768\n",
      "attention.self.key.weight 687 768\n",
      "attention.self.value.weight 688 768\n",
      "attention.output.dense.weight 688 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 687 768\n",
      "attention.self.key.weight 687 768\n",
      "attention.self.value.weight 688 768\n",
      "attention.output.dense.weight 687 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 687 768\n",
      "attention.self.key.weight 688 768\n",
      "attention.self.value.weight 688 768\n",
      "attention.output.dense.weight 688 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 687 768\n",
      "attention.self.key.weight 688 768\n",
      "attention.self.value.weight 688 768\n",
      "attention.output.dense.weight 687 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 688 768\n",
      "attention.self.key.weight 687 768\n",
      "attention.self.value.weight 688 768\n",
      "attention.output.dense.weight 688 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      " 688 768\n",
      "\n",
      "# Roberta Large Principle Directions \n",
      "\n",
      " 1012 1024\n",
      " 498 514\n",
      " 0 1\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 916 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 916 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 916 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 916 1024\n",
      "attention.output.dense.weight 916 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 916 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 918 1024\n",
      "attention.output.dense.weight 916 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1004 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 916 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 916 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 916 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 916 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 916 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 916 1024\n",
      "attention.output.dense.weight 916 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 918 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 916 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 916 1024\n",
      "attention.self.key.weight 916 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 916 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 916 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 918 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 916 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      " 917 1024\n"
     ]
    }
   ],
   "source": [
    "explained_variance = 0.99\n",
    "print(\"# Roberta Base Principle Directions \\n\")\n",
    "print_principle_direction(roberta_base_model, explained_variance)\n",
    "\n",
    "print(\"\\n# Roberta Large Principle Directions \\n\")\n",
    "print_principle_direction(roberta_large_model, explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a39e3e-2c84-458e-a47f-5e5a86443278",
   "metadata": {},
   "source": [
    "On the surface, the above results suggest you need most of the directions to account for the explained variance in the parameters.\n",
    "As such, we finetune the models for SQuAD and review the difference in the weights of the base and the tuned model. If the difference has \n",
    "fewer principle directions with high explanation, it would mean it is possible the task-based fine-tuning can be done in a smaller subspace. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a1ff52-126c-4665-92fd-c3e5d8c83fb2",
   "metadata": {},
   "source": [
    "## Rank Variation During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d59c3413-b156-4dfd-a1f5-1df488ff818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dataset\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from train.train import train_epoch\n",
    "from utils.metrics import AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "719ff899-edf9-4f7e-b665-ea440ef6bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Training Configuration\n",
    "with hydra.initialize(version_base=None, config_path=\"../config\"):\n",
    "    cfg = hydra.compose(config_name=\"app_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4b82e45-bb22-4aea-b6ac-1c2ef67ab9d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"squad\", split=\"train\")\n",
    "val_dataset = load_dataset(\"squad\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a7bcbd0-1ab7-48b6-b890-79dddf7abbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Training Artifacts\n",
    "training_cfg = hydra.utils.instantiate(cfg.model.model.train)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=training_cfg.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=training_cfg.batch_size)\n",
    "\n",
    "model = roberta_base\n",
    "optimizer = AdamW(params=model.parameters(), lr=training_cfg.lr, weight_decay=training_cfg.weight_decay)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "loss_meter = AverageMeter()\n",
    "acc_meter = AverageMeter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e781f4c5-9bf2-4b92-a0be-184d54fc97aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'title', 'context', 'question', 'answers'])\n",
      "['What was the purpose of the fruit walls built by French and English farmers?', 'What happened which ended in two puppet states dissolving and Soviet withdrawal out of Iran after WWII?', 'Where can Adobe Flash now be used?', 'What two-letter abbreviation is used for undergraduate engineering  courses?', 'For what did the college pay a substancial sum and donate 4.5 hectres of land?', 'What kind of linguistic choices does Catalan have?', 'Who led the Civil Rights movement?', 'How many households were the offices of Qianhu in charge of?']\n",
      "['Agriculture and horticulture seek to optimize the capture of solar energy in order to optimize the productivity of plants. Techniques such as timed planting cycles, tailored row orientation, staggered heights between rows and the mixing of plant varieties can improve crop yields. While sunlight is generally considered a plentiful resource, the exceptions highlight the importance of solar energy to agriculture. During the short growing seasons of the Little Ice Age, French and English farmers employed fruit walls to maximize the collection of solar energy. These walls acted as thermal masses and accelerated ripening by keeping plants warm. Early fruit walls were built perpendicular to the ground and facing south, but over time, sloping walls were developed to make better use of sunlight. In 1699, Nicolas Fatio de Duillier even suggested using a tracking mechanism which could pivot to follow the Sun. Applications of solar energy in agriculture aside from growing crops include pumping water, drying crops, brooding chicks and drying chicken manure. More recently the technology has been embraced by vinters, who use the energy generated by solar panels to power grape presses.', \"In 1941, Reza Shah was forced to abdicate in favor of his son, Mohammad Reza Pahlavi, and established the Persian Corridor, a massive supply route that would last until the end of the ongoing war. The presence of so many foreign troops in the nation also culminated in the Soviet-backed establishment of two puppet regimes in the nation; the Azerbaijan People's Government, and the Republic of Mahabad. As the Soviet Union refused to relinquish the occupied Iranian territory, the Iran crisis of 1946 was followed, which particularly resulted in the dissolution of both puppet states, and the withdrawal of the Soviets.\", 'Internet Explorer 10 is included as both a desktop program and a touch-optimized app, and includes increased support for HTML5, CSS3, and hardware acceleration. The Internet Explorer app does not support plugins or ActiveX components, but includes a version of Adobe Flash Player that is optimized for touch and low power usage. Initially, Adobe Flash would only work on sites included on a \"Compatibility View\" whitelist; however, after feedback from users and additional compatibility tests, an update in March 2013 changed this behavior to use a smaller blacklist of sites with known compatibility issues instead, allowing Flash to be used on most sites by default. The desktop version does not contain these limitations.', 'After successfully completing a diploma at a polytechnic, students can gain lateral entry to engineering degree (under graduate) courses called BE, which are conducted by engineering colleges affiliated to universities or University of Engineering & Technology or University of Engineering Sciences.', 'In 1995 the National Lottery granted money for a £4.6m sports complex, to add to Eton\\'s existing facilities of two swimming pools, 30 cricket squares, 24 football, rugby and hockey pitches and a gym. The College paid £200,000 and contributed 4.5 hectares of land in return for exclusive use of the facilities during the daytime only. The UK Sports Council defended the deal on the grounds that the whole community would benefit, while the bursar claimed that Windsor, Slough and Eton Athletic Club was \"deprived\" because local people (who were not pupils at the College) did not have a world-class running track and facilities to train with. Steve Osborn, director of the Safe Neighbourhoods Unit, described the decision as \"staggering\" given the background of a substantial reduction in youth services by councils across the country, a matter over which, however, neither the College nor the UK Sports Council, had any control. The facility, which became the Thames Valley Athletics Centre, opened in April 1999.', 'Situated between two large linguistic blocks (Ibero-Romance and Gallo-Romance), Catalan has many unique lexical choices, such as enyorar \"to miss somebody\", apaivagar \"to calm down somebody\", or rebutjar \"reject\".', 'By the 1900s, nigger had become a pejorative word in the United States. In its stead, the term colored became the mainstream alternative to negro and its derived terms. After the African-American Civil rights movement, the terms colored and negro gave way to \"black\". Negro had superseded colored as the most polite word for African Americans at a time when black was considered more offensive. This term was accepted as normal, including by people classified as Negroes, until the later Civil Rights movement in the late 1960s. One well-known example is the identification by Reverend Martin Luther King, Jr. of his own race as \"Negro\" in his famous speech of 1963, I Have a Dream. During the American Civil Rights movement of the 1950s and 1960s, some African-American leaders in the United States, notably Malcolm X, objected to the word Negro because they associated it with the long history of slavery, segregation, and discrimination that treated African Americans as second-class citizens, or worse. Malcolm X preferred Black to Negro, but later gradually abandoned that as well for Afro-American after leaving the Nation of Islam.', 'Chen Qingying, Professor of History and Director of the History Studies Institute under the China Tibetology Research Center in Beijing, writes that the Ming court conferred new official positions on ex-Yuan Tibetan leaders of the Phachu Kargyu and granted them lower-ranking positions. Of the county (zong or dzong) leaders of Neiwo Zong and Renbam Zong, Chen states that when \"the Emperor learned the actual situation of the Phachu Kargyu, the Ming court then appointed the main Zong leaders to be senior officers of the Senior Command of Dbus and Gtsang.\" The official posts that the Ming court established in Tibet, such as senior and junior commanders, offices of Qianhu (in charge of 1,000 households), and offices of Wanhu (in charge of 10,000 households), were all hereditary positions according to Chen, but he asserts that \"the succession of some important posts still had to be approved by the emperor,\" while old imperial mandates had to be returned to the Ming court for renewal.']\n",
      "[tensor([574, 477, 646, 144, 263,  97, 577, 690])]\n"
     ]
    }
   ],
   "source": [
    "for item in train_loader:\n",
    "    print(item.keys())\n",
    "    print(item['question'])\n",
    "    print(item['context'])\n",
    "    print(item['answers']['answer_start'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1c168-4382-4963-bab5-e723a863a4f7",
   "metadata": {},
   "source": [
    "# Introducing LoRA Weights\n",
    "This section introduces LoRA weights in our models for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9a0bca-9500-4e4f-9650-23bfc0a02439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On the surface the above results suggest you need most of the directions to account for most of the directions. \n",
    "# It will be useful to see which directions are affected and how later.\n",
    "from models.LoRA import LoRALinearLayer\n",
    "def add_linear_lora(module, rank, init_type=0):\n",
    "    for key, child in module.named_children():\n",
    "        if isinstance(child, torch.nn.Linear):\n",
    "            lora_layer =  LoRALinearLayer(child, rank=rank, init_type=init_type)\n",
    "            setattr(module, key, lora_layer)\n",
    "        else:\n",
    "            add_linear_lora(child, rank, init_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa02e6c0-2f89-40ab-b387-9c77de31b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_linear_lora(roberta_base, rank=10, init_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe6c9164-4b29-4ad1-b98f-a50c4f368e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (v_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (q_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (out_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): LoRALinear(in_features=768, in_features=3072, rank=$10, init_type=$1)\n",
       "            (fc2): LoRALinear(in_features=3072, in_features=768, rank=$10, init_type=$1)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c66542b-d1f8-417c-bae4-172a31970431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ff436bb-df8a-4baa-af98-0be01d85c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40d88517-de50-4af3-ac05-2096882f94d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "model_config = AutoConfig.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "489ec480-9ada-4d51-8c54-a21b050de0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_config(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bb4c7-0028-4504-840b-081200450898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
