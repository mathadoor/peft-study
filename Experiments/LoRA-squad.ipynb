{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e45fd35-cdca-44b8-a00f-607078ee1a67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Investigating Ranks\n",
    "In the first section, I am going to investigate what an appropriate rank to consider should be. It will make sense to look at the \n",
    "ranks of a trained matrix and a randomly initialized matrix. We will start by looking at a randomly initialized matrix and then\n",
    "look at a trained matrix. Specifically, I will look at the rank of a randomly initialized matrix. I will need to consider the sizes \n",
    "that are seen in RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1397017-4851-477f-a432-2a934510e545",
   "metadata": {},
   "source": [
    "## Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4f2172b3-4630-4fed-8bfd-4cf8b3ea7ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import Appropriate Libraries\n",
    "%load_ext autoreload\n",
    "    \n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm \n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# Set Logging Level\n",
    "import logging\n",
    "level = logging.DEBUG\n",
    "logging.getLogger(\"requests\").setLevel(level)\n",
    "logging.getLogger(\"urllib3\").setLevel(level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "25dba68b-c775-4672-8fbf-f2bb3da6f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_principle_direction(A, exp_var):\n",
    "    U, S, V = torch.linalg.svd(A)\n",
    "    X = (torch.cumsum(S, 0) / S.sum().item()).tolist()\n",
    "    num = bisect.bisect(X, exp_var)\n",
    "    return num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35846b95-4743-425e-a2bd-ac1db674217a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Normally Initialized Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4005e5-d964-4def-94f1-41d18030aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(n=100, size=[768, 768], exp_var=0.99):\n",
    "    results = []\n",
    "    for _ in range(n):\n",
    "        A = torch.randn(size)\n",
    "        num = get_principle_direction(A, exp_var)\n",
    "        results.append(num)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86b27c30-3205-4635-b424-9e5e80078d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([51.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 49.]),\n",
       " array([515. , 515.1, 515.2, 515.3, 515.4, 515.5, 515.6, 515.7, 515.8,\n",
       "        515.9, 516. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 3))\n",
    "ax[0].hist(plot_results())\n",
    "ax[1].hist(plot_results(exp_var=0.95))\n",
    "ax[2].hist(plot_results(exp_var=0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601559f6-0a40-40bb-830e-a836a35c5a5b",
   "metadata": {},
   "source": [
    "The above results indicate the rank is very tightly distributed based on the explained variance. The reader is encouraged to play with the explained_variance and support the claim themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41538748-3d56-4a69-a5f6-aa4f2e98f146",
   "metadata": {},
   "source": [
    "## Analysis of RoBERTa pre-trained Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "373c7b6d-5ccd-447e-b545-7349e19e7e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Now let's look at how tightly the weights are distributed in RoBERTa \n",
    "from transformers import AutoModel, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a18bc9a7-0c31-41be-970e-e37992303f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathador/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Extract RoBERTa Configuration\n",
    "roberta_base_config = AutoConfig.from_pretrained('roberta-base')\n",
    "roberta_large_config = AutoConfig.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "acf40d4d-e557-4b8c-a6ec-fe8725910263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract RoBERTa Model\n",
    "roberta_base_model = AutoModel.from_config(roberta_base_config)\n",
    "roberta_large_model = AutoModel.from_config(roberta_large_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9dd7956d-48ca-4f5f-96e1-72ca43118c2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_principle_direction(model, exp_var):\n",
    "    for key, param in model.named_parameters():\n",
    "        with torch.no_grad():\n",
    "            key = \".\".join(key.split(\".\")[3:])\n",
    "            p_size = min(param.size())\n",
    "            if len(param.size()) < 2:\n",
    "                continue\n",
    "            print(key, get_principle_direction(param, exp_var), p_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6379350c-f84f-41e2-bd2e-da56058431bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Roberta Base Principle Directions \n",
      "\n",
      " 759 768\n",
      " 492 514\n",
      " 0 1\n",
      "attention.self.query.weight 687 768\n",
      "attention.self.key.weight 687 768\n",
      "attention.self.value.weight 687 768\n",
      "attention.output.dense.weight 687 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 688 768\n",
      "attention.self.key.weight 687 768\n",
      "attention.self.value.weight 687 768\n",
      "attention.output.dense.weight 688 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 688 768\n",
      "attention.self.key.weight 688 768\n",
      "attention.self.value.weight 687 768\n",
      "attention.output.dense.weight 688 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 688 768\n",
      "attention.self.key.weight 688 768\n",
      "attention.self.value.weight 687 768\n",
      "attention.output.dense.weight 687 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 687 768\n",
      "attention.self.key.weight 688 768\n",
      "attention.self.value.weight 687 768\n",
      "attention.output.dense.weight 687 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 687 768\n",
      "attention.self.key.weight 687 768\n",
      "attention.self.value.weight 687 768\n",
      "attention.output.dense.weight 688 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 688 768\n",
      "attention.self.key.weight 687 768\n",
      "attention.self.value.weight 688 768\n",
      "attention.output.dense.weight 688 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 687 768\n",
      "attention.self.key.weight 687 768\n",
      "attention.self.value.weight 688 768\n",
      "attention.output.dense.weight 688 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 687 768\n",
      "attention.self.key.weight 687 768\n",
      "attention.self.value.weight 688 768\n",
      "attention.output.dense.weight 687 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 687 768\n",
      "attention.self.key.weight 688 768\n",
      "attention.self.value.weight 688 768\n",
      "attention.output.dense.weight 688 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 687 768\n",
      "attention.self.key.weight 688 768\n",
      "attention.self.value.weight 688 768\n",
      "attention.output.dense.weight 687 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      "attention.self.query.weight 688 768\n",
      "attention.self.key.weight 687 768\n",
      "attention.self.value.weight 688 768\n",
      "attention.output.dense.weight 688 768\n",
      "intermediate.dense.weight 753 768\n",
      "output.dense.weight 753 768\n",
      " 688 768\n",
      "\n",
      "# Roberta Large Principle Directions \n",
      "\n",
      " 1012 1024\n",
      " 498 514\n",
      " 0 1\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 916 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 916 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 916 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 916 1024\n",
      "attention.output.dense.weight 916 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 916 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 918 1024\n",
      "attention.output.dense.weight 916 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1004 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 916 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 916 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 916 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 916 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 916 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 916 1024\n",
      "attention.output.dense.weight 916 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 918 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 916 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 916 1024\n",
      "attention.self.key.weight 916 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 916 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 916 1024\n",
      "attention.self.value.weight 917 1024\n",
      "attention.output.dense.weight 918 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      "attention.self.query.weight 917 1024\n",
      "attention.self.key.weight 917 1024\n",
      "attention.self.value.weight 916 1024\n",
      "attention.output.dense.weight 917 1024\n",
      "intermediate.dense.weight 1005 1024\n",
      "output.dense.weight 1005 1024\n",
      " 917 1024\n"
     ]
    }
   ],
   "source": [
    "explained_variance = 0.99\n",
    "print(\"# Roberta Base Principle Directions \\n\")\n",
    "print_principle_direction(roberta_base_model, explained_variance)\n",
    "\n",
    "print(\"\\n# Roberta Large Principle Directions \\n\")\n",
    "print_principle_direction(roberta_large_model, explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a39e3e-2c84-458e-a47f-5e5a86443278",
   "metadata": {},
   "source": [
    "On the surface, the above results suggest you need most of the directions to account for the explained variance in the parameters.\n",
    "As such, we finetune the models for SQuAD and review the difference in the weights of the base and the tuned model. If the difference has \n",
    "fewer principle directions with high explanation, it would mean it is possible the task-based fine-tuning can be done in a smaller subspace. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a1ff52-126c-4665-92fd-c3e5d8c83fb2",
   "metadata": {},
   "source": [
    "## Rank Variation During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d59c3413-b156-4dfd-a1f5-1df488ff818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dataset\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from train.train import train_epoch\n",
    "from utils.metrics import AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "719ff899-edf9-4f7e-b665-ea440ef6bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Training Configuration\n",
    "with hydra.initialize(version_base=None, config_path=\"../config\"):\n",
    "    cfg = hydra.compose(config_name=\"app_config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9efb6c9-3495-4760-9c2b-094fa47b98bd",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f4b82e45-bb22-4aea-b6ac-1c2ef67ab9d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process Data\n",
    "train_dataset = load_dataset(\"squad\", split=\"train\")\n",
    "val_dataset = load_dataset(\"squad\", split=\"validation\")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "76dfbf26-bbad-4d73-933a-652dded44c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Max Length is 512\n",
      "Dataset Features are {'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model Max Length is {tokenizer.model_max_length}\")\n",
    "print(f\"Dataset Features are {train_dataset.features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "19b45799-1fa8-4ed4-a7c2-b3004997e9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 143 training instances with length longer than 512\n"
     ]
    }
   ],
   "source": [
    "cut_off_length = 512\n",
    "long_dataset = train_dataset.filter(lambda x: len(tokenizer(x['question'], x['context']).input_ids) > cut_off_length)\n",
    "print(f\"There are {long_dataset.num_rows} training instances with length longer than {cut_off_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932bb38a-5b28-4dbd-9faa-0aa9571a02e7",
   "metadata": {},
   "source": [
    "Since there are only 143 instances with the length longer than 512. I will remove those instances for the purpose of simplicity. These changes are unlikely to affect the outcome. The learned concept will not account for\n",
    "the cases in which the context may not contain the answer. Also, if there is a regularity in the placement of the answer in the question, the model may over fit to it. But given large number of samples, I assume it is not\n",
    "the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "119e8460-86c9-40d3-8fdb-2ac52d692766",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.filter(lambda x: len(tokenizer(x['question'], x['context']).input_ids) <= cut_off_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5dbd6078-c403-46ae-9aee-abd56889548b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "['a copper statue of Christ']\n",
      "a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n"
     ]
    }
   ],
   "source": [
    "## Let's See how the answer looks like\n",
    "idx = 1\n",
    "instance = train_dataset[idx]\n",
    "answer = instance['answers']\n",
    "print(answer['answer_start'][0])\n",
    "print(answer['text'])\n",
    "print(instance['context'][answer['answer_start'][0]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ae666051-6c8c-4e42-995e-adc84cef27fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer is not character based\n"
     ]
    }
   ],
   "source": [
    "# The above indicates the answer_start is the beginning character. Let's see if this is consistent with the rest of the results\n",
    "char_tokenizer = True\n",
    "for idx, item in enumerate(train_dataset):\n",
    "    start = item['answers']['answer_start'][0]\n",
    "    end = start + len(item['answers']['text'][0])\n",
    "    extracted_answer = item['context'][start:end]\n",
    "    answer = item['answers']['text'][0]\n",
    "    if extracted_answer != answer:\n",
    "        print(idx, extracted_answer, answer)\n",
    "    if char_tokenizer:\n",
    "        tokenized_answer = tokenizer(answer).input_ids\n",
    "        char_tokenizer = len(tokenized_answer) - 2 == len(answer)\n",
    "\n",
    "if not char_tokenizer:\n",
    "    print(\"Tokenizer is not character based\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c37f437-6dbf-4a61-a180-42285188b5c2",
   "metadata": {},
   "source": [
    "The above result confirms that the answers are made available in terms of character offset instead of tokenizer offset. This is likely the case to maintain generality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1e3db4e-f142-4acd-ae85-0ff707c3384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisect(l, r, tokenizer, tokenized_context, target, l_off=0, r_off=0, mid_off=0):\n",
    "    # Standard Binary Search with a Few Bells and Whistles\n",
    "    while l < r:\n",
    "        mid = l + (r - l + mid_off) // 2\n",
    "        partial_context = tokenizer.decode(tokenized_context[:mid])\n",
    "        if len(partial_context) <= target:\n",
    "            l = mid + l_off\n",
    "        else:\n",
    "            r = mid + r_off\n",
    "        # print(r, l, mid)\n",
    "    return max(l, r)\n",
    "\n",
    "def get_start_end_index(tokenized_context, answer, answer_start):\n",
    "    # Set Answer End Index\n",
    "    answer_end = answer_start + len(answer)\n",
    "\n",
    "    # Search for the starting index of the Token That contains the answer\n",
    "    ll, rl = 0, len(tokenized_context)\n",
    "    # print(\"Starting Left Search\")\n",
    "    start_index = bisect(ll, rl, tokenizer, tokenized_context, answer_start, r_off=-1, mid_off=1)\n",
    "\n",
    "    # Search for the ending index of the tokens in which the answer terminates\n",
    "    rl, rr = start_index, len(tokenized_context)\n",
    "    # print(\"Starting Right Search\")\n",
    "    end_index = bisect(start_index, len(tokenized_context), tokenizer, tokenized_context, answer_end, l_off=1)\n",
    "    \n",
    "    return start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "be31a5ad-b61e-475d-874e-db47e377ea5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87456it [08:35, 169.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# Let's tokenize the start and end character\n",
    "failed_indices = []\n",
    "\n",
    "def validate(tokenized_context, start_index, end_index, idx, answer, context, question, ret):\n",
    "    # Test if the correct Solution is found\n",
    "    extracted_context = tokenized_context[:end_index]\n",
    "    extracted_answer = tokenizer.decode(extracted_context).strip()\n",
    "    \n",
    "    if extracted_answer.find(answer) == -1:\n",
    "        failed_instance = {\"idx\" : idx, \n",
    "                           \"start_index\" : start_index,\n",
    "                           \"end_index\" : end_index,\n",
    "                           \"extracted_answer\" : extracted_answer,\n",
    "                           \"answer\" : answer,\n",
    "                           \"context\" : context,\n",
    "                           \"question\" : question} \n",
    "        ret.append(failed_instance)\n",
    "\n",
    "for idx, item in tqdm(enumerate(train_dataset)):\n",
    "    question = item['question']\n",
    "    context = item['context']\n",
    "    \n",
    "    answer = item['answers']['text'][0]\n",
    "    answer_start = item['answers']['answer_start'][0]\n",
    "\n",
    "    # Extract Start and End Index of the Tokenized Question/Context Duo\n",
    "    tokenized_question = tokenizer(question).input_ids\n",
    "    tokenized_context = tokenizer(question, context).input_ids\n",
    "    start_index, end_index = get_start_end_index(tokenized_context, answer, answer_start + len(question) + 10)\n",
    "\n",
    "    # Test if the correct Solution is found\n",
    "    validate(tokenized_context, start_index, end_index, idx, answer, context, question, failed_indices)\n",
    "    # extracted_context = tokenized_context[:end_index]\n",
    "    # extracted_answer = tokenizer.decode(extracted_context).strip()\n",
    "    \n",
    "    # if extracted_answer.find(answer) == -1:\n",
    "    #     failed_instance = {\"idx\" : idx, \n",
    "    #                        \"start_index\" : start_index,\n",
    "    #                        \"end_index\" : end_index,\n",
    "    #                        \"extracted_answer\" : extracted_answer,\n",
    "    #                        \"answer\" : answer,\n",
    "    #                        \"context\" : context,\n",
    "    #                        \"question\" : question} \n",
    "    #     failed_indices.append(failed_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d26eb5e8-1043-40ff-8920-b8693db68547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 56 failed instances by the above method\n"
     ]
    }
   ],
   "source": [
    "print(fr\"There are {len(failed_indices)} failed instances by the above method\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "726329a5-b44d-4615-9c2c-35ac09a49789",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_failed_instances = []\n",
    "\n",
    "def process_batched_training_examples(instances):\n",
    "    questions, contexts = instances['question'], instances['context']\n",
    "    answers = instances['answers']\n",
    "    \n",
    "    inputs = tokenizer(questions, contexts)\n",
    "    start_index, end_index = [], []\n",
    "    for idx, instance in enumerate(instances['id']):\n",
    "        answer = answers[idx]\n",
    "        question = questions[idx]\n",
    "        answer_text, answer_start = answer['text'][0], answer['answer_start'][0]\n",
    "\n",
    "        start, end = get_start_end_index(inputs.input_ids[idx], answer_text, answer_start + len(question) + 10)\n",
    "        \n",
    "        start_index.append(start)\n",
    "        end_index.append(end)\n",
    "\n",
    "        validate(inputs.input_ids[idx], start, end, 0, answer, context, question, map_failed_instances)\n",
    "\n",
    "    inputs['start_index'] = start_index\n",
    "    inputs['end_index'] = end_index\n",
    "\n",
    "    return inputs\n",
    "\n",
    "def process_training_examples(instance):\n",
    "    question, context = instance['question'], instance['context']\n",
    "    answer = instance['answers']\n",
    "    \n",
    "    inputs = tokenizer(question, context)\n",
    "    \n",
    "    answer_text, answer_start = answer['text'][0], answer['answer_start'][0]\n",
    "\n",
    "    start_index, end_index = get_start_end_index(inputs.input_ids, answer_text, answer_start + len(question) + 10)\n",
    "    \n",
    "    inputs['start_index'] = start_index\n",
    "    inputs['end_index'] = end_index\n",
    "\n",
    "    validate(inputs.input_ids, start_index, end_index, 0, answer, context, question, map_failed_instances)\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5ca9b2a1-63df-4897-b8bc-a91e46ef61ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed5a71eff5045539addc66420857780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87456 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocess_batched_training_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py:3156\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3151\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3152\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3153\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3154\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3155\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3157\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3158\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py:3547\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3543\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3544\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3545\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3546\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3547\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3551\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3553\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3556\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/arrow_dataset.py:3416\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3415\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3416\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3418\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3419\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3420\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[115], line 19\u001b[0m, in \u001b[0;36mprocess_batched_training_examples\u001b[0;34m(instances)\u001b[0m\n\u001b[1;32m     16\u001b[0m     start_index\u001b[38;5;241m.\u001b[39mappend(start)\n\u001b[1;32m     17\u001b[0m     end_index\u001b[38;5;241m.\u001b[39mappend(end)\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_failed_instances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_index\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m start_index\n\u001b[1;32m     22\u001b[0m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_index\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m end_index\n",
      "Cell \u001b[0;32mIn[103], line 9\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(tokenized_context, start_index, end_index, idx, answer, context, question, ret)\u001b[0m\n\u001b[1;32m      6\u001b[0m extracted_context \u001b[38;5;241m=\u001b[39m tokenized_context[:end_index]\n\u001b[1;32m      7\u001b[0m extracted_answer \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(extracted_context)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mextracted_answer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43manswer\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     10\u001b[0m     failed_instance \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midx\u001b[39m\u001b[38;5;124m\"\u001b[39m : idx, \n\u001b[1;32m     11\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_index\u001b[39m\u001b[38;5;124m\"\u001b[39m : start_index,\n\u001b[1;32m     12\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_index\u001b[39m\u001b[38;5;124m\"\u001b[39m : end_index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m : context,\n\u001b[1;32m     16\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m : question} \n\u001b[1;32m     17\u001b[0m     ret\u001b[38;5;241m.\u001b[39mappend(failed_instance)\n",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not dict"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    process_batched_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=train_dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a31482-ff23-4244-8f81-6f9656ac8a15",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a7bcbd0-1ab7-48b6-b890-79dddf7abbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Training Artifacts\n",
    "training_cfg = hydra.utils.instantiate(cfg.model.model.train)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=training_cfg.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=training_cfg.batch_size)\n",
    "\n",
    "model = roberta_base_model\n",
    "optimizer = AdamW(params=model.parameters(), lr=training_cfg.lr, weight_decay=training_cfg.weight_decay)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "loss_meter = AverageMeter()\n",
    "acc_meter = AverageMeter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e36ab-0cef-48c2-9871-fa85e359ed33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5935d06e-6829-4170-8382-57d203cd8467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 3972, 2661, 222, 5, 9880, 2708, 2346, 2082, 11, 504, 4432, 11, 226, 2126, 10067, 1470, 116, 2, 2, 37848, 37471, 28108, 6, 5, 334, 34, 10, 4019, 2048, 4, 497, 1517, 5, 4326, 6919, 18, 1637, 31346, 16, 10, 9030, 9577, 9, 5, 9880, 2708, 4, 29261, 11, 760, 9, 5, 4326, 6919, 8, 2114, 24, 6, 16, 10, 7621, 9577, 9, 4845, 19, 3701, 62, 33161, 19, 5, 7875, 22, 39043, 1459, 1614, 1464, 13292, 4977, 845, 4130, 7, 5, 4326, 6919, 16, 5, 26429, 2426, 9, 5, 25095, 6924, 4, 29261, 639, 5, 32394, 2426, 16, 5, 7461, 26187, 6, 10, 19035, 317, 9, 9621, 8, 12456, 4, 85, 16, 10, 24633, 9, 5, 11491, 26187, 23, 226, 2126, 10067, 6, 1470, 147, 5, 9880, 2708, 2851, 13735, 352, 1382, 7, 6130, 6552, 625, 3398, 208, 22895, 853, 1827, 11, 504, 4432, 4, 497, 5, 253, 9, 5, 1049, 1305, 36, 463, 11, 10, 2228, 516, 14, 15230, 149, 155, 19638, 8, 5, 2610, 25336, 238, 16, 10, 2007, 6, 2297, 7326, 9577, 9, 2708, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "for item in train_dataset:\n",
    "    x = f\"[CLS]{item['question']}[SEP]{item['context']}\"\n",
    "    tokenized_x = tokenizer(item['question'], item['context'])\n",
    "    print(tokenized_x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd23942f-6ea1-4a79-98ae-ddaa0d6a765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d0c2e-1193-416a-8d95-52dc9e5c3832",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1c168-4382-4963-bab5-e723a863a4f7",
   "metadata": {},
   "source": [
    "# Introducing LoRA Weights\n",
    "This section introduces LoRA weights in our models for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9a0bca-9500-4e4f-9650-23bfc0a02439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On the surface the above results suggest you need most of the directions to account for most of the directions. \n",
    "# It will be useful to see which directions are affected and how later.\n",
    "from models.LoRA import LoRALinearLayer\n",
    "def add_linear_lora(module, rank, init_type=0):\n",
    "    for key, child in module.named_children():\n",
    "        if isinstance(child, torch.nn.Linear):\n",
    "            lora_layer =  LoRALinearLayer(child, rank=rank, init_type=init_type)\n",
    "            setattr(module, key, lora_layer)\n",
    "        else:\n",
    "            add_linear_lora(child, rank, init_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa02e6c0-2f89-40ab-b387-9c77de31b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_linear_lora(roberta_base, rank=10, init_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe6c9164-4b29-4ad1-b98f-a50c4f368e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (v_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (q_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (out_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): LoRALinear(in_features=768, in_features=3072, rank=$10, init_type=$1)\n",
       "            (fc2): LoRALinear(in_features=3072, in_features=768, rank=$10, init_type=$1)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c66542b-d1f8-417c-bae4-172a31970431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ff436bb-df8a-4baa-af98-0be01d85c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40d88517-de50-4af3-ac05-2096882f94d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "model_config = AutoConfig.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "489ec480-9ada-4d51-8c54-a21b050de0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_config(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bb4c7-0028-4504-840b-081200450898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
