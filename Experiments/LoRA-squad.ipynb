{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e45fd35-cdca-44b8-a00f-607078ee1a67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Investigating Ranks\n",
    "In the first section, I am going to investigate what an appropriate rank to consider should be. It will make sense to look at the \n",
    "ranks of a trained matrix and a randomly initialized matrix. We will start by looking at a randomly initialized matrix and then\n",
    "look at a trained matrix. Specifically, I will look at the rank of a randomly initialized matrix. I will need to consider the sizes \n",
    "that are seen in RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1397017-4851-477f-a432-2a934510e545",
   "metadata": {},
   "source": [
    "## Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f2172b3-4630-4fed-8bfd-4cf8b3ea7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Appropriate Libraries\n",
    "%load_ext autoreload\n",
    "    \n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "import bisect\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25dba68b-c775-4672-8fbf-f2bb3da6f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_principle_direction(A, exp_var):\n",
    "    U, S, V = torch.linalg.svd(A)\n",
    "    X = (torch.cumsum(S, 0) / S.sum().item()).tolist()\n",
    "    num = bisect.bisect(X, exp_var)\n",
    "    return num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35846b95-4743-425e-a2bd-ac1db674217a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Normally Initialized Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a4005e5-d964-4def-94f1-41d18030aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(n=100, size=[768, 768], exp_var=0.99):\n",
    "    results = []\n",
    "    for _ in range(n):\n",
    "        A = torch.randn(size)\n",
    "        num = get_principle_direction(A, exp_var)\n",
    "        results.append(num)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b27c30-3205-4635-b424-9e5e80078d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([44.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 56.]),\n",
       " array([515. , 515.1, 515.2, 515.3, 515.4, 515.5, 515.6, 515.7, 515.8,\n",
       "        515.9, 516. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3)\n",
    "ax[0].hist(plot_results())\n",
    "ax[1].hist(plot_results(exp_var=0.95))\n",
    "ax[2].hist(plot_results(exp_var=0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601559f6-0a40-40bb-830e-a836a35c5a5b",
   "metadata": {},
   "source": [
    "The above results indicate the rank is very tightly distributed based on the explained variance. The reader is encouraged to play with the explained_variance and support the claim themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41538748-3d56-4a69-a5f6-aa4f2e98f146",
   "metadata": {},
   "source": [
    "## Analysis of RoBERTa pre-trained Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "373c7b6d-5ccd-447e-b545-7349e19e7e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mathador/.cache/torch/hub/pytorch_fairseq_main\n",
      "2024-05-19 12:28:37 | INFO | fairseq.file_utils | loading archive file http://dl.fbaipublicfiles.com/fairseq/models/roberta.large.tar.gz from cache at /home/mathador/.cache/torch/pytorch_fairseq/83e3a689e28e5e4696ecb0bbb05a77355444a5c8a3437e0f736d8a564e80035e.c687083d14776c1979f3f71654febb42f2bb3d9a94ff7ebdfe1ac6748dba89d2\n",
      "/home/mathador/.local/lib/python3.10/site-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(message=message)\n",
      "/home/mathador/.local/lib/python3.10/site-packages/hydra/experimental/initialize.py:45: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  self.delegate = real_initialize(\n",
      "/home/mathador/.local/lib/python3.10/site-packages/hydra/experimental/compose.py:25: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(message=message)\n",
      "/home/mathador/.local/lib/python3.10/site-packages/hydra/core/default_element.py:124: UserWarning: In 'config': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  deprecation_warning(\n",
      "/home/mathador/.cache/torch/hub/pytorch_fairseq_main/fairseq/checkpoint_utils.py:450: UserWarning: \n",
      "'config' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "  state = load_checkpoint_to_cpu(filename, arg_overrides)\n",
      "/home/mathador/.local/lib/python3.10/site-packages/hydra/compose.py:56: UserWarning: \n",
      "The strict flag in the compose API is deprecated.\n",
      "See https://hydra.cc/docs/1.2/upgrades/0.11_to_1.0/strict_mode_flag_deprecated for more info.\n",
      "\n",
      "  deprecation_warning(\n",
      "/home/mathador/.cache/torch/hub/pytorch_fairseq_main/fairseq/models/roberta/model.py:369: UserWarning: \n",
      "'config' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "  x = hub_utils.from_pretrained(\n",
      "2024-05-19 12:28:37 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2024-05-19 12:28:42 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 25, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 4, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1024, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 19237, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 200, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'mmap', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 500000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0004], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1024}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=25, log_format='json', tbmf_wrapper=False, seed=4, cpu=False, fp16=True, memory_efficient_fp16=True, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=2, skip_invalid_size_inputs_valid_test=True, max_tokens=4400, max_sentences=8, required_batch_size_multiple=1, dataset_impl='mmap', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, only_validate=False, max_sentences_valid=8, curriculum=0, distributed_world_size=1024, distributed_rank=0, distributed_backend='nccl', distributed_port=19237, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=200, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_large', max_epoch=0, max_update=500000, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0004], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=2000, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.01, force_anneal=None, warmup_updates=24000, end_learning_rate=0.0, power=1.0, total_num_update=500000, sample_break_mode='complete', tokens_per_sample=512, mask_prob=0.15, leave_unmasked_prob=0.1, random_token_prob=0.1, activation_fn='gelu', dropout=0.1, attention_dropout=0.1, encoder_embed_dim=1024, encoder_layers=24, encoder_attention_heads=16, encoder_ffn_embed_dim=4096, pooler_activation_fn='tanh', max_positions=512, activation_dropout=0.0, load_checkpoint_heads=True, data='/home/mathador/.cache/torch/pytorch_fairseq/83e3a689e28e5e4696ecb0bbb05a77355444a5c8a3437e0f736d8a564e80035e.c687083d14776c1979f3f71654febb42f2bb3d9a94ff7ebdfe1ac6748dba89d2', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_large', pooler_dropout=0.0, no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': '/home/mathador/.cache/torch/pytorch_fairseq/83e3a689e28e5e4696ecb0bbb05a77355444a5c8a3437e0f736d8a564e80035e.c687083d14776c1979f3f71654febb42f2bb3d9a94ff7ebdfe1ac6748dba89d2', 'sample_break_mode': 'complete', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 4, 'include_target_tokens': False, 'include_index': True, 'skip_masking': False, 'd2v2_multi': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [0.0004]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 24000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 500000.0, 'lr': [0.0004]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
      "Using cache found in /home/mathador/.cache/torch/hub/pytorch_fairseq_main\n",
      "2024-05-19 12:28:43 | INFO | fairseq.file_utils | loading archive file http://dl.fbaipublicfiles.com/fairseq/models/roberta.base.tar.gz from cache at /home/mathador/.cache/torch/pytorch_fairseq/37d2bc14cf6332d61ed5abeb579948e6054e46cc724c7d23426382d11a31b2d6.ae5852b4abc6bf762e0b6b30f19e741aa05562471e9eb8f4a6ae261f04f9b350\n",
      "2024-05-19 12:28:43 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2024-05-19 12:28:45 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 25, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 512, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': 19812, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 200, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 999999, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'mmap', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 999999, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 500000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0006], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 2000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 512}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=25, log_format='json', tbmf_wrapper=False, seed=1, cpu=False, fp16=True, memory_efficient_fp16=True, fp16_init_scale=4, fp16_scale_window=128, fp16_scale_tolerance=0.0, min_loss_scale=0.0001, threshold_loss_scale=1.0, user_dir=None, criterion='masked_lm', tokenizer=None, bpe='gpt2', optimizer='adam', lr_scheduler='polynomial_decay', task='masked_lm', num_workers=2, skip_invalid_size_inputs_valid_test=True, max_tokens=999999, max_sentences=16, required_batch_size_multiple=1, dataset_impl='mmap', train_subset='train', valid_subset='valid', validate_interval=1, disable_validation=False, only_validate=False, max_sentences_valid=16, curriculum=0, distributed_world_size=512, distributed_rank=0, distributed_backend='nccl', distributed_port=19812, device_id=0, distributed_no_spawn=False, ddp_backend='c10d', bucket_cap_mb=200, fix_batches_to_gpus=False, find_unused_parameters=True, arch='roberta_base', max_epoch=0, max_update=500000, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0006], use_bmuf=False, global_sync_iter=10, restore_file='checkpoint_last.pt', reset_dataloader=True, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=2000, keep_interval_updates=-1, keep_last_epochs=-1, no_save=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, adam_betas='(0.9, 0.98)', adam_eps=1e-06, weight_decay=0.01, force_anneal=None, warmup_updates=24000, end_learning_rate=0.0, power=1.0, total_num_update=500000, sample_break_mode='complete', tokens_per_sample=512, mask_prob=0.15, leave_unmasked_prob=0.1, random_token_prob=0.1, activation_fn='gelu', dropout=0.1, attention_dropout=0.1, encoder_embed_dim=768, encoder_layers=12, encoder_attention_heads=12, encoder_ffn_embed_dim=3072, pooler_activation_fn='tanh', max_positions=512, activation_dropout=0.0, load_checkpoint_heads=True, data='/home/mathador/.cache/torch/pytorch_fairseq/37d2bc14cf6332d61ed5abeb579948e6054e46cc724c7d23426382d11a31b2d6.ae5852b4abc6bf762e0b6b30f19e741aa05562471e9eb8f4a6ae261f04f9b350', max_source_positions=512, max_target_positions=512, stop_min_lr=-1, encoder_layerdrop=0, encoder_layers_to_keep=None, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, spectral_norm_classification_head=False, min_params_to_wrap=100000000, mha_reg_scale_factor=0.0, ffn_reg_scale_factor=0.0, mha_heads_to_keep=-1, ffn_blocks_to_remove=-1, _name='roberta_base', pooler_dropout=0.0, no_token_positional_embeddings=False, encoder_learned_pos=True, layernorm_embedding=True, no_scale_embedding=True, encoder_normalize_before=False, untie_weights_roberta=False, adaptive_input=False), 'task': {'_name': 'masked_lm', 'data': '/home/mathador/.cache/torch/pytorch_fairseq/37d2bc14cf6332d61ed5abeb579948e6054e46cc724c7d23426382d11a31b2d6.ae5852b4abc6bf762e0b6b30f19e741aa05562471e9eb8f4a6ae261f04f9b350', 'sample_break_mode': 'complete', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 1, 'include_target_tokens': False, 'include_index': True, 'skip_masking': False, 'd2v2_multi': False}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [0.0006]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 24000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 500000.0, 'lr': [0.0006]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n"
     ]
    }
   ],
   "source": [
    "## Now let's look at how tightly the weights are distributed in RoBERTa \n",
    "roberta_large = torch.hub.load('pytorch/fairseq', 'roberta.large') \n",
    "roberta_base = torch.hub.load('pytorch/fairseq', 'roberta.base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dd7956d-48ca-4f5f-96e1-72ca43118c2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_principle_direction(model, exp_var):\n",
    "    for key, param in model.named_parameters():\n",
    "        with torch.no_grad():\n",
    "            key = \".\".join(key.split(\".\")[3:])\n",
    "            p_size = min(param.size())\n",
    "            if len(param.size()) < 2:\n",
    "                print(key, p_size)\n",
    "                continue\n",
    "            print(key, get_principle_direction(param, exp_var), p_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379350c-f84f-41e2-bd2e-da56058431bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = 0.99\n",
    "print(\"# Roberta Base Principle Directions \\n\")\n",
    "print_principle_direction(roberta_base, explained_variance)\n",
    "\n",
    "print(\"# Roberta Large Principle Directions \\n\")\n",
    "print_principle_direction(roberta_large, explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a39e3e-2c84-458e-a47f-5e5a86443278",
   "metadata": {},
   "source": [
    "On the surface, the above results suggest you need most of the directions to account for the explained variance in the parameters.\n",
    "As such, we finetune the models for SQuAD and review the difference in the weights of the base and the tuned model. If the difference has \n",
    "fewer principle directions with high explanation, it would mean it is possible the task-based fine-tuning can be done in a smaller subspace. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a1ff52-126c-4665-92fd-c3e5d8c83fb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Rank Variation During Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1c168-4382-4963-bab5-e723a863a4f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Introducing LoRA Weights\n",
    "This section introduces LoRA weights in our models for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9a0bca-9500-4e4f-9650-23bfc0a02439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On the surface the above results suggest you need most of the directions to account for most of the directions. \n",
    "# It will be useful to see which directions are affected and how later.\n",
    "from models.LoRA import LoRALinearLayer\n",
    "def add_linear_lora(module, rank, init_type=0):\n",
    "    for key, child in module.named_children():\n",
    "        if isinstance(child, torch.nn.Linear):\n",
    "            lora_layer =  LoRALinearLayer(child, rank=rank, init_type=init_type)\n",
    "            setattr(module, key, lora_layer)\n",
    "        else:\n",
    "            add_linear_lora(child, rank, init_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa02e6c0-2f89-40ab-b387-9c77de31b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_linear_lora(roberta_base, rank=10, init_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe6c9164-4b29-4ad1-b98f-a50c4f368e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (v_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (q_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (out_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): LoRALinear(in_features=768, in_features=3072, rank=$10, init_type=$1)\n",
       "            (fc2): LoRALinear(in_features=3072, in_features=768, rank=$10, init_type=$1)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c66542b-d1f8-417c-bae4-172a31970431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff436bb-df8a-4baa-af98-0be01d85c430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
