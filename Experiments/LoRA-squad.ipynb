{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e45fd35-cdca-44b8-a00f-607078ee1a67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Investigating Ranks\n",
    "In the first section, I am going to investigate what an appropriate rank to consider should be. It will make sense to look at the \n",
    "ranks of a trained matrix and a randomly initialized matrix. We will start by looking at a randomly initialized matrix and then\n",
    "look at a trained matrix. Specifically, I will look at the rank of a randomly initialized matrix. I will need to consider the sizes \n",
    "that are seen in RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1397017-4851-477f-a432-2a934510e545",
   "metadata": {},
   "source": [
    "## Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2172b3-4630-4fed-8bfd-4cf8b3ea7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Appropriate Libraries\n",
    "%load_ext autoreload\n",
    "    \n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm.notebook import tqdm \n",
    "import bisect\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fe7ef66-162e-40e3-bb71-025bf872cd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Logging Level\n",
    "import logging\n",
    "import datetime\n",
    "time_now = str(datetime.datetime.now()).split('.')[0]\n",
    "logging.basicConfig(filename=f'../logs/peft-{time_now}.log', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25dba68b-c775-4672-8fbf-f2bb3da6f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_principle_direction(A, exp_var):\n",
    "    U, S, V = torch.linalg.svd(A)\n",
    "    S = S ** 2\n",
    "    X = (torch.cumsum(S, 0) / S.sum().item()).tolist()\n",
    "    num = bisect.bisect(X, exp_var)\n",
    "    return num\n",
    "\n",
    "def get_principle_directions(A, exp_vars):\n",
    "    U, S, V = torch.linalg.svd(A)\n",
    "    S = S ** 2\n",
    "    X = (torch.cumsum(S, 0) / S.sum().item()).tolist()\n",
    "    ret = []\n",
    "    i, j = 0, 0\n",
    "    while i < len(exp_vars) and j < len(X):\n",
    "        val = X[j]\n",
    "        exp_var = exp_vars[i]\n",
    "        if val < exp_var:\n",
    "            j += 1\n",
    "        else:\n",
    "            ret.append(j)\n",
    "            i += 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35846b95-4743-425e-a2bd-ac1db674217a",
   "metadata": {},
   "source": [
    "## Normally Initialized Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a4005e5-d964-4def-94f1-41d18030aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(n=100, size=[768, 768], exp_var=0.99):\n",
    "    results = []\n",
    "    for _ in range(n):\n",
    "        A = torch.randn(size)\n",
    "        num = get_principle_direction(A, exp_var)\n",
    "        results.append(num)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b27c30-3205-4635-b424-9e5e80078d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([16.,  0.,  0.,  0.,  0., 79.,  0.,  0.,  0.,  5.]),\n",
       " array([390. , 390.2, 390.4, 390.6, 390.8, 391. , 391.2, 391.4, 391.6,\n",
       "        391.8, 392. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz8AAAESCAYAAADT+GuCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyx0lEQVR4nO3de3RU5b3/8c+EJBMEMoFAZhIJGBQJXlCJnjBoqQ0pkQWKJcsLxSMihUojFVKr5CzUStUgXQWKhouWhtqKHOkRrxWOBAkHSWKIYvHSCBabICS0YhKIzYSS5/eHv0wZCJTJ3DKZ92utZy1n7z17f79mz+P+uvezH4sxxggAAAAAurmoUAcAAAAAAMFA8QMAAAAgIlD8AAAAAIgIFD8AAAAAIgLFDwAAAICIQPEDAAAAICJQ/AAAAACICNGhDuBUbW1tOnjwoPr06SOLxRLqcICIZozR0aNHlZKSoqio8Pl/JfQjQNcRjv0IfQjQdfi7D+lyxc/BgweVmpoa6jAAnKS2tlYDBw4MdRjnjH4E6HrCqR+hDwG6Hn/1IV2u+OnTp4+kbxKMj48PcTRAZGtqalJqaqr7dxku6EeAriMc+xH6EKDr8Hcf0uWKn/bby/Hx8XQ4QBcRbo990I8AXU849SP0IUDX468+JDwevgUAAAAAH1H8AAAAAIgIFD8AACBsnDhxQg899JDS0tLUs2dPXXjhhfr5z38uY4x7G2OMHn74YSUnJ6tnz57Kzs7W3r17Qxg1gK6C4gcAAISNJ598UitXrtTTTz+tTz75RE8++aQWL16sp556yr3N4sWLtXz5cq1atUoVFRXq1auXcnJy1NLSEsLIAXQFXe6FBwAAAGeyc+dOTZo0SRMmTJAkXXDBBXrhhRf07rvvSvrmrs+yZcu0YMECTZo0SZL03HPPyW636+WXX9btt99+2j5dLpdcLpf7c1NTUxAyARAK3PkBAABhY/To0SopKdGnn34qSfrggw+0Y8cOjR8/XpK0f/9+1dXVKTs72/0dm82mzMxMlZWVdbjPwsJC2Ww2d2OOH6D74s4PAAAIG/Pnz1dTU5PS09PVo0cPnThxQo8//rimTp0qSaqrq5Mk2e12j+/Z7Xb3ulMVFBQoPz/f/bl9XhEA3Q/FDwAACBsvvviinn/+ea1bt06XXnqpdu/erblz5yolJUXTpk3r1D6tVqusVqufIwXQFVH8IGAumP+G3/f5+aIJft8ngK6LfgSn+ulPf6r58+e7x+5cfvnl+utf/6rCwkJNmzZNDodDklRfX6/k5GT39+rr63XllVeGImSEEH0ITsWYHwAAEDa+/vprRUV5Xr706NFDbW1tkqS0tDQ5HA6VlJS41zc1NamiokJOpzOosQLoerjzAwAAwsaNN96oxx9/XIMGDdKll16q999/X0uWLNHdd98tSbJYLJo7d64ee+wxDR06VGlpaXrooYeUkpKim2++ObTBAwg5ih8AABA2nnrqKT300EP60Y9+pMOHDyslJUU//OEP9fDDD7u3eeCBB9Tc3KxZs2apoaFB1113nTZt2qS4uLgQRg6gK6D4AQAAYaNPnz5atmyZli1bdsZtLBaLFi5cqIULFwYvMABhgTE/AAAAACICxQ8AAACAiEDxAwAAACAiUPwAAAAAiAgUPwAAAAAiAsUPAAAAgIhA8QMAAAAgIlD8AAAAAIgIFD8Agu6LL77QHXfcocTERPXs2VOXX365du3a5V5vjNHDDz+s5ORk9ezZU9nZ2dq7d28IIwYAAN2BV8XPBRdcIIvFclrLy8uTJLW0tCgvL0+JiYnq3bu3cnNzVV9fH5DAAYSnr776Stdee61iYmL05ptv6uOPP9Yvf/lL9e3b173N4sWLtXz5cq1atUoVFRXq1auXcnJy1NLSEsLIAQBAuIv2ZuPKykqdOHHC/fnDDz/Ud7/7Xd1yyy2SpHnz5umNN97Qhg0bZLPZdO+992ry5Ml65513/Bs1gLD15JNPKjU1VcXFxe5laWlp7n82xmjZsmVasGCBJk2aJEl67rnnZLfb9fLLL+v2228PeswAAKB78OrOz4ABA+RwONzt9ddf14UXXqhvf/vbamxs1Jo1a7RkyRJlZWUpIyNDxcXF2rlzp8rLywMVP4Aw8+qrr+rqq6/WLbfcoqSkJF111VV69tln3ev379+vuro6ZWdnu5fZbDZlZmaqrKysw326XC41NTV5NAAAgFN1esxPa2urfv/73+vuu++WxWJRVVWVjh8/7nHBkp6erkGDBp3xgkXiogWINH/5y1+0cuVKDR06VJs3b9bs2bP14x//WL/97W8lSXV1dZIku93u8T273e5ed6rCwkLZbDZ3S01NDWwSAAAgLHW6+Hn55ZfV0NCgu+66S9I3FyyxsbFKSEjw2O5sFywSFy1ApGlra9PIkSP1xBNP6KqrrtKsWbM0c+ZMrVq1qtP7LCgoUGNjo7vV1tb6MWIAANBddLr4WbNmjcaPH6+UlBSfAuCiBYgsycnJuuSSSzyWDR8+XDU1NZIkh8MhSae9LKW+vt697lRWq1Xx8fEeDQAA4FSdKn7++te/asuWLfrBD37gXuZwONTa2qqGhgaPbc92wSJx0QJEmmuvvVbV1dUeyz799FMNHjxY0jcvP3A4HCopKXGvb2pqUkVFhZxOZ1BjBQAA3Uunip/i4mIlJSVpwoQJ7mUZGRmKiYnxuGCprq5WTU0NFywA3ObNm6fy8nI98cQT2rdvn9atW6dnnnnG/cp8i8WiuXPn6rHHHtOrr76qPXv26M4771RKSopuvvnm0AYPAADCmlevupa+eV6/uLhY06ZNU3T0v75us9k0Y8YM5efnq1+/foqPj9ecOXPkdDo1atQovwYNIHxdc8012rhxowoKCrRw4UKlpaVp2bJlmjp1qnubBx54QM3NzZo1a5YaGhp03XXXadOmTYqLiwth5AAAINx5Xfxs2bJFNTU1uvvuu09bt3TpUkVFRSk3N1cul0s5OTlasWKFXwIF0H1MnDhREydOPON6i8WihQsXauHChUGMCgAAdHdeFz/jxo2TMabDdXFxcSoqKlJRUZHPgQEAAACAP3X6bW8AAAAAEE4ofgAAAABEBIofAAAAABGB4gcAAABARKD4AQAAABARKH4AAAAARASKHwAAAAARgeIHAAAAQESg+AEAAAAQESh+AAAAAEQEih8AAAAAEYHiBwAAAEBEoPgBAAAAEBEofgAAAABEBIofAAAAABGB4gcAAABARKD4AQAAABARKH4AAAAARASvi58vvvhCd9xxhxITE9WzZ09dfvnl2rVrl3u9MUYPP/ywkpOT1bNnT2VnZ2vv3r1+DRoAAAAAvOVV8fPVV1/p2muvVUxMjN588019/PHH+uUvf6m+ffu6t1m8eLGWL1+uVatWqaKiQr169VJOTo5aWlr8HjwAAAAAnKtobzZ+8sknlZqaquLiYveytLQ09z8bY7Rs2TItWLBAkyZNkiQ999xzstvtevnll3X77bf7KWwAAAAA8I5Xd35effVVXX311brllluUlJSkq666Ss8++6x7/f79+1VXV6fs7Gz3MpvNpszMTJWVlXW4T5fLpaamJo8GAAAAAP7mVfHzl7/8RStXrtTQoUO1efNmzZ49Wz/+8Y/129/+VpJUV1cnSbLb7R7fs9vt7nWnKiwslM1mc7fU1NTO5AEgTPzsZz+TxWLxaOnp6e71LS0tysvLU2Jionr37q3c3FzV19eHMGIAANBdeFX8tLW1aeTIkXriiSd01VVXadasWZo5c6ZWrVrV6QAKCgrU2NjobrW1tZ3eF4DwcOmll+rQoUPutmPHDve6efPm6bXXXtOGDRtUWlqqgwcPavLkySGMFgAAdBdeFT/Jycm65JJLPJYNHz5cNTU1kiSHwyFJp/1f2vr6eve6U1mtVsXHx3s0AN1bdHS0HA6Hu/Xv31+S1NjYqDVr1mjJkiXKyspSRkaGiouLtXPnTpWXl4c4agBdBW+eBdBZXhU/1157raqrqz2Wffrppxo8eLCkb15+4HA4VFJS4l7f1NSkiooKOZ1OP4QLoDvYu3evUlJSNGTIEE2dOtX9P1Cqqqp0/Phxj3GD6enpGjRo0BnHDUqMHQQiCW+eBeALr972Nm/ePI0ePVpPPPGEbr31Vr377rt65pln9Mwzz0iSLBaL5s6dq8cee0xDhw5VWlqaHnroIaWkpOjmm28ORPwAwkxmZqbWrl2rYcOG6dChQ3r00Uf1rW99Sx9++KHq6uoUGxurhIQEj++cbdyg9M3YwUcffTTAkQPoCnjzLABfeHXn55prrtHGjRv1wgsv6LLLLtPPf/5zLVu2TFOnTnVv88ADD2jOnDmaNWuWrrnmGh07dkybNm1SXFyc34MHEH7Gjx+vW265RSNGjFBOTo7++Mc/qqGhQS+++GKn98nYQSBy8OZZAL7wqviRpIkTJ2rPnj1qaWnRJ598opkzZ3qst1gsWrhwoerq6tTS0qItW7bo4osv9lvAALqXhIQEXXzxxdq3b58cDodaW1vV0NDgsc3Zxg1KjB0EIglvngXgC6+LHwDwp2PHjumzzz5TcnKyMjIyFBMT4zFusLq6WjU1NYwbBCCJN88C8A3FD4Cguv/++1VaWqrPP/9cO3fu1Pe+9z316NFDU6ZMkc1m04wZM5Sfn6+3335bVVVVmj59upxOp0aNGhXq0AF0Abx5FoAvvHrhAQD46sCBA5oyZYq+/PJLDRgwQNddd53Ky8s1YMAASdLSpUsVFRWl3NxcuVwu5eTkaMWKFSGOGkBX4c2bZ6+88kpJ/3rz7OzZs4MdLoAuhuIHQFCtX7/+rOvj4uJUVFSkoqKiIEUEIJzw5lkAvqD4AQAAYaP9zbMFBQVauHCh0tLSOnzzbHNzs2bNmqWGhgZdd911vHkWgCSKHwAAEGYmTpyoiRMnnnF9+5tnFy5cGMSoAIQDXngAAAAAICJQ/AAAAACICBQ/AAAAACICxQ8AAACAiEDxAwAAACAiUPwAAAAAiAgUPwAAAAAiAsUPAAAAgIhA8QMAAAAgIlD8AAAAAIgIFD8AAAAAIgLFDwAAAICI4FXx87Of/UwWi8Wjpaenu9e3tLQoLy9PiYmJ6t27t3Jzc1VfX+/3oAEAAADAW17f+bn00kt16NAhd9uxY4d73bx58/Taa69pw4YNKi0t1cGDBzV58mS/BgwAAAAAnRHt9Reio+VwOE5b3tjYqDVr1mjdunXKysqSJBUXF2v48OEqLy/XqFGjfI8WAAAAADrJ6zs/e/fuVUpKioYMGaKpU6eqpqZGklRVVaXjx48rOzvbvW16eroGDRqksrKyM+7P5XKpqanJowEAAACAv3lV/GRmZmrt2rXatGmTVq5cqf379+tb3/qWjh49qrq6OsXGxiohIcHjO3a7XXV1dWfcZ2FhoWw2m7ulpqZ2KhEAAAAAOBuvHnsbP368+59HjBihzMxMDR48WC+++KJ69uzZqQAKCgqUn5/v/tzU1EQBBAAAAMDvfHrVdUJCgi6++GLt27dPDodDra2tamho8Nimvr6+wzFC7axWq+Lj4z0aAAAAAPibT8XPsWPH9Nlnnyk5OVkZGRmKiYlRSUmJe311dbVqamrkdDp9DhQAAAAAfOHVY2/333+/brzxRg0ePFgHDx7UI488oh49emjKlCmy2WyaMWOG8vPz1a9fP8XHx2vOnDlyOp286Q0AAABAyHl15+fAgQOaMmWKhg0bpltvvVWJiYkqLy/XgAEDJElLly7VxIkTlZubqzFjxsjhcOill14KSOAAwt+iRYtksVg0d+5c9zImSwYAAIHi1Z2f9evXn3V9XFycioqKVFRU5FNQALq/yspKrV69WiNGjPBYPm/ePL3xxhvasGGDbDab7r33Xk2ePFnvvPNOiCIFAADdhU9jfgCgM44dO6apU6fq2WefVd++fd3L2ydLXrJkibKyspSRkaHi4mLt3LlT5eXlIYwYAAB0BxQ/AIIuLy9PEyZM8JgUWWKyZAAAEFhePfYGAL5av3693nvvPVVWVp62zpfJkh999FF/hwoAALoZ7vwACJra2lrdd999ev755xUXF+e3/RYUFKixsdHdamtr/bZvAADQfVD8AAiaqqoqHT58WCNHjlR0dLSio6NVWlqq5cuXKzo6Wna7ncmSAQBAwPDYG4CgGTt2rPbs2eOxbPr06UpPT9eDDz6o1NRU92TJubm5kpgsGQAA+A/FD4Cg6dOnjy677DKPZb169VJiYqJ7OZMlAwCAQKH4AdClLF26VFFRUcrNzZXL5VJOTo5WrFgR6rAAAEA3QPEDIKS2bdvm8ZnJkgEAQKDwwgMAAAAAEYHiBwAAAEBEoPgBAAAAEBEofgAAAABEBIofAAAAABGB4gcAAABARKD4AQAAABARKH4AAAAARASKHwAAAAARwafiZ9GiRbJYLJo7d657WUtLi/Ly8pSYmKjevXsrNzdX9fX1vsYJAAAAAD7pdPFTWVmp1atXa8SIER7L582bp9dee00bNmxQaWmpDh48qMmTJ/scKAAAAAD4olPFz7FjxzR16lQ9++yz6tu3r3t5Y2Oj1qxZoyVLligrK0sZGRkqLi7Wzp07VV5e3uG+XC6XmpqaPBoAAAAA+Funip+8vDxNmDBB2dnZHsurqqp0/Phxj+Xp6ekaNGiQysrKOtxXYWGhbDabu6WmpnYmJAAAAAA4K6+Ln/Xr1+u9995TYWHhaevq6uoUGxurhIQEj+V2u111dXUd7q+goECNjY3uVltb621IAAAgQjH+GIA3vCp+amtrdd999+n5559XXFycXwKwWq2Kj4/3aAAAAP8O448BeMur4qeqqkqHDx/WyJEjFR0drejoaJWWlmr58uWKjo6W3W5Xa2urGhoaPL5XX18vh8Phz7gBAEAE8+f4YwCRw6viZ+zYsdqzZ492797tbldffbWmTp3q/ueYmBiVlJS4v1NdXa2amho5nU6/Bw8AACKTP8cf8/IlIHJEe7Nxnz59dNlll3ks69WrlxITE93LZ8yYofz8fPXr10/x8fGaM2eOnE6nRo0a5b+oAQCAVy6Y/4Zf9/f5ogl+3Z832scfV1ZWnrauM+OPCwsL9eijjwYiVABdjE+TnHZk6dKlmjhxonJzczVmzBg5HA699NJL/j4MAACIQIEYf8zLl4DI4dWdn45s27bN43NcXJyKiopUVFTk664BAAA8nDz+uN2JEye0fft2Pf3009q8ebN7/PHJd3/ONv7YarXKarUGOnQAXYDPxQ8AAECwtI8/Ptn06dOVnp6uBx98UKmpqe7xx7m5uZIYfwzgXyh+AABA2GD8MQBfUPwAAIBuZenSpYqKilJubq5cLpdycnK0YsWKUIcFoAvw+wsPAOBsVq5cqREjRrgnNXY6nXrzzTfd65mZHYC3tm3bpmXLlrk/t48/PnLkiJqbm/XSSy8x3yAASRQ/AIJs4MCBWrRokaqqqrRr1y5lZWVp0qRJ+uijjyQxMzsAAAgcHnsDEFQ33nijx+fHH39cK1euVHl5uQYOHKg1a9Zo3bp1ysrKkiQVFxdr+PDhKi8v53l9AADgE+78AAiZEydOaP369WpubpbT6ezUzOwSs7MDAIBzQ/EDIOj27Nmj3r17y2q16p577tHGjRt1ySWXdGpmdumb2dltNpu7paamBjgDAAAQjih+AATdsGHDtHv3blVUVGj27NmaNm2aPv74407vj9nZAQDAuWDMD4Cgi42N1UUXXSRJysjIUGVlpX71q1/ptttu83pmdonZ2QEAwLnhzg+AkGtra5PL5VJGRoZ7ZvZ2zMwOAAD8hTs/AIKqoKBA48eP16BBg3T06FGtW7dO27Zt0+bNm2Wz2ZiZHQAABAzFD4CgOnz4sO68804dOnRINptNI0aM0ObNm/Xd735XEjOzAwCAwKH4ARBUa9asOev69pnZi4qKghQRAACIFIz5AQAAABARKH4AAAAARASKHwAAAAARgeIHAAAAQETwqvhZuXKlRowYofj4eMXHx8vpdOrNN990r29paVFeXp4SExPVu3dv5ebmqr6+3u9BAwAAAIC3vCp+Bg4cqEWLFqmqqkq7du1SVlaWJk2apI8++kiSNG/ePL322mvasGGDSktLdfDgQU2ePDkggQMAAACAN7x61fWNN97o8fnxxx/XypUrVV5eroEDB2rNmjVat26dsrKyJEnFxcUaPny4ysvLzzhBocvlksvlcn9uamryNgcAAAAA+Lc6PebnxIkTWr9+vZqbm+V0OlVVVaXjx48rOzvbvU16eroGDRqksrKyM+6nsLBQNpvN3VJTUzsbEgAAAACckdfFz549e9S7d29ZrVbdc8892rhxoy655BLV1dUpNjZWCQkJHtvb7XbV1dWdcX8FBQVqbGx0t9raWq+TAAAAAIB/x6vH3iRp2LBh2r17txobG/WHP/xB06ZNU2lpaacDsFqtslqtnf4+AAAAAJwLr4uf2NhYXXTRRZKkjIwMVVZW6le/+pVuu+02tba2qqGhwePuT319vRwOh98CBgAAAIDO8Hmen7a2NrlcLmVkZCgmJkYlJSXuddXV1aqpqZHT6fT1MAAAAADgE6/u/BQUFGj8+PEaNGiQjh49qnXr1mnbtm3avHmzbDabZsyYofz8fPXr10/x8fGaM2eOnE7nGd/0BgAAAADB4lXxc/jwYd155506dOiQbDabRowYoc2bN+u73/2uJGnp0qWKiopSbm6uXC6XcnJytGLFioAEDgAAAADe8Kr4WbNmzVnXx8XFqaioSEVFRT4FBQAAAAD+5vOYHwAAAAAIBxQ/AAAAACICxQ8AAACAiEDxAwAAACAiUPwAAAAAiAgUPwAAAAAiAsUPAAAAgIhA8QMAAAAgIlD8AAiqwsJCXXPNNerTp4+SkpJ08803q7q62mOblpYW5eXlKTExUb1791Zubq7q6+tDFDEAAOguKH4ABFVpaany8vJUXl6ut956S8ePH9e4cePU3Nzs3mbevHl67bXXtGHDBpWWlurgwYOaPHlyCKMGAADdQXSoAwAQWTZt2uTxee3atUpKSlJVVZXGjBmjxsZGrVmzRuvWrVNWVpYkqbi4WMOHD1d5eblGjRoVirABAEA3wJ0fACHV2NgoSerXr58kqaqqSsePH1d2drZ7m/T0dA0aNEhlZWUd7sPlcqmpqcmjAQAAnIriB0DItLW1ae7cubr22mt12WWXSZLq6uoUGxurhIQEj23tdrvq6uo63E9hYaFsNpu7paamBjp0AAAQhih+AIRMXl6ePvzwQ61fv96n/RQUFKixsdHdamtr/RQhAADoThjzAyAk7r33Xr3++uvavn27Bg4c6F7ucDjU2tqqhoYGj7s/9fX1cjgcHe7LarXKarUGOmQAABDmuPMDIKiMMbr33nu1ceNGbd26VWlpaR7rMzIyFBMTo5KSEvey6upq1dTUyOl0BjtcAADQjXDnB0BQ5eXlad26dXrllVfUp08f9zgem82mnj17ymazacaMGcrPz1e/fv0UHx+vOXPmyOl08qY3AADgE4ofAEG1cuVKSdL111/vsby4uFh33XWXJGnp0qWKiopSbm6uXC6XcnJytGLFiiBHCgAAuhuvHntjZnYAvjLGdNjaCx9JiouLU1FRkY4cOaLm5ma99NJLZxzvAwAAcK68Kn6YmR0AAABAuPKq+Nm0aZPuuusuXXrppbriiiu0du1a1dTUqKqqSpLcM7MvWbJEWVlZysjIUHFxsXbu3Kny8vIO98nkhAAA4FzxFAoAX/j0tjd/zMzO5IQAAOBc8RQKAF90+oUH/pqZvaCgQPn5+e7PTU1NFEAAAKBDmzZt8vi8du1aJSUlqaqqSmPGjHE/hbJu3TplZWVJ+uaFKsOHD1d5eTlvjQQiXKeLn/aZ2Xfs2OFTAExOCAAAOsvbp1A6Kn5cLpdcLpf7M4/gA91Xpx57a5+Z/e233z7jzOwnO9vM7AAAAJ3hr6dQeAQfiBxeFT/MzA4AALqK9qdQ1q9f79N+CgoK1NjY6G61tbV+ihBAV+PVY2/MzA4AALqC9qdQtm/ffsanUE6++3O2p1B4BB+IHF4VP8zMDoTGBfPf8Ps+P180we/7BIBAM8Zozpw52rhxo7Zt23bWp1Byc3Ml8RQKgH/xqvgxxvzbbdpnZi8qKup0UAAAAB3hKRQAvuj0294AAACCjadQAPiC4gcAAIQNnkIB4ItOveoaAAAAAMINxQ8AAACAiEDxAwAAACAiUPwAAAAAiAi88AAAAMAH/p6LjXnYgMDhzg8AAACAiEDxAwAAACAiUPwAAAAAiAgUPwAAAAAiAsUPAAAAgIhA8QMAAAAgIlD8AAiq7du368Ybb1RKSoosFotefvllj/XGGD388MNKTk5Wz549lZ2drb1794YmWAAA0K1Q/AAIqubmZl1xxRUqKirqcP3ixYu1fPlyrVq1ShUVFerVq5dycnLU0tIS5EgBAEB3wySnAIJq/PjxGj9+fIfrjDFatmyZFixYoEmTJkmSnnvuOdntdr388su6/fbbO/yey+WSy+Vyf25qavJ/4AAAIOxx5wdAl7F//37V1dUpOzvbvcxmsykzM1NlZWVn/F5hYaFsNpu7paamBiNcAAAQZih+AHQZdXV1kiS73e6x3G63u9d1pKCgQI2Nje5WW1sb0DgBAEB48rr4YbAygK7GarUqPj7eowEAAJzK6+KHwcoAAsXhcEiS6uvrPZbX19e71wEAAHSW1y888PdgZQYqA2iXlpYmh8OhkpISXXnllZK+6RMqKio0e/bs0AYHAADCnl/H/HRmsDIDlYHIcuzYMe3evVu7d++W9E2/sXv3btXU1MhisWju3Ll67LHH9Oqrr2rPnj268847lZKSoptvvjmkcQMAgPDn11ddd2awckFBgfLz892fm5qaKICAbmzXrl36zne+4/7c/vufNm2a1q5dqwceeEDNzc2aNWuWGhoadN1112nTpk2Ki4sLVcgAAKCbCPk8P1arVVarNdRhAAiS66+/XsaYM663WCxauHChFi5cGMSoAABAJPDrY28MVgYAAADQVfm1+Dl5sHK79sHKTqfTn4cCAAAAAK94/djbsWPHtG/fPvfn9sHK/fr106BBg9yDlYcOHaq0tDQ99NBDDFYGAAAAEHJeFz8MVgYAAAAQjrwufhisDAAAACAc+XXMDwAAAAB0VRQ/AAAAACICxQ8AAACAiEDxAwAAACAieP3Cg67mgvlv+HV/ny+a4Nf9AQAAAOgauPMDAAAAICJQ/AAAAACICGH/2BsAAACAwPL3UBMpNMNNuPMDAAAAICJQ/AAAAACICBQ/AAAAACICxQ8AAACAiEDxAwAAACAiUPwAAAAAiAgUPwAAAAAiAvP8AIho3WXeAgAA8O9x5wcAAABARKD4AQAAABARAlb8FBUV6YILLlBcXJwyMzP17rvvBupQALoh+hAAvqIfAXCqgBQ///3f/638/Hw98sgjeu+993TFFVcoJydHhw8fDsThAHQz9CEAfEU/AqAjAXnhwZIlSzRz5kxNnz5dkrRq1Sq98cYb+s1vfqP58+d7bOtyueRyudyfGxsbJUlNTU3ndKw219d+ilpeHRf/nr//NlLk/n1C9e+yfRtjjN+Pfzbe9CGSb/0I52nXxt/Hf0L138tw6Ee4Fum+6EP8p9tcixg/c7lcpkePHmbjxo0ey++8805z0003nbb9I488YiTRaLQu3Gpra/3dVZyRt32IMfQjNFo4tK7cj9CH0Ghdv/mrD/H7nZ+///3vOnHihOx2u8dyu92uP//5z6dtX1BQoPz8fPfntrY2HTlyRImJibJYLGc9VlNTk1JTU1VbW6v4+Hj/JBBC3Smf7pSLFLn5GGN09OhRpaSkBC02b/sQqfP9SKT+XcMF+XRd3uQSDv0I1yL/0p3y6U65SJGbj7/7kJDP82O1WmW1Wj2WJSQkeLWP+Pj4bnEStOtO+XSnXKTIzMdmswUpms7ztR+JxL9rOCGfrutcc+nq/QjXIqfrTvl0p1ykyMzHn32I31940L9/f/Xo0UP19fUey+vr6+VwOPx9OADdDH0IAF/RjwA4E78XP7GxscrIyFBJSYl7WVtbm0pKSuR0Ov19OADdDH0IAF/RjwA4k4A89pafn69p06bp6quv1n/8x39o2bJlam5udr9xxV+sVqseeeSR025Vh6vulE93ykUin2CjD+kc8unaulM+4ZAL/UjndKd8ulMuEvn4i8WYwLx78umnn9YvfvEL1dXV6corr9Ty5cuVmZkZiEMB6IboQwD4in4EwKkCVvwAAAAAQFfi9zE/AAAAANAVUfwAAAAAiAgUPwAAAAAiAsUPAAAAgIgQkuLnZz/7mSwWi0dLT093r//ss8/0ve99TwMGDFB8fLxuvfXW0yYqO3LkiKZOnar4+HglJCRoxowZOnbs2FmP29LSory8PCUmJqp3797Kzc09bb/hlM/1119/2nHvueeeLpHP448/rtGjR+u8884751myjTF6+OGHlZycrJ49eyo7O1t79+4Ny1zuuuuu0457ww03+JSLP/L5/PPPNWPGDKWlpalnz5668MIL9cgjj6i1tfWsxw3Ub8dfFi1aJIvForlz53osLysrU1ZWlnr16qX4+HiNGTNG//jHPzy2eeONN5SZmamePXuqb9++uvnmm896rECcp6HMJ1Dnqq/5bNu27bS42ltlZeUZjxWMczWY+QSqn/clF0n69NNPNWnSJPXv31/x8fG67rrr9Pbbb5/1WMH47Xhj5cqVGjFihHt2eafTqTfffNO9PtyuRUKVT6DOUX/k01WuRUKVS6D6d1/zCfW1SMju/Fx66aU6dOiQu+3YsUOS1NzcrHHjxslisWjr1q1655131NraqhtvvFFtbW3u70+dOlUfffSR3nrrLb3++uvavn27Zs2addZjzps3T6+99po2bNig0tJSHTx4UJMnTw7bfCRp5syZHsddvHhxl8intbVVt9xyi2bPnn3Ox1y8eLGWL1+uVatWqaKiQr169VJOTo5aWlrCLhdJuuGGGzyO+8ILL/iUhz/y+fOf/6y2tjatXr1aH330kZYuXapVq1bpv/7rv856zED+dnxVWVmp1atXa8SIER7Ly8rKdMMNN2jcuHF69913VVlZqXvvvVdRUf/q9v7nf/5H//mf/6np06frgw8+0DvvvKPvf//7Zz1eoM7TUOUjBe5c9SWf0aNHe8R06NAh/eAHP1BaWpquvvrqMx4v0OdqsPORAtfP+3KuTZw4Uf/85z+1detWVVVV6YorrtDEiRNVV1d3xuMF+rfjrYEDB2rRokWqqqrSrl27lJWVpUmTJumjjz4Ky2uRUOUjBeYc9Uc+XeVaJFS5SIHp333NJ+TXIiYEHnnkEXPFFVd0uG7z5s0mKirKNDY2upc1NDQYi8Vi3nrrLWOMMR9//LGRZCorK93bvPnmm8ZisZgvvviiw/02NDSYmJgYs2HDBveyTz75xEgyZWVlYZePMcZ8+9vfNvfdd59PsXfE13xOVlxcbGw22789Zltbm3E4HOYXv/iFx36tVqt54YUXvM6hXShyMcaYadOmmUmTJnUi4rPzZz7tFi9ebNLS0s64PpC/HV8dPXrUDB061Lz11lun/R4yMzPNggULzvjd48ePm/PPP9/8+te/PufjBeo8bRfsfIwJ3LlqjG/5nKq1tdUMGDDALFy48IzbBPpcDXY+xgSun/cll7/97W9Gktm+fbt7WVNTk5F0xr4m0L8df+nbt6/59a9/HZbXIqHIx5jAnaMd8Safk4X6WqQjgc7FmMD276fqbD7tgnktErI7P3v37lVKSoqGDBmiqVOnqqamRpLkcrlksVg8ZnuNi4tTVFSU+/9wl5WVKSEhweP/lmVnZysqKkoVFRUdHq+qqkrHjx9Xdna2e1l6eroGDRqksrKysMun3fPPP6/+/fvrsssuU0FBgb7++mufc/E1n87Yv3+/6urqPP4+NptNmZmZPv99gp1Lu23btikpKUnDhg3T7Nmz9eWXX/q8T8n/+TQ2Nqpfv35nXB/o344v8vLyNGHCBI/YJOnw4cOqqKhQUlKSRo8eLbvdrm9/+9se/x7ee+89ffHFF4qKitJVV12l5ORkjR8/Xh9++OEZjxfI8zQU+bQL1LnqSz6nevXVV/Xll19q+vTpZ9wm0OdqsPNpF4h+3pdcEhMTNWzYMD333HNqbm7WP//5T61evVpJSUnKyMjo8HiB/u346sSJE1q/fr2am5vldDrD9lok2Pm0C9S1iC/5dEYwztNg5dIuUP17O3/lE8xrkZAUP5mZmVq7dq02bdqklStXav/+/frWt76lo0ePatSoUerVq5cefPBBff3112pubtb999+vEydO6NChQ5Kkuro6JSUleewzOjpa/fr1O+Mt97q6OsXGxp72nKTdbj/rbfqumo8kff/739fvf/97vf322yooKNDvfvc73XHHHT7l4o98OqM9T7vd7rHc179PKHKRvrnN/Nxzz6mkpERPPvmkSktLNX78eJ04ccKn/fo7n3379umpp57SD3/4wzMeM5C/HV+sX79e7733ngoLC09b95e//EXSN2OkZs6cqU2bNmnkyJEaO3as+9ntk7dZsGCBXn/9dfXt21fXX3+9jhw50uExA3WehiofKXDnqq/5nGrNmjXKycnRwIEDz3jMQJ6rochHCkw/72suFotFW7Zs0fvvv68+ffooLi5OS5Ys0aZNm9S3b98OjxnI344v9uzZo969e8tqteqee+7Rxo0bdckll4TltUgo8pECdy3iaz6dEcjzNNi5SIHr3/2dT9CvRby6TxQgX331lYmPj3c/rrF582YzZMgQY7FYTI8ePcwdd9xhRo4cae655x5jjDGPP/64ufjii0/bz4ABA8yKFSs6PMbzzz9vYmNjT1t+zTXXmAceeMCP2QQnn46UlJQYSWbfvn3+SeT/8zafk53r7dl33nnHSDIHDx70WH7LLbeYW2+91S95GBOcXDry2WefGUlmy5YtvoR/Gl/yOXDggLnwwgvNjBkzznqMYP52zlVNTY1JSkoyH3zwgXvZyY9etJ9PBQUFHt+7/PLLzfz5840x3+Qlyaxevdq9vqWlxfTv39+sWrWqw+MG6jwNVT4d8ce56o98TlZbW2uioqLMH/7wh7MeN1Dnaqjy6Yiv/bw/cmlrazM33XSTGT9+vNmxY4epqqoys2fPNueff/5pv412werjveVyuczevXvNrl27zPz5803//v3NRx99ZIwJz2uRYOfTEX9ei/iSz8m6wrVIsHPpiD+vRfyVTyiuRaK9K5UCIyEhQRdffLH27dsnSRo3bpw+++wz/f3vf1d0dLQSEhLkcDg0ZMgQSZLD4dDhw4c99vHPf/5TR44ckcPh6PAYDodDra2tamho8Kga6+vrz/idrpxPRzIzMyV9U0FfeOGFfsrG+3w6oz3P+vp6JScnu5fX19fryiuv9Cn+kwUjl44MGTJE/fv31759+zR27Fi/7bez+Rw8eFDf+c53NHr0aD3zzDNnPUYwfzvnqqqqSocPH9bIkSPdy06cOKHt27fr6aefVnV1tSTpkksu8fje8OHD3Y8Jtp9nJ29jtVo1ZMgQ9zanCtR5Gqp8OuKPc9Uf+ZysuLhYiYmJuummm8563ECdq6HKpyO+9vP+yGXr1q16/fXX9dVXXyk+Pl6StGLFCr311lv67W9/q/nz55923GD18d6KjY3VRRddJEnKyMhQZWWlfvWrX2n16tVheS0S7Hw64s9rEV/y6YxAnqfBzqUj/rwW8Uc+oboW6RLz/Bw7dkyfffaZx4kmSf3791dCQoK2bt2qw4cPu/9D4XQ61dDQoKqqKve2W7duVVtbm/tHd6qMjAzFxMSopKTEvay6ulo1NTVyOp1hl09Hdu/eLUmnHddX3ubTGWlpaXI4HB5/n6amJlVUVPj17xOMXDpy4MABffnll13ib/PFF1/o+uuvV0ZGhoqLiz3e4NSRYP52ztXYsWO1Z88e7d69292uvvpqTZ06Vbt379aQIUOUkpLivpBr9+mnn2rw4MGSvsnLarV6bHP8+HF9/vnn7m1OFajzNFT5dMQf56o/8mlnjFFxcbHuvPNOxcTEnPW4gTpXQ5VPR3zt5/2RS/t4jlP7jqioKI+3U50sWH28r9ra2uRyuTyWheu1SDDy6UigrkUk7/LpjGCep4HOpSOBuhaRvM8npNciXt0n8pOf/OQnZtu2bWb//v3mnXfeMdnZ2aZ///7m8OHDxhhjfvOb35iysjKzb98+87vf/c7069fP5Ofne+zjhhtuMFdddZWpqKgwO3bsMEOHDjVTpkxxrz9w4IAZNmyYqaiocC+75557zKBBg8zWrVvNrl27jNPpNE6nMyzz2bdvn1m4cKHZtWuX2b9/v3nllVfMkCFDzJgxY7pEPn/961/N+++/bx599FHTu3dv8/7775v333/fHD161L3NsGHDzEsvveT+vGjRIpOQkGBeeeUV86c//clMmjTJpKWlmX/84x9hlcvRo0fN/fffb8rKysz+/fvNli1bzMiRI83QoUNNS0tLp3PxRz4HDhwwF110kRk7dqw5cOCAOXTokLudvE2wfjv+dOobh5YuXWri4+PNhg0bzN69e82CBQtMXFycx6MY9913nzn//PPN5s2bzZ///GczY8YMk5SUZI4cOeLeJhjnaajyCeS56o98jDFmy5YtRpL55JNPTttnKM/VYOQTyH7el1z+9re/mcTERDN58mSze/duU11dbe6//34TExNjdu/e7d5PqH4752r+/PmmtLTU7N+/3/zpT38y8+fPNxaLxfzv//6vMSb8rkVCkU8gz1F/5NNVrkVCkUsg+3df8wn1tUhIip/bbrvNJCcnm9jYWHP++eeb2267zeM/EA8++KCx2+0mJibGDB061Pzyl780bW1tHvv48ssvzZQpU0zv3r1NfHy8mT59uscJsH//fiPJvP322+5l//jHP8yPfvQj07dvX3PeeeeZ733vex7/osMpn5qaGjNmzBjTr18/Y7VazUUXXWR++tOferxaMJT5TJs2zUg6rZ3895BkiouL3Z/b2trMQw89ZOx2u7FarWbs2LGmuro67HL5+uuvzbhx48yAAQNMTEyMGTx4sJk5c6apq6vzKRd/5FNcXNxhLif/f5Bg/nb8qaPXrRYWFpqBAwea8847zzidTvN///d/HutbW1vNT37yE5OUlGT69OljsrOzzYcffuixTTDO01DlE8hz1R/5GGPMlClTzOjRozvcZyjP1WDkE8h+3tdcKisrzbhx40y/fv1Mnz59zKhRo8wf//hHj21C9ds5V3fffbcZPHiwiY2NNQMGDDBjx451X7wZE37XIqHIJ5DnqD/y6SrXIqHIJZD9u6/5hPpaxGKMMd7dKwIAAACA8NMlxvwAAAAAQKBR/AAAAACICBQ/AAAAACICxQ8AAACAiEDxAwAAACAiUPwAAAAAiAgUPwAAAAAiAsUPAAAAgIhA8QMAAAAgIlD8AAAAAIgIFD8AAAAAIsL/Ayf4L7pNE62wAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 3))\n",
    "ax[0].hist(plot_results())\n",
    "ax[1].hist(plot_results(exp_var=0.95))\n",
    "ax[2].hist(plot_results(exp_var=0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601559f6-0a40-40bb-830e-a836a35c5a5b",
   "metadata": {},
   "source": [
    "The above results indicate the rank is very tightly distributed based on the explained variance. The reader is encouraged to play with the explained_variance and support the claim themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41538748-3d56-4a69-a5f6-aa4f2e98f146",
   "metadata": {},
   "source": [
    "## Analysis of RoBERTa pre-trained Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "373c7b6d-5ccd-447e-b545-7349e19e7e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Now let's look at how tightly the weights are distributed in RoBERTa \n",
    "from transformers import AutoModelForQuestionAnswering, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a18bc9a7-0c31-41be-970e-e37992303f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract RoBERTa Configuration\n",
    "roberta_base_config = AutoConfig.from_pretrained('roberta-base')\n",
    "roberta_large_config = AutoConfig.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acf40d4d-e557-4b8c-a6ec-fe8725910263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract RoBERTa Model\n",
    "roberta_base_model = AutoModelForQuestionAnswering.from_config(roberta_base_config)\n",
    "roberta_large_model = AutoModelForQuestionAnswering.from_config(roberta_large_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dd7956d-48ca-4f5f-96e1-72ca43118c2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract Variances for a given set of explained variances\n",
    "def get_model_principle_direction(model, exp_vars):\n",
    "    principle_dirs = []\n",
    "    for key, param in model.named_parameters():\n",
    "        with torch.no_grad():\n",
    "            p_size = min(param.size())\n",
    "            \n",
    "            if len(param.size()) < 2:\n",
    "                continue\n",
    "                \n",
    "            curr_principle_dirs = get_principle_directions(param, exp_vars)\n",
    "            curr_principle_dirs = torch.tensor(curr_principle_dirs) / p_size\n",
    "            \n",
    "            if torch.any(curr_principle_dirs == 0):\n",
    "                continue\n",
    "                \n",
    "            principle_dirs.append(curr_principle_dirs)\n",
    "    \n",
    "    return torch.stack(principle_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6379350c-f84f-41e2-bd2e-da56058431bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variances = [0.1, 0.3, 0.5, 0.7, 0.9, 0.95, 0.99]\n",
    "roberta_base_dirs = get_model_principle_direction(roberta_base_model, explained_variances)\n",
    "roberta_large_dirs = get_model_principle_direction(roberta_large_model, explained_variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bbc96cf-cb21-400e-bff7-d1d2ad1d1cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))\n",
    "ax.errorbar(explained_variances, roberta_base_dirs.mean(dim=0).tolist(), yerr= roberta_base_dirs.std(dim=0).tolist(), label=\"RoBERTa Base\", color='r', capsize=2)\n",
    "ax.errorbar(explained_variances, roberta_large_dirs.mean(dim=0).tolist(), yerr= roberta_base_dirs.std(dim=0).tolist(), label=\"RoBERTa Large\", color='b', capsize=2)\n",
    "ax.set_xlabel(\"Explained Ratio\")\n",
    "ax.set_ylabel(\"Directions Considered\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a39e3e-2c84-458e-a47f-5e5a86443278",
   "metadata": {},
   "source": [
    "The above results suggest you need most of the directions to account for the explained variance in the parameters.\n",
    "As such, we finetune the models for SQuAD and review the difference in the weights of the base and the tuned model. If the difference has \n",
    "fewer principle directions with high explanation, it would mean it is possible that task-based fine-tuning can be done in a smaller subspace.\n",
    "Let's add a final touch to the above results by looking at the ratio of number of significant principle directions and all directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a1ff52-126c-4665-92fd-c3e5d8c83fb2",
   "metadata": {},
   "source": [
    "## Rank Variation During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d59c3413-b156-4dfd-a1f5-1df488ff818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dataset\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from train.train import train_epoch\n",
    "from utils.metrics import AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "719ff899-edf9-4f7e-b665-ea440ef6bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Training Configuration\n",
    "with hydra.initialize(version_base=None, config_path=\"../config\"):\n",
    "    cfg = hydra.compose(config_name=\"app_config\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9efb6c9-3495-4760-9c2b-094fa47b98bd",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "552abb28-447c-4920-ab41-1cf2e93bce6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'squad', 'load_from_disk': True, 'save_to_disk': True}\n"
     ]
    }
   ],
   "source": [
    "# load Dataset Config\n",
    "dataset_cfg = cfg.dataset\n",
    "print(dataset_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4b82e45-bb22-4aea-b6ac-1c2ef67ab9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33cdf8034d1c4d13a1705f2dd07c747c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathadoor/Documents/peft-study/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Process Data\n",
    "if dataset_cfg.load_from_disk:\n",
    "    train_dataset = load_from_disk(f\"../data/{dataset_cfg.name}\")\n",
    "else:\n",
    "    train_dataset = load_dataset(f\"{dataset_cfg.name}\", split=\"train\")\n",
    "val_dataset = load_dataset(f\"{dataset_cfg.name}\", split=\"validation\")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0bab19-fe5f-41d3-a4c8-282bbda8647d",
   "metadata": {},
   "source": [
    "#### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76dfbf26-bbad-4d73-933a-652dded44c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Max Length is 512\n",
      "Dataset Features are {'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'start_positions': Value(dtype='int64', id=None), 'end_positions': Value(dtype='int64', id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model Max Length is {tokenizer.model_max_length}\")\n",
    "print(f\"Dataset Features are {train_dataset.features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c89dd9c-1957-45c8-8461-e69b41717cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to Remove\n",
    "remove_columns=['question', 'context', 'id', 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19b45799-1fa8-4ed4-a7c2-b3004997e9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_off_length = 512\n",
    "if not dataset_cfg.load_from_disk:\n",
    "    long_dataset = train_dataset.filter(lambda x: len(tokenizer(x['question'], x['context']).input_ids) > cut_off_length)\n",
    "    print(f\"There are {long_dataset.num_rows} training instances with length longer than {cut_off_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932bb38a-5b28-4dbd-9faa-0aa9571a02e7",
   "metadata": {},
   "source": [
    "Since there are only 143 instances with the length longer than 512. I will remove those instances for the purpose of simplicity. These changes are unlikely to affect the outcome. The learned concept will not account for\n",
    "the cases in which the context may not contain the answer. Also, if there is a regularity in the placement of the answer in the question, the model may over fit to it. But given large number of samples, I assume it is not\n",
    "the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "119e8460-86c9-40d3-8fdb-2ac52d692766",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not dataset_cfg.load_from_disk:\n",
    "    train_dataset = train_dataset.filter(lambda x: len(tokenizer(x['question'], x['context']).input_ids) <= cut_off_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5a48aac-08b5-4e92-bad3-eac07df2633c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "    num_rows: 87456\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5dbd6078-c403-46ae-9aee-abd56889548b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "['a copper statue of Christ']\n"
     ]
    }
   ],
   "source": [
    "## Let's See how the answer looks like\n",
    "idx = 1\n",
    "instance = train_dataset[idx]\n",
    "answer = instance['answers']\n",
    "print(answer['answer_start'][0])\n",
    "print(answer['text'])\n",
    "if not dataset_cfg.load_from_disk:\n",
    "    print(instance['context'][answer['answer_start'][0]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae666051-6c8c-4e42-995e-adc84cef27fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above indicates the answer_start is the beginning character. Let's see if this is consistent with the rest of the results\n",
    "if not dataset_cfg.load_from_disk:\n",
    "    char_tokenizer = True\n",
    "    for idx, item in enumerate(train_dataset):\n",
    "        start = item['answers']['answer_start'][0]\n",
    "        end = start + len(item['answers']['text'][0])\n",
    "        extracted_answer = item['context'][start:end]\n",
    "        answer = item['answers']['text'][0]\n",
    "        if extracted_answer != answer:\n",
    "            print(idx, extracted_answer, answer)\n",
    "        if char_tokenizer:\n",
    "            tokenized_answer = tokenizer(answer).input_ids\n",
    "            char_tokenizer = len(tokenized_answer) - 2 == len(answer)\n",
    "    \n",
    "    if not char_tokenizer:\n",
    "        print(\"Tokenizer is not character based\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c37f437-6dbf-4a61-a180-42285188b5c2",
   "metadata": {},
   "source": [
    "The above result confirms that the answers are made available in terms of character offset instead of tokenizer offset. This is likely the case to maintain generality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1e3db4e-f142-4acd-ae85-0ff707c3384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisect_custom(l, r, tokenizer, tokenized_context, target, l_off=0, r_off=0, mid_off=0):\n",
    "    # Standard Binary Search with a Few Bells and Whistles\n",
    "    while l < r:\n",
    "        mid = l + (r - l + mid_off) // 2\n",
    "        partial_context = tokenizer.decode(tokenized_context[:mid])\n",
    "        if len(partial_context) <= target:\n",
    "            l = mid + l_off\n",
    "        else:\n",
    "            r = mid + r_off\n",
    "        # print(r, l, mid)\n",
    "    return max(l, r)\n",
    "\n",
    "def get_start_end_index(tokenized_context, answer, answer_start):\n",
    "    # Set Answer End Index\n",
    "    answer_end = answer_start + len(answer)\n",
    "\n",
    "    # Search for the starting index of the Token That contains the answer\n",
    "    ll, rl = 0, len(tokenized_context)\n",
    "    # print(\"Starting Left Search\")\n",
    "    start_index = bisect_custom(ll, rl, tokenizer, tokenized_context, answer_start, r_off=-1, mid_off=1)\n",
    "\n",
    "    # Search for the ending index of the tokens in which the answer terminates\n",
    "    rl, rr = start_index, len(tokenized_context)\n",
    "    # print(\"Starting Right Search\")\n",
    "    end_index = bisect_custom(start_index, len(tokenized_context), tokenizer, tokenized_context, answer_end, l_off=1)\n",
    "    \n",
    "    return start_index, end_index\n",
    "\n",
    "def validate(tokenized_context, start_index, end_index, idx, answer, context, question, ret):\n",
    "    # Test if the correct Solution is found by extracting the partial context and checking if the answer is contained.\n",
    "    # While this is not a 100% foolproof solution. Informal tests before confirmed this to be the case.\n",
    "    # You can set the extracted_answers char offset to answer_start\n",
    "    extracted_context = tokenized_context[start_index:end_index]\n",
    "    extracted_answer = tokenizer.decode(extracted_context).strip()\n",
    "    \n",
    "    if extracted_answer.find(answer) == -1:\n",
    "        failed_instance = {\"idx\" : idx, \n",
    "                           \"start_index\" : start_index,\n",
    "                           \"end_index\" : end_index,\n",
    "                           \"extracted_answer\" : extracted_answer,\n",
    "                           \"answer\" : answer,\n",
    "                           \"context\" : context,\n",
    "                           \"question\" : question} \n",
    "        ret.append(failed_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be31a5ad-b61e-475d-874e-db47e377ea5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0fbe8f9e864452699ffef3c1a1348da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'question'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m failed_indices \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, item \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(train_dataset)):\n\u001b[0;32m----> 4\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m     context \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m     answer \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswers\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'question'"
     ]
    }
   ],
   "source": [
    "# Let's tokenize the start and end character\n",
    "failed_indices = []\n",
    "for idx, item in tqdm(enumerate(train_dataset)):\n",
    "    question = item['question']\n",
    "    context = item['context']\n",
    "    \n",
    "    answer = item['answers']['text'][0]\n",
    "    answer_start = item['answers']['answer_start'][0]\n",
    "\n",
    "    # Extract Start and End Index of the Tokenized Question/Context Duo\n",
    "    tokenized_question = tokenizer(question).input_ids\n",
    "    tokenized_context = tokenizer(question, context).input_ids\n",
    "    start_index, end_index = get_start_end_index(tokenized_context, answer, answer_start + len(question) + 10)\n",
    "\n",
    "    # Test if the correct Solution is found\n",
    "    validate(tokenized_context, start_index, end_index, idx, answer, context, question, failed_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d26eb5e8-1043-40ff-8920-b8693db68547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 failed instances by the above method\n"
     ]
    }
   ],
   "source": [
    "print(fr\"There are {len(failed_indices)} failed instances by the above method\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "726329a5-b44d-4615-9c2c-35ac09a49789",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_failed_instances = []\n",
    "\n",
    "def process_batched_training_examples(instances):\n",
    "    questions, contexts = instances['question'], instances['context']\n",
    "    answers = instances['answers']\n",
    "    \n",
    "    inputs = tokenizer(questions, contexts) # Batched Tokenization\n",
    "    start_index, end_index = [], [] # Store the start and end_index in the beginning\n",
    "    \n",
    "    for idx, instance in enumerate(instances['id']):\n",
    "        answer_text, answer_start = answers[idx]['text'][0], answers[idx]['answer_start'][0]\n",
    "\n",
    "        start, end = get_start_end_index(inputs.input_ids[idx], answer_text, answer_start + len(questions[idx]) + 10)\n",
    "        \n",
    "        start_index.append(start)\n",
    "        end_index.append(end)\n",
    "\n",
    "        # Result Validation and storing the ones that failed. - map failed instances must be cleared every time to avoid accumulation\n",
    "        validate(inputs.input_ids[idx], start, end, 0, answer_text, contexts[idx], questions[idx], map_failed_instances)\n",
    "\n",
    "    inputs['start_positions'] = start_index\n",
    "    inputs['end_positions'] = end_index\n",
    "\n",
    "    return inputs\n",
    "\n",
    "def process_training_examples(instance):\n",
    "    \n",
    "    question, context = instance['question'], instance['context']\n",
    "    answer = instance['answers']\n",
    "    \n",
    "    inputs = tokenizer(question, context)\n",
    "    \n",
    "    answer_text, answer_start = answer['text'][0], answer['answer_start'][0]\n",
    "\n",
    "    start_index, end_index = get_start_end_index(inputs.input_ids, answer_text, answer_start + len(question) + 10)\n",
    "    \n",
    "    inputs['start_positions'] = start_index\n",
    "    inputs['end_positions'] = end_index\n",
    "\n",
    "    # Result Validation and storing the ones that failed. - map failed instances must be cleared every time to avoid accumulation\n",
    "    validate(inputs.input_ids, start_index, end_index, 0, answer_text, context, question, map_failed_instances)\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ca9b2a1-63df-4897-b8bc-a91e46ef61ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Column to remove ['context', 'id', 'title', 'question'] not in the dataset. Current columns in the dataset: ['answers', 'input_ids', 'attention_mask', 'start_positions', 'end_positions']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocess_batched_training_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/peft-study/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/peft-study/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/peft-study/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:3087\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3085\u001b[0m     missing_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(remove_columns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names)\n\u001b[1;32m   3086\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing_columns:\n\u001b[0;32m-> 3087\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3088\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn to remove \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(missing_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3089\u001b[0m         )\n\u001b[1;32m   3091\u001b[0m load_from_cache_file \u001b[38;5;241m=\u001b[39m load_from_cache_file \u001b[38;5;28;01mif\u001b[39;00m load_from_cache_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_caching_enabled()\n\u001b[1;32m   3093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Column to remove ['context', 'id', 'title', 'question'] not in the dataset. Current columns in the dataset: ['answers', 'input_ids', 'attention_mask', 'start_positions', 'end_positions']"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    process_batched_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=remove_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b02930ef-a55b-44fb-9795-1bb44475e351",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "Tried to overwrite /home/mathadoor/Documents/peft-study/data/squad but a dataset can't overwrite itself.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset_cfg\u001b[38;5;241m.\u001b[39msave_to_disk:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_to_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdataset_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/peft-study/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:1534\u001b[0m, in \u001b[0;36mDataset.save_to_disk\u001b[0;34m(self, dataset_path, fs, max_shard_size, num_shards, num_proc, storage_options)\u001b[0m\n\u001b[1;32m   1532\u001b[0m     \u001b[38;5;66;03m# Check that the dataset doesn't overwrite iself. It can cause a permission error on Windows and a segfault on linux.\u001b[39;00m\n\u001b[1;32m   1533\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Path(dataset_path)\u001b[38;5;241m.\u001b[39mexpanduser()\u001b[38;5;241m.\u001b[39mresolve() \u001b[38;5;129;01min\u001b[39;00m parent_cache_files_paths:\n\u001b[0;32m-> 1534\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mPermissionError\u001b[39;00m(\n\u001b[1;32m   1535\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to overwrite \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPath(dataset_path)\u001b[38;5;241m.\u001b[39mexpanduser()\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but a dataset can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt overwrite itself.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1536\u001b[0m         )\n\u001b[1;32m   1538\u001b[0m fs\u001b[38;5;241m.\u001b[39mmakedirs(dataset_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1540\u001b[0m \u001b[38;5;66;03m# Get json serializable state\u001b[39;00m\n",
      "\u001b[0;31mPermissionError\u001b[0m: Tried to overwrite /home/mathadoor/Documents/peft-study/data/squad but a dataset can't overwrite itself."
     ]
    }
   ],
   "source": [
    "if dataset_cfg.save_to_disk:\n",
    "    train_dataset.save_to_disk(f\"../data/{dataset_cfg.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d4e98-7a06-4fdc-92d4-8177b5e558b0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cadb715-65dc-4ddd-a0e3-11368be102d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 10570\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.filter(lambda x: len(x['answers']) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72715268-e5d5-47f1-b96a-638573644aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = val_dataset.filter(lambda x: len(tokenizer(x['question'], x['context']).input_ids) <= cut_off_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ddd2ee3-809f-462f-9963-2f47d26673a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_validation_examples(instances):\n",
    "    questions, contexts = instances['question'], instances['context']\n",
    "    inputs = tokenizer(questions, contexts) # Batched Tokenization\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e4e51ad-b3b3-41c0-b0c6-637170f18a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = val_dataset.map(\n",
    "    process_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=remove_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e24b2996-8eea-4b7e-8241-530ad19a4b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['answers', 'input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "print(val_dataset[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a31482-ff23-4244-8f81-6f9656ac8a15",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab63ac41-7dca-4d80-a70a-cbcec6a5e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict\n",
    "pad_keys = ['input_ids', 'attention_mask']\n",
    "stack_keys = [ 'start_positions', 'end_positions']\n",
    "pad_id = tokenizer.pad_token_id\n",
    "\n",
    "def collate_fn(batch):\n",
    "    tensor_batch = defaultdict(list)\n",
    "        \n",
    "    # Generate list of samples in batch\n",
    "    for sample in batch:\n",
    "        for key in pad_keys + stack_keys:\n",
    "            key_tensor = torch.tensor(sample[key])\n",
    "            tensor_batch[key].append(key_tensor)\n",
    "\n",
    "    # padding value of attention_mask is 0 since it is multiplied\n",
    "    tensor_batch['input_ids'] = pad_sequence(tensor_batch['input_ids'], padding_value=pad_id, batch_first=True)\n",
    "    tensor_batch['attention_mask'] = pad_sequence(tensor_batch['attention_mask'], padding_value=0, batch_first=True)\n",
    "    \n",
    "    for key in stack_keys:\n",
    "        tensor_batch[key] = torch.stack(tensor_batch[key])\n",
    "\n",
    "    for k, v in tensor_batch.items():\n",
    "        tensor_batch[k] = v.to(device)\n",
    "\n",
    "    return tensor_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2f70cea-a6ee-46f2-92b8-4b944cd6d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors for Gradient Accumulation\n",
    "def get_grad_principle_directions(gradient_dictionary, exp_vars):\n",
    "    exp_dirs = []\n",
    "    for key, val in gradient_dictionary.items():\n",
    "        \n",
    "        if min(val.size()) < 2:\n",
    "            continue\n",
    "\n",
    "        curr_dirs = get_principle_directions(val, exp_vars)\n",
    "        curr_dirs = torch.tensor(curr_dirs) / min(val.size())\n",
    "\n",
    "        exp_dirs.append(curr_dirs)\n",
    "    return torch.stack(exp_dirs)\n",
    "        \n",
    "\n",
    "class GradAccumulator:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        \n",
    "        self.model = model\n",
    "        self.accumulator = self.init_grad()\n",
    "    \n",
    "    def init_grad(self):\n",
    "        accumulator = dict()\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if len(param.size()) < 2:\n",
    "                continue\n",
    "                \n",
    "            accumulator[name] = torch.zeros_like(param, requires_grad=False)\n",
    "    \n",
    "        return accumulator\n",
    "\n",
    "    def accumulate_grad(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name in self.accumulator:\n",
    "                self.accumulator[name] += param.grad\n",
    "\n",
    "    def reset(self):\n",
    "        for key in self.accumulator.keys():\n",
    "            self.accumulator[key] = 0\n",
    "\n",
    "    def analyze_grad(self, exp_vars):\n",
    "        # Move to CPU\n",
    "        for key in self.accumulator.keys():\n",
    "            self.accumulator[key] = self.accumulator[key].cpu()\n",
    "        exp_dirs = get_grad_principle_directions(self.accumulator, exp_vars)\n",
    "        return exp_dirs.mean(dim=0), exp_dirs.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a7bcbd0-1ab7-48b6-b890-79dddf7abbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Training Artifacts\n",
    "training_cfg = hydra.utils.instantiate(cfg.model.model.train)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=training_cfg.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=training_cfg.batch_size)\n",
    "\n",
    "model = roberta_base_model if cfg.model.name == 'roberta-base' else roberta_large_model\n",
    "model.to(device)\n",
    "optimizer = AdamW(params=model.parameters(), lr=training_cfg.lr, weight_decay=training_cfg.weight_decay)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "loss_meter = AverageMeter()\n",
    "acc_meter = AverageMeter()\n",
    "accumulator = GradAccumulator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1efba1f3-4678-4dc2-b887-1191ea32cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ML Flow\n",
    "import mlflow\n",
    "\n",
    "# Set Tracking URI\n",
    "uri = mlflow.get_tracking_uri()\n",
    "if uri is None or uri != \"http://127.0.0.1:8080\":\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Set Experiment\n",
    "experiment_name = f\"{cfg.model.name}-{cfg.dataset.name}\"\n",
    "exps = mlflow.search_experiments(filter_string=f\"name='{experiment_name}'\")\n",
    "\n",
    "if len(exps) == 0:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "else:\n",
    "    experiment_id = exps[0].experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ccdfe5-a449-4da3-8e9c-0b1517fe61c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39876455bba4ea1957e724f68ae77ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52476 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Loop\n",
    "progress_bar = tqdm(total=training_cfg.epochs * len(train_loader))\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=experiment_name) as run:\n",
    "    for epoch in range(training_cfg.epochs):\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            # Reset Optimizer to 0\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # Forward Pass\n",
    "            output = model(**batch)\n",
    "        \n",
    "            # Backward Pass\n",
    "            output.loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate Gradient\n",
    "            accumulator.accumulate_grad()\n",
    "            \n",
    "            # Evaluate Performance\n",
    "            start_position_pred = torch.argmax(output.start_logits, dim=1)\n",
    "            end_position_pred = torch.argmax(output.end_logits, dim=1)\n",
    "            correct_exact_matches = ((batch[\"start_positions\"] == start_position_pred) \n",
    "                                     & (batch[\"end_positions\"] == end_position_pred)).sum()\n",
    "            \n",
    "            # Update Meters\n",
    "            acc_meter.update(correct_exact_matches.item(), len(batch))\n",
    "            loss_meter.update(output.loss.item(), 1)\n",
    "\n",
    "            # Update Progress\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        \n",
    "        # Compute Metrics\n",
    "        match_accuracy = acc_meter.average()\n",
    "        training_loss = loss_meter.average()\n",
    "        mean_dirs, std_dirs = accumulator.analyze_grad(explained_variances)\n",
    "\n",
    "        # Reset Accumulator\n",
    "        accumulator.reset()\n",
    "        \n",
    "        \n",
    "        # Track Metrics\n",
    "        mlflow.log_metric(\"training match accuracy\", match_accuracy, step=epoch)\n",
    "        mlflow.log_metric(\"training loss\", training_loss, step=epoch)\n",
    "        \n",
    "        for i, exp_var in enumerate(explained_variances):\n",
    "            mlflow.log_metric(f\"Mean Principle Dir Ratio {exp_var}\", mean_dirs[i], step=epoch)\n",
    "            mlflow.log_metric(f\"Std Dev Principle Dir Ratio {exp_var}\", std_dirs[i], step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ee990fd-f371-4e59-9b01-905cd7f2313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b2f4c-7afe-4826-9302-02d4eaf27b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = None\n",
    "for params in model.parameters():\n",
    "    param = params\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "50378659-1c48-4fea-9b3a-dff612d13b3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/graphviz/backend/execute.py:78\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m         proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/subprocess.py:1863\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1862\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: PosixPath('dot')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchviz\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_dot\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmake_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_graph\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/graphviz/_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/graphviz/rendering.py:122\u001b[0m, in \u001b[0;36mRender.render\u001b[0;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001b[0m\n\u001b[1;32m    118\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(filename, directory\u001b[38;5;241m=\u001b[39mdirectory, skip_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    120\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(filepath)\n\u001b[0;32m--> 122\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[1;32m    125\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelete \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, filepath)\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/graphviz/_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/graphviz/backend/rendering.py:326\u001b[0m, in \u001b[0;36mrender\u001b[0;34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001b[0m\n\u001b[1;32m    322\u001b[0m cmd \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m filepath \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwork around pytype false alarm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 326\u001b[0m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mfspath(outfile)\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/graphviz/backend/execute.py:81\u001b[0m, in \u001b[0;36mrun_check\u001b[0;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute PosixPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "make_dot(output.start_logits, params=dict(model.named_parameters())).render(\"model_graph\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8e703e8b-5b69-407e-84be-c85a2f5fa84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph(%self.1 : __torch__.transformers.models.roberta.modeling_roberta.___torch_mangle_1139.RobertaForQuestionAnswering,\n",
       "      %input_ids : Long(1, 5, strides=[5, 1], requires_grad=0, device=cuda:0)):\n",
       "  %qa_outputs : __torch__.torch.nn.modules.linear.___torch_mangle_1138.Linear = prim::GetAttr[name=\"qa_outputs\"](%self.1)\n",
       "  %roberta : __torch__.transformers.models.roberta.modeling_roberta.___torch_mangle_1137.RobertaModel = prim::GetAttr[name=\"roberta\"](%self.1)\n",
       "  %3479 : Tensor = prim::CallMethod[name=\"forward\"](%roberta, %input_ids)\n",
       "  %3480 : Tensor = prim::CallMethod[name=\"forward\"](%qa_outputs, %3479)\n",
       "  %2575 : int = prim::Constant[value=1]() # /home/mathadoor/Documents/peft-study/venv/lib/python3.10/site-packages/torch/_tensor.py:919:0\n",
       "  %2576 : int = prim::Constant[value=-1]() # /home/mathadoor/Documents/peft-study/venv/lib/python3.10/site-packages/torch/_tensor.py:919:0\n",
       "  %2577 : Tensor[] = aten::split(%3480, %2575, %2576) # /home/mathadoor/Documents/peft-study/venv/lib/python3.10/site-packages/torch/_tensor.py:919:0\n",
       "  %start_logits : Float(1, 5, 1, strides=[10, 2, 1], requires_grad=1, device=cuda:0), %end_logits : Float(1, 5, 1, strides=[10, 2, 1], requires_grad=1, device=cuda:0) = prim::ListUnpack(%2577)\n",
       "  %2580 : int = prim::Constant[value=-1]() # /home/mathadoor/Documents/peft-study/venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1509:0\n",
       "  %2581 : Float(1, 5, strides=[10, 2], requires_grad=1, device=cuda:0) = aten::squeeze(%start_logits, %2580) # /home/mathadoor/Documents/peft-study/venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1509:0\n",
       "  %2582 : int = prim::Constant[value=0]() # /home/mathadoor/Documents/peft-study/venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1509:0\n",
       "  %2583 : Float(1, 5, strides=[5, 1], requires_grad=1, device=cuda:0) = aten::contiguous(%2581, %2582) # /home/mathadoor/Documents/peft-study/venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1509:0\n",
       "  %2584 : int = prim::Constant[value=-1]() # /home/mathadoor/Documents/peft-study/venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1510:0\n",
       "  %2585 : Float(1, 5, strides=[10, 2], requires_grad=1, device=cuda:0) = aten::squeeze(%end_logits, %2584) # /home/mathadoor/Documents/peft-study/venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1510:0\n",
       "  %2586 : int = prim::Constant[value=0]() # /home/mathadoor/Documents/peft-study/venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1510:0\n",
       "  %2587 : Float(1, 5, strides=[5, 1], requires_grad=1, device=cuda:0) = aten::contiguous(%2585, %2586) # /home/mathadoor/Documents/peft-study/venv/lib/python3.10/site-packages/transformers/models/roberta/modeling_roberta.py:1510:0\n",
       "  %2588 : str = prim::Constant[value=\"start_logits\"]() # /home/mathadoor/Documents/peft-study/venv/lib/python3.10/site-packages/torch/jit/_trace.py:1088:0\n",
       "  %2589 : str = prim::Constant[value=\"end_logits\"]() # /home/mathadoor/Documents/peft-study/venv/lib/python3.10/site-packages/torch/jit/_trace.py:1088:0\n",
       "  %2590 : Dict(str, Tensor) = prim::DictConstruct(%2588, %2583, %2589, %2587)\n",
       "  return (%2590)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = \"dummy input\"\n",
    "torch.jit.trace(model, tokenizer(dummy_input, return_tensors=\"pt\").input_ids.to(device), strict=False).graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "618e1ac9-77d9-4289-a7af-3b3ed5a2a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_position = torch.argmax(output.start_logits, dim=1)\n",
    "end_position = torch.argmax(output.end_logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84c4645c-4f29-44ff-884c-0b4a306c0dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((batch[\"start_positions\"] == start_position) \n",
    " & (batch[\"end_positions\"] == end_position)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5935d06e-6829-4170-8382-57d203cd8467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 3972, 2661, 222, 5, 9880, 2708, 2346, 2082, 11, 504, 4432, 11, 226, 2126, 10067, 1470, 116, 2, 2, 37848, 37471, 28108, 6, 5, 334, 34, 10, 4019, 2048, 4, 497, 1517, 5, 4326, 6919, 18, 1637, 31346, 16, 10, 9030, 9577, 9, 5, 9880, 2708, 4, 29261, 11, 760, 9, 5, 4326, 6919, 8, 2114, 24, 6, 16, 10, 7621, 9577, 9, 4845, 19, 3701, 62, 33161, 19, 5, 7875, 22, 39043, 1459, 1614, 1464, 13292, 4977, 845, 4130, 7, 5, 4326, 6919, 16, 5, 26429, 2426, 9, 5, 25095, 6924, 4, 29261, 639, 5, 32394, 2426, 16, 5, 7461, 26187, 6, 10, 19035, 317, 9, 9621, 8, 12456, 4, 85, 16, 10, 24633, 9, 5, 11491, 26187, 23, 226, 2126, 10067, 6, 1470, 147, 5, 9880, 2708, 2851, 13735, 352, 1382, 7, 6130, 6552, 625, 3398, 208, 22895, 853, 1827, 11, 504, 4432, 4, 497, 5, 253, 9, 5, 1049, 1305, 36, 463, 11, 10, 2228, 516, 14, 15230, 149, 155, 19638, 8, 5, 2610, 25336, 238, 16, 10, 2007, 6, 2297, 7326, 9577, 9, 2708, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "for item in train_dataset:\n",
    "    x = f\"[CLS]{item['question']}[SEP]{item['context']}\"\n",
    "    tokenized_x = tokenizer(item['question'], item['context'])\n",
    "    print(tokenized_x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd23942f-6ea1-4a79-98ae-ddaa0d6a765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d0c2e-1193-416a-8d95-52dc9e5c3832",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1c168-4382-4963-bab5-e723a863a4f7",
   "metadata": {},
   "source": [
    "# Introducing LoRA Weights\n",
    "This section introduces LoRA weights in our models for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9a0bca-9500-4e4f-9650-23bfc0a02439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On the surface the above results suggest you need most of the directions to account for most of the directions. \n",
    "# It will be useful to see which directions are affected and how later.\n",
    "from models.LoRA import LoRALinearLayer\n",
    "def add_linear_lora(module, rank, init_type=0):\n",
    "    for key, child in module.named_children():\n",
    "        if isinstance(child, torch.nn.Linear):\n",
    "            lora_layer =  LoRALinearLayer(child, rank=rank, init_type=init_type)\n",
    "            setattr(module, key, lora_layer)\n",
    "        else:\n",
    "            add_linear_lora(child, rank, init_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa02e6c0-2f89-40ab-b387-9c77de31b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_linear_lora(roberta_base, rank=10, init_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe6c9164-4b29-4ad1-b98f-a50c4f368e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (v_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (q_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (out_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): LoRALinear(in_features=768, in_features=3072, rank=$10, init_type=$1)\n",
       "            (fc2): LoRALinear(in_features=3072, in_features=768, rank=$10, init_type=$1)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c66542b-d1f8-417c-bae4-172a31970431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ff436bb-df8a-4baa-af98-0be01d85c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40d88517-de50-4af3-ac05-2096882f94d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "model_config = AutoConfig.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "489ec480-9ada-4d51-8c54-a21b050de0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_config(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bb4c7-0028-4504-840b-081200450898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
