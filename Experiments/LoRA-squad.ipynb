{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e45fd35-cdca-44b8-a00f-607078ee1a67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Investigating Ranks\n",
    "In the first section, I am going to investigate what an appropriate rank to consider should be. It will make sense to look at the \n",
    "ranks of a trained matrix and a randomly initialized matrix. We will start by looking at a randomly initialized matrix and then\n",
    "look at a trained matrix. Specifically, I will look at the rank of a randomly initialized matrix. I will need to consider the sizes \n",
    "that are seen in RoBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1397017-4851-477f-a432-2a934510e545",
   "metadata": {},
   "source": [
    "## Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2172b3-4630-4fed-8bfd-4cf8b3ea7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Appropriate Libraries\n",
    "%load_ext autoreload\n",
    "    \n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm.notebook import tqdm \n",
    "import bisect\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# Set Logging Level\n",
    "import logging\n",
    "level = logging.DEBUG\n",
    "logging.getLogger(\"requests\").setLevel(level)\n",
    "logging.getLogger(\"urllib3\").setLevel(level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25dba68b-c775-4672-8fbf-f2bb3da6f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_principle_direction(A, exp_var):\n",
    "    U, S, V = torch.linalg.svd(A)\n",
    "    S = S ** 2\n",
    "    X = (torch.cumsum(S, 0) / S.sum().item()).tolist()\n",
    "    num = bisect.bisect(X, exp_var)\n",
    "    return num\n",
    "\n",
    "def get_principle_directions(A, exp_vars):\n",
    "    U, S, V = torch.linalg.svd(A)\n",
    "    S = S ** 2\n",
    "    X = (torch.cumsum(S, 0) / S.sum().item()).tolist()\n",
    "    ret = []\n",
    "    i, j = 0, 0\n",
    "    while i < len(exp_vars) and j < len(X):\n",
    "        val = X[j]\n",
    "        exp_var = exp_vars[i]\n",
    "        if val < exp_var:\n",
    "            j += 1\n",
    "        else:\n",
    "            ret.append(j)\n",
    "            i += 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4aaf774e-319c-4da5-a422-d7267ea08966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight tensor([0.0820, 0.2578, 0.4466, 0.6523, 0.8763, 0.9362, 0.9870])\n",
      "weight tensor([0.0331, 0.1128, 0.2179, 0.3599, 0.6031, 0.7160, 0.8833])\n",
      "weight tensor([0., 0., 0., 0., 0., 0., 0.])\n",
      "0.attention.self.query.weight tensor([0.0273, 0.0951, 0.1810, 0.3008, 0.5091, 0.6081, 0.7695])\n",
      "0.attention.self.key.weight tensor([0.0273, 0.0938, 0.1810, 0.3008, 0.5091, 0.6081, 0.7695])\n",
      "0.attention.self.value.weight tensor([0.0273, 0.0938, 0.1810, 0.3021, 0.5091, 0.6094, 0.7695])\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "for key, param in roberta_base_model.named_parameters():\n",
    "    with torch.no_grad():\n",
    "        key = \".\".join(key.split(\".\")[3:])\n",
    "        p_size = min(param.size())\n",
    "        if len(param.size()) < 2:\n",
    "            continue\n",
    "        print(key, torch.tensor(get_principle_directions(param, [0.1, 0.3, 0.5, 0.7, 0.9, 0.95, 0.99])) / p_size)\n",
    "    k += 1\n",
    "    if k > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35846b95-4743-425e-a2bd-ac1db674217a",
   "metadata": {},
   "source": [
    "## Normally Initialized Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a4005e5-d964-4def-94f1-41d18030aeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(n=100, size=[768, 768], exp_var=0.99):\n",
    "    results = []\n",
    "    for _ in range(n):\n",
    "        A = torch.randn(size)\n",
    "        num = get_principle_direction(A, exp_var)\n",
    "        results.append(num)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86b27c30-3205-4635-b424-9e5e80078d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([18.,  0.,  0.,  0.,  0., 77.,  0.,  0.,  0.,  5.]),\n",
       " array([390. , 390.2, 390.4, 390.6, 390.8, 391. , 391.2, 391.4, 391.6,\n",
       "        391.8, 392. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(10, 3))\n",
    "ax[0].hist(plot_results())\n",
    "ax[1].hist(plot_results(exp_var=0.95))\n",
    "ax[2].hist(plot_results(exp_var=0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601559f6-0a40-40bb-830e-a836a35c5a5b",
   "metadata": {},
   "source": [
    "The above results indicate the rank is very tightly distributed based on the explained variance. The reader is encouraged to play with the explained_variance and support the claim themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41538748-3d56-4a69-a5f6-aa4f2e98f146",
   "metadata": {},
   "source": [
    "## Analysis of RoBERTa pre-trained Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "373c7b6d-5ccd-447e-b545-7349e19e7e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Now let's look at how tightly the weights are distributed in RoBERTa \n",
    "from transformers import AutoModelForQuestionAnswering, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a18bc9a7-0c31-41be-970e-e37992303f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract RoBERTa Configuration\n",
    "roberta_base_config = AutoConfig.from_pretrained('roberta-base')\n",
    "roberta_large_config = AutoConfig.from_pretrained('roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acf40d4d-e557-4b8c-a6ec-fe8725910263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract RoBERTa Model\n",
    "roberta_base_model = AutoModelForQuestionAnswering.from_config(roberta_base_config)\n",
    "roberta_large_model = AutoModelForQuestionAnswering.from_config(roberta_large_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9dd7956d-48ca-4f5f-96e1-72ca43118c2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract Variances for a given set of explained variances\n",
    "def get_model_principle_direction(model, exp_vars):\n",
    "    principle_dirs = []\n",
    "    for key, param in model.named_parameters():\n",
    "        with torch.no_grad():\n",
    "            p_size = min(param.size())\n",
    "            \n",
    "            if len(param.size()) < 2:\n",
    "                continue\n",
    "                \n",
    "            curr_principle_dirs = get_principle_directions(param, exp_vars)\n",
    "            curr_principle_dirs = torch.tensor(curr_principle_dirs) / p_size\n",
    "            \n",
    "            if torch.any(curr_principle_dirs == 0):\n",
    "                continue\n",
    "                \n",
    "            principle_dirs.append(curr_principle_dirs)\n",
    "    \n",
    "    return torch.stack(principle_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6379350c-f84f-41e2-bd2e-da56058431bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variances = [0.1, 0.3, 0.5, 0.7, 0.9, 0.95, 0.99]\n",
    "roberta_base_dirs = get_model_principle_direction(roberta_base_model, explained_variances)\n",
    "roberta_large_dirs = get_model_principle_direction(roberta_large_model, explained_variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5bbc96cf-cb21-400e-bff7-d1d2ad1d1cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcoAAAHACAYAAAAiByi6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABRNklEQVR4nO3deVhV5d7G8S8gs4wSiEiSmuaMaZKmmR2VtDQ7dbIs5zGtVNKcxRkzx9TULIdKszcrcwpzSEszLZWsNGdzAhQHQBCQvdf7B0WRSGwENsP9ua59Hfez1/Db6xA3a61nPY+NYRgGIiIiki1baxcgIiJSlCkoRUREcqCgFBERyYGCUkREJAcKShERkRwoKEVERHKgoBQREcmBglJERCQHZaxdQGEzm81cuHABNzc3bGxsrF2OiIhYiWEYJCYmUqFCBWxtb3/eWOqC8sKFCwQGBlq7DBERKSLOnj1LxYoVb/t5qQtKNzc3IOPAuLu7W7kaERGxloSEBAIDAzNz4XZKXVD+ebnV3d1dQSkiIv96G06deURERHKgoBQREcmBglJERCQHCkoREZEcKChFRERyoKAUERHJgYJSREQkBwpKERGRHCgoRUREcqCgFBERyYGCUkREJAcKShERkRwoKEVERHJQ6mYPERGRYio6OuP1T/7+Ga8CoqAUEZFiIXr6CqJnrryl3T+sE/4zhhTYfhWUIiJSLCyiL+O5NRDDSWRcAe5XQSkiIsVC3yFutGpzg6atnAHYufkGzt7O+Pu7Feh+FZQiIlIs+PuDu505831wXTOuvgW/X/V6FRERyYGCUkREJAcKShERkRwoKEVERHKgoBQREcmBglJERCQHCkoREZEcKChFRERyoKAUERHJgYJSREQkBwpKERGRHCgoRUREcqCgFBERyYGCUkREJAcKShERkRwoKEVERHKgoBQREcmBglJERCQHCkoREZEcKChFRERyoKAUERHJgYJSREQkBwpKERGRHCgoRUREcqCgFBERyYGCUkREJAcKShERkRwoKEVERHKgoBQREcmBglJERCQHCkoRESlW7Egv1P2VKdS9iYiI3KEevIcbicRuCqFy52YFvj8FpYiIFBvmxCTW0Z4Y/Hn08lEqF8I+delVRESKjV9W/kQM/rhyncb/rVAo+1RQiohIsfHVZ9cBqMIJHJ1sCmWfCkoRESkeDINNhwIBMBdifCkoRUSkWIjbdYTv0+4H4DhVC22/CkoRESkWvpp/DANbgjhJCs6Ftl8FpYiIFAsbtzkB4MXVQt2vHg8REZHCER2d8fonf/+MVw5MV+KJvFgfgBhyXja/KShFRKRQRE9fQfTMlbe0+4d1wn/GkBzX3btgH5d5FE/beKLNhfNYyJ8UlCIiUigW0Zfx3BqI4SQy7l/W3fh/GY+FtLrnOJ+caJD/xeXA6vco58+fT1BQEE5OToSEhLB3794cl589ezbVq1fH2dmZwMBABg8eTEpKSiFVKyIiedV3iBs7N9/IfL9z8w327ctoz5HZzMZDlQBo3cauIEvMllXPKD/++GPCwsJYuHAhISEhzJ49m9DQUI4cOYKvr+8ty69cuZLhw4ezZMkSmjRpwtGjR+nWrRs2NjbMnDnTCt9ARERyy98f3O3Mme+D65pxvfVX/S2iN//M/vR6APynZxDMK6ACb8OqZ5QzZ86kd+/edO/enZo1a7Jw4UJcXFxYsmRJtst/9913PPTQQ3Tq1ImgoCBat27N888//69noSIiUnxFLvwdgAe8juFbwb7Q92+1oExLS2Pfvn20bNnyr2JsbWnZsiW7d+/Odp0mTZqwb9++zGA8efIkGzdupG3btoVSs4iIFL6N35QFoG3TRKvs32qXXuPi4jCZTPj5+WVp9/Pz47fffst2nU6dOhEXF0fTpk0xDIP09HT69evHyJEjb7uf1NRUUlNTM98nJCTkzxcQEZECd/PCJb66ktF5p22filapweqdeSyxfft2pkyZwttvv83+/fv57LPP2LBhAxMnTrztOhEREXh4eGS+AgMDC7FiERG5E7vmR5GAB3eVuULDtrm4oVkArBaUPj4+2NnZERsbm6U9NjaW8uXLZ7vOmDFj6Ny5M7169aJOnTo89dRTTJkyhYiICMxmc7brjBgxgvj4+MzX2bNn8/27iIhIwdj4WcZTDY/d9zu2VkosqwWlg4MDDRo0YOvWrZltZrOZrVu30rhx42zXSU5OxvYfR8rOLqOrsGEY2a7j6OiIu7t7lpeIiBQDJhMbj2YMfv74/1ysVoZVHw8JCwuja9euNGzYkEaNGjF79mySkpLo3r07AF26dCEgIICIiAgA2rVrx8yZM6lfvz4hISEcP36cMWPG0K5du8zAFBGRkuH3NQf41dwQW0y0fqmK1eqwalB27NiRS5cuMXbsWGJiYggODiYyMjKzg8+ZM2eynEGOHj0aGxsbRo8ezfnz57nrrrto164dkydPttZXEBGRAvLlu+eBhjTxOYbXXfdZrQ4b43bXLEuohIQEPDw8iI+P12VYEZFClnQxibJ+rgBcj03C1df1tsu299jBuoTmTPnfAUb8X32L1/83uc2DYtXrVURESoeUE+fZmtAQgLYvVbJqLQpKEREpcr6Z/zPJuFLB/iJ1H/G2ai0KShERKXI2rE0HoG2dc9jYWLcWBaWIiBQtaWlsPJnReaftc9bvS6KgFBGRIuXYqn0cN6piTxot+1S2djkKShERKVo2LssYse1h/2O4eVg/pqxfgYiIyN9s3OsDQNtWN61cSQYFpYiIFBlJv5xie9IDALQdYP3LrqCgFBGRImTbvEOk4cg9Theo/oD1O/KAglJERIqQjV9m/G/b+jFWfyzkTwpKEREpEozkG2w8UweAti9ad5CBv1NQiohIkfDrsh84w9042aTwSFfrDlv3dwpKEREpEjZ+eAWAFhWP4+JaRK67oqAUEZGiwDDYuL88AI+3LVqTWikoRUTE6uJ/PMbO1IzZQtq8fJtJmqOj4eDBv94fPAj792e0FyAFpYiIWN3meUcwUYb7XM9QubZLtstET19BVKshme+jWg1hf4NeRE9fUaC1KShFRMTqNm4uA0DbB+Juu8wi+tKUXZnvm7KLBuxnEX0LtLYyBbp1ERGRf2G+lsCX0cEAtO3me9vl+g5xo/0Lt7b7+7sVUGUZFJQiImJVUe/+SAyPUtbmOk2fq3jb5fz9M16FTZdeRUTEqjasSgCgZeWTODpauZhsKChFRMR6DIONBwMBaPuEnZWLyZ6CUkRErCZu+y/suVkfgLav3OaxECtTUIqIiNVsWnASA1vquZ8koIqTtcvJloJSRESsZuPXzgC0bRJv5UpuT71eRUTktqKjYon+9cot7f61vPEP9rujbZvirhAZ1wCAtr0q3NG2CpKCUkREbmvRoMOM3/HILe3hzbczbvudBeX+ZT9xhSfwtE3gwSfvbFsFSUEpIiK31Xd2DVrtPkjT/nUB2Pn2QZzd7fGvVeOOt715XRoAodVOUaZMvTveXkFRUIqIyG35B/vhXqEs9M94H/x0FVx9Xe94u7aYiDyW0cu17VNF8OHJv1FnHhERKXR1+Yn9pnrYYOaxAUXzsZA/KShFRKTQVeJ3AB7wPoFvgL2Vq8mZglJERApdIu4AtG123cqV/DsFpYiIFCpfYviBBwBo2y/QytX8OwWliIgUqvpEkYg7d5W5QoPWPtYu518pKEVEpFC5kARAaLXT2BaDFCoGJYqISElxfWcUO3gEgDadPK1aS24pKEVEpNAseO04VyiHPxd4okfRHY3n7xSUIiJSKK5s2M2s0x0ASMcOu6I5/eQtFJQiIlLwDIM3+50gAQ8COMclisfZJCgoRUSkEMT+3w7eOvcUADcomvNO3o6CUkRECpZhMPXVCyTjygN3neYKRf+RkL9TUIqISIE6994mFlz8LwBjJhftAdCzo6AUEZGCYzYz6fUEUnHi4cBTtGjvbu2KLKagFBGRAnPyrfW8dzXj3uSkhT7Y2Fi5oDxQUIqISMFIT2fC2HTSsSe06nGatXWzdkV5kquJm9euXZvrDbZv3z7PxYiISMnx2xtf8EFiBwAmLva3bjF3IFdB2aFDhyzvbWxsMAwjy/s/mUym/KlMRESKr9RUwqc4YMaOJ2sd54FHqlq7ojzL1aVXs9mc+frqq68IDg7myy+/5Nq1a1y7do2NGzdy//33ExkZWdD1iohIMfDTuM/5v+R22GBmwpKK1i7njuTqjPLvBg0axMKFC2natGlmW2hoKC4uLvTp04fDhw/na4EiIlLMJCczdpYnAB0bnKBuo3utW88dsrgzz4kTJ/D09Lyl3cPDg9OnT+dDSSIiUpztHf4Za1MfwxYT45ZWsnY5d8zioHzggQcICwsjNjY2sy02NpahQ4fSqFGjfC1ORESKmYQERi8MAKDLQyepXsfBygXdOYuDcsmSJURHR3P33XdTtWpVqlatyt1338358+d57733CqJGEREpJnYM+pzNN1tgTxrhy+6xdjn5wuJ7lFWrVuXgwYNs3ryZ3377DYAaNWrQsmXLLL1fRUSkdDEuX2HM+xm9W3u1OkNQ1eLb0/XvLA5KyHgcpHXr1jz88MM4OjoqIEVEhM0D1vCtqQeONqmMeq+ytcvJNxZfejWbzUycOJGAgADKli3LqVOnABgzZowuvYqIlFJGdAyjPqkHQP925wgILDkDv1n8TSZNmsSyZcuYNm0aDg5/3aStXbs27777br4WJyIixcPaPuv50dwAV9tkhr9Tcs4mIQ9B+f777/POO+/wwgsvYGdnl9ler169zHuWIiJSeph/P8uYDSEADOwYg69fybodZ3FQnj9/nqrZ3KA1m83cvHkzX4oSEZHi45Oekfxs1MHD7jpD5pWMnq5/Z3FQ1qxZk2+//faW9tWrV1O/fv18KUpERIqH9CMnGLv1YQBe63YZL++SdTYJeej1OnbsWLp27cr58+cxm8189tlnHDlyhPfff5/169cXRI0iIlJEfdh9K0fpQzn7eAbNKv6j8GTH4jPKJ598knXr1rFlyxZcXV0ZO3Yshw8fZt26dbRq1aogahQRkSIoLeoQ43dn/N4f3j8Rt+I53eS/suiMMj09nSlTptCjRw82b95cUDWJiEgxsKTHTk7Th/KOV+k/pXjPEJITi84oy5Qpw7Rp00hPTy+oekREpBi48d0BJh54HIBRr6Xg4mLlggqQxZde//Of/7Bjx46CqEVERIqJhb1+5AIB3O0SR++x/tYup0BZ3JmnTZs2DB8+nJ9//pkGDRrg6uqa5fP27dvnW3EiIlL0XN/yPRGHnwRg7GgTjo5WLqiAWRyU/fv3B2DmzJm3fGZjY4PJZLrzqkREpMia2/dnLvEgVd1j6TLEz9rlFDiLg9JsNhdEHSIiUgwkfPkt004+A8C4CXbY21u5oEJwR6PWpqSk5FcdIiJS5BnMH36Oa3hRy/sCz73sY+2CCoXFQWkymbLMHnLy5Ekg77OHzJ8/n6CgIJycnAgJCWHv3r05Ln/t2jUGDBiAv78/jo6OVKtWjY0bN1q8XxERsUwrvmJOTEcAJkxz5m/DfZdoFgfl5MmT8232kI8//piwsDDCw8PZv38/9erVIzQ0lIsXL2a7fFpaGq1ateL06dOsXr2aI0eOsHjxYgICAiz9GiIiYgEbzFQgmuu4Ud/vPE/18LJ2SYXHsFCVKlWMLVu2GIZhGGXLljVOnDhhGIZhHD582PD09LRoW40aNTIGDBiQ+d5kMhkVKlQwIiIisl1+wYIFRuXKlY20tDRLy84UHx9vAEZ8fHyetyEiUppcj71uPM5aw5kkAwxjw0d5//15Pfa6AYYBGf+2ptzmgdVmD0lLS2Pfvn20bNkys83W1paWLVuye/fubNdZu3YtjRs3ZsCAAfj5+VG7dm2mTJmSY0/b1NRUEhISsrxERMQCJhMexHMDFxpX+J02Hd2tXVGhstrsIXFxcZhMJvz8snYt9vPzIyYmJtt1Tp48yerVqzGZTGzcuJExY8YwY8YMJk2adNv9RERE4OHhkfkKDAzMdY0iIgLnZ6zkE54FYPQbZbEpeROE5KhYzR5iNpvx9fXlnXfewc7OjgYNGnD+/HnefPNNwsPDs11nxIgRhIWFZb5PSEhQWIqI5FLyx+voOqMeN3GgImdp3trb2iUVOouD8s/ZQyZMmJA5e8j9999v8ewhPj4+2NnZERsbm6U9NjaW8uXLZ7uOv78/9vb22P2tq1WNGjWIiYkhLS0tS+eiPzk6OuJY0oeNEBEpAOk7dtGxky3f0xgXkjhHRSDZ2mUVujw9R9msWTM2b97MxYsXSU5OZufOnbRu3dqibTg4ONCgQQO2bt2a2WY2m9m6dSuNGzfOdp2HHnqI48ePZxn04OjRo/j7+2cbkiIikjfGr4d4qfUJ1psfx8k2lRQcgVJ2zfUPdzTgwJ0KCwtj8eLFLF++nMOHD/PSSy+RlJRE9+7dAejSpQsjRozIXP6ll17iypUrDBw4kKNHj7JhwwamTJnCgAEDrPUVRERKnnPnGNfkK95N64ItJpYuSMFs+QXIEiNX39zLywubXN69vXLlSq533rFjRy5dusTYsWOJiYkhODiYyMjIzA4+Z86cwdb2rywPDAxk06ZNDB48mLp16xIQEMDAgQMZNmxYrvcpIiI5uHaNRSFLmJAwFoC3p9+gXYcy0NfKdVmRjWEYxr8ttHz58sx/X758mUmTJhEaGpp5iXT37t1s2rSJMWPGMHjw4IKrNh8kJCTg4eFBfHw87u6lq4uziEiOUlJY02AiTx+agBk7xr56jfFzPEm6mERZv4yZoq7HJuHq6/ovG7q9/NzWncptHuQqKP/u6aefpkWLFrz88stZ2ufNm8eWLVtYs2ZNngouLApKEZFsmEzsahlOy+2jSMGZXk9d5p1Py2Fjk7/hVhyD0uJ7lJs2beKxxx67pf2xxx5jy5Ytlm5ORESszTA41GUq7baHkYIzTzwYx4L/K5f/z0tGR8PBg3+9P3gQ9u/PaC/CLA7KcuXK8cUXX9zS/sUXX1CuXLl8KUpERArPuZFv89jKzlzFmwfvjePjrT6UKYC+O9HTVxDVakjm+6hWQ9jfoBfR01fk/87ykcWHYvz48fTq1Yvt27cTEhICwJ49e4iMjGTx4sX5XqCIiBSca2+vpM3UhznL3VT3vcK673xwcSmYfS2iL+P5KyibsguAcBIZVzC7zBcWB2W3bt2oUaMGb731Fp999hmQ8dD/zp07M4NTRESKvpQvNvHkgIr8Qh38XROI3OONTwFOMdl3iBvtX7i13d/freB2mg/ydHIdEhLCihVF+1RZRERuz7R7L52fTuIbQnG3T+bLb8sSFFSw+/T3z3gVN7kKyoSEhMweQf82+4Z6koqIFG3G0WMMevQgq029cLBJY816e+rVt+r4M0VargcciI6OxtfXF09Pz2wHHzAMAxsbmxynvBIRESuLieGNBz9nXsrrALy/xESL1s5WLqpoy1VQbtu2DW/vjBHjv/766wItSERECkhiIssfXMCIq+MBmD0xgY7ddBXw3+QqKJs3b57tv0VEpJhIS+PL5lPp+XtGSA7tdZWBo72sXFTxYPFF6cjISHbu3Jn5fv78+QQHB9OpUyeuXr2ar8WJiEg+MJv54clJPHNgJCbK8GKbOKYuUkjmlsVBOXTo0MwOPT///DNhYWG0bduWU6dOZZkgWUREioZjfafzeOTLJONK6/vjeG+ND7bqu5NrFj8ecurUKWrWrAnAp59+Srt27ZgyZQr79++nbdu2+V6giIjkXezEdwh99xku4cv9lS6zersPmr7XMhb/TeHg4EBycsYM11u2bMmcsNnb2/tfHx0REZHCk7h0NW3HNuAUlansfZWNe8rhVrSf7S+SLD6jbNq0KWFhYTz00EPs3buXjz/+GICjR49SsWLFfC9QREQsl7bpa57u6cF+GnCXcyKRuz35Y6pfsZDFZ5Tz5s2jTJkyrF69mgULFhAQEADAl19+me2sIiIiUrjM+6Po8cRFNhutcLFLYcM2F+6tlt9TgZQeFs9HWdxpPkoRKdFOn+b12ht4M2kAZWzSWbfGzGPt7+ymZFGaQzI/5TYP8jTWq9ls5vjx41y8eBGz2Zzls4cffjgvmxQRkTsVF8fsRit5M2kkAO+9ncpj7UtGqFmTxUH5/fff06lTJ37//Xf+eTKqIexERKwkKYlVjWcz+NIkACKGx9Oln4eViyoZLA7Kfv360bBhQzZs2IC/v3+2476KiEghSk9nW8spdDkeDsArL1xh2BRvKxdVclgclMeOHWP16tVUrVq1IOoRERFLGAZR/5tMh++HcRMHnmkRx6zlPugcJv9Y3Os1JCSE48ePF0QtIiJiodMDZ9FmTR8Scad5rTg+2OiDnZ21qypZLD6jfOWVV3jttdeIiYmhTp062NvbZ/m8bt26+VaciIjcXtz0ZTw2ty0x+FMn4DJrdvrg5GTtqkoeix8Psc1mgEAbG5tiMx+lHg8RkZIg+eN1/Oc5H76nMYHu8ew+5MEfj7XnOz0eYqFTp07dUWEiInJn0rfvpGMnW76nMV6OSWza7V5gISl5CMpKlSoVRB0iIpILxq+H6Bd6kvXmLjjZprJukyM1aqrnTkHK04ADJ06cYPbs2Rw+fBiAmjVrMnDgQKpUqZKvxYmIyN+cO8e4Jl/xXtogbDGx6iN4qHmefo2LBSzu9bpp0yZq1qzJ3r17qVu3LnXr1mXPnj3UqlWLzZs3F0SNIiJy7RqLQpYwIWEQAG9Pv8GTzzpat6ZSwuI/RYYPH87gwYOZOnXqLe3Dhg2jVatW+VaciIgAKSmseehN+l+YAED4wGv0fc3TujWVIhafUR4+fJiePXve0t6jRw8OHTqUL0WJiMgfTCZ2PTaR5w+NxowdvZ++TPgsT2tXVapYHJR33XUXUVFRt7RHRUXh6+ubHzWJiAiAYXCocwTtdrxGCs60axzH26vKadSdQmbxpdfevXvTp08fTp48SZMmTQDYtWsXb7zxBmFhYfleoIhIaXVuxHwe+6gLV/GmcbU4Vm3xoYz67hQ6iw/5mDFjcHNzY8aMGYwYMQKAChUqMG7cOF599dV8L1BEpDS69vZK2rzRnLPcTXXfK6z7zgcXF2tXVTrd0cTNiYmJALi5ueVbQQVNI/OISFGX8sUmQjs48w0P4++awO5f3bHmI+ylfWSeXN+jvHHjBmvXrs0MR8gISDc3NxISEli7di2pqal3VrWISCln2r2XF59O5hsext0+mS+/LWvVkBQLgvKdd95hzpw52Z49uru789Zbb/Huu+/ma3EiIqWJcfQYAx/9mU9NT+Fgk8aaDQ7Uq29xn0vJZ7n+f2DFihUMGjTotp8PGjSI5cuX50dNIiKlT0wMUx9cw/yUnthg5oOlJlq0Us+doiDXQXns2DHq1at328/r1q3LsWPH8qUoEZFSJTGRZSELGHl1KACzJl7n2a7OVi5K/pTroExPT+fSpUu3/fzSpUukp6fnS1EiIqVGWhpfPhxBrzNjAHi9z1UGjlZHw6Ik10FZq1YttmzZctvPv/rqK2rVqpUvRYmIlApmM3vbT+KZqFGYKMOLbS4TscDL2lXJP+Q6KHv06MHEiRNZv379LZ+tW7eOyZMn06NHj3wtTkSkJDvW500e3/QKybjS+v443ltTDtui1ncnOhoOHvzr/cGDsH9/Rnspkes7xX369OGbb76hffv23HfffVSvXh2A3377jaNHj/Lss8/Sp0+fAitURKQkiRm/iND3/kccd9Eg6DKrt/vg4GDtqm4VPX0FJ2d+DuwCIKrVEJy5gX9YJ/xnDLFucYXEor9dPvzwQ1atWkW1atU4evQoR44coXr16nz00Ud89NFHBVWjiEiJkrh0NY+Pa8gpKlOl3FU2fF+OojpuyyL60vSPkARoyi4asJ9F9LViVYXrjkbmKY40Mo+IWFNa5DaeaGtis9GKu5wT+e6nslS9t+iOch4dnf1VVn//jFdxlts80EM6IiKFxLw/ih7tLrHZ6IirXQobt7sW6ZCEkhGId0pBKSIlWnRULNG/Xrml3b+WN/7BfoVXyKlTDH94FyvSB1DGJp3Vn9nSsFFR67kj2VFQikiJtmjQYcbveOSW9vDm2xm3vZCCMi6O2SEf8WbSSADeezuNx9prKpDiQkEpIiVa39k1aLX7IE371wVg59sHcXa3x79WjcIpICmJVY1nM/jSJACmjkygSz/1jyhO7jgoExIS2LZtG9WrV6dGjUL6wRMRySX/YD/cK5SF/hnvg5+uUnjTRKWns+0/k+lyfBwAr7xwhdcneRfOviXfWHyB/Nlnn2XevHlAxtRbDRs25Nlnn6Vu3bp8+umn+V6giEixZBhEPTOJDnuGcxMH/vdoHLOWe2NTtPvuSDYsDspvvvmGZs2aAfD5559jGAbXrl3jrbfeYtKkSfleoIhIcXR64CzafNGXRNxpXjuO9zf4YGdn7aokLywOyvj4eLy9My4dREZG8vTTT+Pi4sLjjz+u2UNERIC46csInfs4MfhTJ+Aya771wcnJ2lVJXlkclIGBgezevZukpCQiIyNp3bo1AFevXsVJPwkiUsolfbSWJ4bex1Gqc7fHNb7cUw5PT2tXJXfC4s48gwYN4oUXXqBs2bJUqlSJRx55BMi4JFunTp38rk9EpNhI376T5160Yw8P4uWYROR3HgQEWLsquVMWB2X//v1p1KgRZ8+epVWrVtj+MdR95cqVdY9SREot45df6Rd6kvXmLjjZprL+K0dq1FTPnZIgT4+HNGzYkIYNG2Zpe/zxx/OlIBGRYufcOcKbbOa9tEHYYuLjVdDkYT2mXlJY/P+kyWRi2bJlbN26lYsXL2I2m7N8vm3btnwrTkSkyLt6lYWNljAxcSwAC2am0P5/hfScphQKi4Ny4MCBLFu2jMcff5zatWtjo4eCRKS0SklhzUNvMiB6IgDhA6/RZ7CndWuSfGdxUK5atYr/+7//o23btgVRj4hI8WAysTN0Is8fHoMZO3o/fYXwWRp1pySy+PEQBwcHqlatWhC1iIgUD4bBoc4RtPtmCCk4075JHG+v0qg7JZXFQfnaa68xZ84cStl8zyIimc4Nn8djH3XhGl40rhbHR5t9KKO+OyWWxf/X7ty5k6+//povv/ySWrVqYW9vn+Xzzz77LN+KExEpaq69vZI20x7hLHdzn98V1n3ng4tmzCrRLA5KT09PnnrqqYKoRUSkSEtZE8mTAyryC3XwL5tA5B5vypWzdlVS0CwOyqVLlxZEHSIiRZpp915efOYG3/AY7vbJRO50o1Ila1clhSHPV9UvXbrEkSNHAKhevTp33XVXvhUlIlKUGEeOMvDRn/nU1BMHmzTWbHCgbj313CktLO7Mk5SURI8ePfD39+fhhx/m4YcfpkKFCvTs2ZPk5OSCqFFExHpiYpja+Avmp/TEBjMfLDPTopV67pQmFgdlWFgYO3bsYN26dVy7do1r167xxRdfsGPHDl577bU8FTF//nyCgoJwcnIiJCSEvXv35mq9VatWYWNjQ4cOHfK0XxGRHCUksCxkASOvDgVg9qQknu2iWZJKHcNC5cqVM77++utb2rdt22b4+PhYujlj1apVhoODg7FkyRLj119/NXr37m14enoasbGxOa536tQpIyAgwGjWrJnx5JNP5np/8fHxBmDEx8dbXKuIFE/XY68bYBiQ8e9cSU01NtYbbthx0wDDGNbnSsEWKYUut3lg8RllcnIyfn5+t7T7+vrm6dLrzJkz6d27N927d6dmzZosXLgQFxcXlixZctt1TCYTL7zwAuPHj6dy5coW71NEJEdmM3vbTeSZn0Zjogyd214mYqGXtasSK7E4KBs3bkx4eDgpKSmZbTdu3GD8+PE0btzYom2lpaWxb98+WrZs+VdBtra0bNmS3bt333a9CRMm4OvrS8+ePf91H6mpqSQkJGR5iYjk5FjvaTz+1ask40pogzjeW1NOo+6UYhbfkZ4zZw6hoaFUrFiRevXqAfDTTz/h5OTEpk2bLNpWXFwcJpPpljNUPz8/fvvtt2zX2blzJ++99x5RUVG52kdERATjx4+3qC4RKb1ixi0kdMmzxHEXDYIus3q7D/8YV0VKGYuDsnbt2hw7dowVK1Zkhtnzzz/PCy+8gLOzc74X+HeJiYl07tyZxYsX4+Pjk6t1RowYQVhYWOb7hIQEAgMDC6pEESnGEpd8QtvxjThFZaqUu8qG78tRtqy1qxJry1MfZxcXF3r37n3HO/fx8cHOzo7Y2Ngs7bGxsZQvX/6W5U+cOMHp06dp165dZtuf82GWKVOGI0eOUKVKlSzrODo64ujoeMe1ikjJlha5jf/28uIA93OXcyKbvvckm+4YUgrlKijXrl1LmzZtsLe3Z+3atTku2759+1zv3MHBgQYNGrB169bMRzzMZjNbt27l5ZdfvmX5++67j59//jlL2+jRo0lMTGTOnDk6UxSRPDHvj6JHu0tsMTriWiaFjdtdqVJVNyUlQ66CskOHDsTExODr65vjM4s2NjaYTCaLCggLC6Nr1640bNiQRo0aMXv2bJKSkujevTsAXbp0ISAggIiICJycnKhdu3aW9T09PQFuaRcRyZVTpxjW7DtWpPenjE06n35uS8NGFvdzlBIsV0H55+XNf/47P3Ts2JFLly4xduxYYmJiCA4OJjIyMrODz5kzZ7C11Q+tiBSAuDhmNfqI6ckjAViyII3QJzQViGRlYxiWTSz5/vvv07Fjx1vu+6WlpbFq1Sq6dOmSrwXmt4SEBDw8PIiPj8fd3d3a5YhIIUi6mERZP1cArscm4errCklJrAqO4PnjkwB4Y1QCr0/S74TSJLd5YPGpWvfu3YmPj7+lPTExMfNyqYhIkXbzJtsenUSX42MBeLXzFYZOVEhK9iwOSsMwsMnmydtz587h4eGRL0WJiBQYwyDqf5PpsHcEN3Hg2f/EMWuZtwYUkNvK9eMh9evXx8bGBhsbG/7zn/9Qpsxfq5pMJk6dOsVjjz1WIEWKiOSX8yPn0eaLviTiziN14nh/gw/qBiE5yXVQ/tnbNSoqitDQUMr+7SlcBwcHgoKCePrpp/O9QBGR/NKVpbRb8hQx+FO34mXWfOuDHrOWf5ProAwPDwcgKCiI5557Tg/xi0jxYRi8yPv8Rg2OUp27Pa7x5Z5y6G6R5IbFFxxq1qyZ7Tire/bs4ccff8yPmkRE8s/ly5x8bgSHqMUeHsTb4TqR33lQoYK1C5PiwuKgHDBgAGfPnr2l/fz58wwYMCBfihIRyQ/mjZHMqTybRtunsZ8GOJPMJ6ttqFFTPXck9ywOykOHDnH//fff0l6/fn0OHTqUL0WJiNyRpCTOdhlF68fLMChhIik44048N3AhJMTaxUlxY3FQOjo63jKIOUB0dHSWnrAiItZgfL+HlVXGUOeDoWylJc5l0pg18ToJ6Iak5I3FQdm6dWtGjBiRZdCBa9euMXLkSFq1apWvxYmI5NrNm1x5fSrPNfmdF2JnEo8nje6LJ+pXB3r30aVWyTuLTwGnT5/Oww8/TKVKlahfvz6Q8ciIn58fH3zwQb4XKCLyr44cYVO7efQ4NpwLBGBnYyJ8eBojJnhQpgwkXbR2gVKcWRyUAQEBHDx4kBUrVvDTTz/h7OxM9+7def7557HXNOAiUpgMg+RZi3j9dZhvmgtA9QoJfPiFOw0bFuxE8lJ65OmmoqurK3369MnvWkREcu/8efY+/Qad9wzgKNUBeKX7dabOc8dFE4BIPsrTwE0ffPABTZs2pUKFCvz+++8AzJo1iy+++CJfixMRyc7NFf/HuKof0mTPTI5SnQDP63wVaeatJWUVkpLvLA7KBQsWEBYWRps2bbh69WrmRM1eXl7Mnj07v+sTEfnL1ascaTeEJi/ew/iUYZgow/OPx/PzybK0CtWArVIwLP7Jmjt3LosXL2bUqFFZHgdp2LAhP//8c74WJyLyJ2PLVuZVnkH99RP4kQfwdLrBRx+ks3K9B15e1q5OSjKLg/LUqVOZvV3/ztHRkaSkpHwpSkQk040bnO8VzmOt0nnl2iRu4EKrRvH8ctyZ517Us9tS8CwOynvuuSfbsV4jIyOpUaNGftQkIpJh/34+vncUdd4byFeE4mSXxtzpqUTu9iAgwNrFSWlh8Z9jYWFhDBgwgJSUFAzDYO/evXz00UdERETw7rvvFkSNIlLapKdzddwcBkypwEfGTAAa3nuND9Z6ct99Vq5NSh2Lg7JXr144OzszevRokpOT6dSpExUqVGDOnDk899xzBVGjiJQmx4+zpf1bdDv8OuepiJ2NidFDUhk12RM9qi3WYFFQpqens3LlSkJDQ3nhhRdITk7m+vXr+Pr6FlR9IlJaGAbJ85cwfHAac9PfAuBevwQ+/MKNRiF65kOsx6J7lGXKlKFfv36kpKQA4OLiopAUkTsXE8OPzQbT4JUmzE1/CYD+nRM5cMKdRiEap1Wsy+LOPI0aNeLAgQMFUYuIlELpq9cwsfJSGu96k9+ogb/7dSI3mpn/vhuurtauTiQP9yj79+/Pa6+9xrlz52jQoAGu//hJrlu3br4VJyIlWEICR7tNocvnHdhDBwD+1zqeBSs9KFfOuqWJ/J2NYRiGJSvY2t56EmpjY4NhGNjY2GSO1FNUJSQk4OHhQXx8PO7u7tYuR6RUMnZ8w8L/fsWQKyNIxhUPxxvMX1iGTl3tsSmAK61JF5Mo65fxR/312CRcfXWqKrnPA4vPKE+dOnVHhYlIKZaayoXBb9JzQQMimQTAfxpcY+nnngQGWrk2kduwOCgrVapUEHWISEl38CCftFtOvzMjuUI5nOzSmDrZzCtDPcnmQpVIkZGroFy7di1t2rTB3t6etWvX5rhs+/bt86UwESkhTCauTZ7PK+PL8aF5BgD3V8kYPKBmTSvXJpILuQrKDh06EBMTg6+vLx06dLjtcsXhHqWIFKLTp9nWfjbdfg7jLHdji4mRg1MYM9UTBwdrFyeSO7kKSrPZnO2/RUSyZRjcWPwhI19OYPbN2QBU9Y3n/c/dadxEHWmkeNHQ+yKSvy5d4kDHqbz4dQ8OUQuAfp0SeHORB2XLWrk2kTywKCjNZjPLli3js88+4/Tp09jY2HDPPffwzDPP0LlzZ2wKol+3iBQb6V9s4I0XDjIuaSrp2FPe7TrvrXCmbTs9iiXFV677mhmGQfv27enVqxfnz5+nTp061KpVi99//51u3brx1FNPFWSdIlKUXb/O8edG83AHL0YnjSAde57+zzV+PlmWtu3srF2dyB3J9RnlsmXL+Oabb9i6dSstWrTI8tm2bdvo0KED77//Pl26dMn3IkWk6DJ2fcfipzYQdmkESZTF3eEG8xbY8WJ3zwIZPECksOX6jPKjjz5i5MiRt4QkwKOPPsrw4cNZsWJFvhYnIkVYWhoxAyNo1/QqfS9NJomyPBJ8lZ+POdO5h4NCUkqMXJ9RHjx4kGnTpt328zZt2vDWW2/lS1EiklV0VCzRv165pd2/ljf+wX6FX9ChQ3z2xBL6nBrOZXxwtE0jYqKJgcO9NHiAlDi5DsorV67g53f7/yD9/Py4evVqvhQlIlktGnSY8TseuaU9vPl2xm0vxKA0m4mftoiBo8qy3DwdgOCgq3ywzovatQuvDJHClOugNJlMlClz+8Xt7OxIT0/Pl6JEJKu+s2vQavdBmvbPmJ1n59sHcXa3x79WjcIr4uxZtneYTdf9r3KGSthiYtgrNxg33UuDB0iJluugNAyDbt264ejomO3nqamp+VaUiGTlH+yHe4Wy0D/jffDTVQpvBgzDIGX5x4zue4mZaW9iYEtln4zBAx5qqgcjpeTLdVB27dr1X5dRj1eREubKFaKem0rnzZ35hToA9H72GjPe9cTNzcq1iRSSXAfl0qVLC7IOESliTBs38eZz+xibOImbOODrmjF4wBNPelq7NJFCpSHsRCSr5GRO9ptGlw9asouRAHR45Crv/J8Xd91l5dryIDoqlpO7Y4GM+7tRn5744/6ulXoMS7GjoBSRTMbeH1jSfg2DYodzHTfc7FN4a64NXft4FdvnIv/ZY/jPDlGF3mNYii0FpYhAejqxI+fQ+81qrGMyAA/XucrytV4EBVm3tDvVd3YN2v96+Jb2Qu0xLMWaglKktDt6lDVPLKbPsaFcwhcH25tMDr/J4FFe2JWAYVr9g/10iVXuiIJSpLQyDBJmvcfg1+1ZYnoTgLp3ZwweULeuvZWLEyk6FJQipdGFC3z71Ey67B3Aae7BBjOv97/O+Jle3OZRaZFSS0EpUsqkrvyUsT3P82bKNAxsCfKO5/3P3GjWXHNGimRHwxeLlBbXrnHwiZE0eqEq01JexcCWHv+9xk+nPGjWXL8KRG5HZ5QipYBpy9fMfOY7RseHk4Yjd7lcZ/FyR558xtPapYkUefozUqQkS0nhdM+JtGhlx+vxo0jDkfZNr/DLqbI8+Yw67Ijkhs4oRUooY/8BlrdbzasXhpGIO2XtU5g9C3r09y62gweIWIOCUqSkMZm4NHYufSLuYY2RMXhA05pXWL7Om8qVrVybSDGkoBQpSU6eZN0Ti+h1OIyL+GFvc5OJo9MYEu5dIgYPELEGBaVISWAYJL79AWGDzLyb/gYAtSte5YO1ngTX171IkTuhoBQp7mJj2fX0TLrs6sNJqmCDmdd6JzLxLS+cnKxdnEjxp6AUKcbSVq8lvMsppt2Yghk7KnnFs3x1WZo/6mHt0kRKDD0eIlIcXU/kl/+OJeR/gUy9MRAzdnR78goHT3vQ/FHdjBTJTzqjFClmmrCThQ22M+raSFJxwsf5Ou8sc+SpZ72tXZpIiaQzSpHi4tJFxjAeB24y5NpoUnHi8caX+flkWZ56Vh12RAqKzihFirqrV4ket4jJb3uymOGk4YhrmRRmzTDo9Uo5DR4gUsAUlCJF1fXrxE15h2kzyzAv9VVu4AKAF5fZscuZOo1crFygSOmgoBQpalJSuDZrKTMnJTMruQ/XcQMgpGoce46X4yrlqByUZOUiRUoPBaVIUXHzJtcXfMBbYy7xZkIfruEFQP2gK0ya68nDDzjjVl7XWUUKm4JSxNpMJm68/wkLhp5k6uVeXMIXgJr+V5k4242n/pcxiHnSRSvXKVJKKShFrMUwSPvkC94b9DOTontwgecAqOpzjfFvutCxs5fGZxUpAorE4yHz588nKCgIJycnQkJC2Lt3722XXbx4Mc2aNcPLywsvLy9atmyZ4/IiRY5hkL7xK5ZWnki1jsH0jx7DBQK42zOed+elcOiCJ526OSgkRYoIqwflxx9/TFhYGOHh4ezfv5969eoRGhrKxYvZX2favn07zz//PF9//TW7d+8mMDCQ1q1bc/78+UKuXMRy5m92sqrmBGo9Xokep8fyO0GUd01k3rRkjsZ40HOAE/Z6JFKkSLExDMOwZgEhISE88MADzJs3DwCz2UxgYCCvvPIKw4cP/9f1TSYTXl5ezJs3jy5duvzr8gkJCXh4eBAfH4+7u/sd1y+SG8aP+/iizwbGHHiKX6gDgI/zdYYPM3hpqBsuuXjSI+liEmX9XAG4HpuEq69rQZYsUuLlNg+seo8yLS2Nffv2MWLEiMw2W1tbWrZsye7du3O1jeTkZG7evIm3d/bDd6WmppKampr5PiEh4c6KFrGA8eshNvX5lDHfPcaPjAXAwyGZoQNv8uoYD9zcrFygiPwrq156jYuLw2Qy4efnl6Xdz8+PmJiYXG1j2LBhVKhQgZYtW2b7eUREBB4eHpmvwMDAO65b5F+dPMn21lNoVvsKbb4bw488gGuZFEb1v8qpGBdGTVNIihQXVr9HeSemTp3KqlWr+Pzzz3G6zcR7I0aMID4+PvN19uzZQq5SSpXz5/n+qTdoVfUkLTaPZBdNcbJN5bWucZy64MSk+V54eVm7SBGxhFUvvfr4+GBnZ0dsbGyW9tjYWMqXL5/jutOnT2fq1Kls2bKFunXr3nY5R0dHHB0d86Vekdu6dImosPcZs/I+1puHAWBvc5PeT19l5GxfAgL0MyhSXFn1jNLBwYEGDRqwdevWzDaz2czWrVtp3LjxbdebNm0aEydOJDIykoYNGxZGqSLZu3aNwy+9xbMVvqX+h6+x3vw4dqTTo20MR0/aM/8TXwICrF2kiNwJqw84EBYWRteuXWnYsCGNGjVi9uzZJCUl0b17dwC6dOlCQEAAERERALzxxhuMHTuWlStXEhQUlHkvs2zZspQtW9Zq30NKmaQkToS/z/i5XqxIG4AZO2ww83yLGMIX+FOtes5XRESk+LB6UHbs2JFLly4xduxYYmJiCA4OJjIyMrODz5kzZ7C1/evEd8GCBaSlpfHMM89k2U54eDjjxo0rzNKlNEpN5UzECiZNs2fJjd6Y/vhP6KmQ80xYXIHadSpYuUARyW9Wf46ysOk5SsmT9HRi5nzMlHFpLLreiTQy7jm2qXueiYvL06BRwQ+jo+coRfJXsXiOUqTIM5u5/O7nTBt2mbnXXsycE/KRaheY9I4vDzXXDUiRkk5BKZIdwyB+1ZfMHHSGWRc7kUjGX5sPVrrApAU+PPpYBWw045VIqaCgFPk7wyBp/dfM7X+Yaeee5yptAQj2j2HSWx60fVoBKVLaKChF/pDy9W4W9t5HxIn/cZFHAajpE8uEN114qkt5bIv18BwiklcKSin10n74iSU9djLplyc5T8bzu1U8LjF+igPP9fXTdFcipZyCUkqt9F9+48MeWxn/Q1tOMwCAQNfLjB0DXcPu0nRXIgIoKKUUMp84xSc9viT8m0c58kdAlne6yqihN+k9yheNeCgif6eglFLDOH+Btb3XMebLJvxMfwDKOSQwbEASAyb552pOSGuJjorl5O5YIGNc46hPT+Dsbo9/LW/8g/1yXllE7oiCUko841Icm/t/zuhP6/OD0RcA9zJJDOlxlYFvViwWA08sGnSY8TseyXzftH9GYIY338647QpKkYKkoJTCEx2d8fonf/+MV35LSOCbgZ8y+oNqfGvqDYCrbTIDn7/Ea29Vwtu7+Ixs03d2Ddr/eviWdv9aNaxQjUjpoqCUQhM9fQXRM1fe0u4f1gn/GUPyb0fJyex5/VPGLKrI5vSMwfUdbVLp/+QFhi8MwtevUv7tq5D4B/vpEquIlSgopdAsoi/juTUQw0lkXH7sIDWVn8I/Y8xsb9aldgbAnjR6tT7LqHfvISDwnvzYi4iUMgpKKTR9h7jRqs0NmrZyBmDn5hs4ezvj7+92ZxtOT+fwG2sZN8WB/0t+HgBbTHRtdpIxSypzT9Uqd1q6iJRiCkopNP7+4G5nznwfXNeMq+8dbNBs5uS8jYwfk86HCU9iJmNkgOcaHmPckkpUr3PvHVYsIqKglOLIMDi3fCuThlzlvcsdSCdjZIAOtY8x/r1A6jZSQIpI/lFQSrESu/pbIl65wMKYJ0nFCYDHqh5nwjvleaCFAlJE8p+CUoqFy5t+5M0+x5h7pj3JNAOgeeAJJi3woenjVa1cnYiUZApKKdLid/7MrJ6/MPPo4yTSEIAQv1NMmuPOf56toimvRKTAKSilSEo6cJR53X5k2sFQrlAHgHreZ5g0zZHHe9yjgBSRQqOglCIl5cjvLOqyiyl7/8NFOgFQw/0cEybY8N9X7tackCJS6BSUUiTcPBvD0i5fM3F7U879EZCVXaIZN/ImnYbfrTkhRcRqFJRiVaZLV1jRfQvjNzbkpJExWEBFx4uMHXydbhMqa05IEbE6BaVYhSuJfNF7AxPX1+c387MA+NlfZmSfy/SZXg0npzsZiUBEJP8oKKVQpcdcogObOMa9vLD2OQC87a4xrHM0A+beh2vZclauUEQkKwWlFDzD4Pzne1kcfo7FvzzIBf4LgLttIq89fZpB79TC3dPTujWKiNyGglIKjPlqPFtGfc2CD8uyLvERTIQA4MUVAjjHxoNBBNaqY+UqRURypqCUfHdpy08sHXmMRT/ez0mjQ2Z78/JH6NHdoGvEfVzFG++7kqxXpIhILikoJV8YScnsmvQ1C9+x5ZMrj5JGPQA8bBPo0uwU/d6oTM2Q6iRdTKJrhJWLFRGxgIJS7kj8nt/4cNjPLPy2Jr+YH89sb+h9gn69zTw3uiquZetZsUIRkTujoBTLpaayf+Z2Fr6VxsqYFiRxHwDONjfo1PAY/SYH0rCVJksWkZJBQSm5lnzoNB8P/ZGFX93D3vTQzPaabmfo92ISnSdVx9O7rhUrFBHJfwpKyZnJxG+LdrBwWgLLf2/ONZ4BwJ40nql9hH7hfjR7+m4NUi4iJZaCUrKV9ns0nw/9joVr/dme+mhm+z3O0fR9+jLd37gP3wp6tENESj4FpfzFbOb0yu9YPCmW9448RCxPA2CLiSeq/sZLI7xo3a0Ctrb+Vi5URKTwKCgF08XLfDniGxau8mRjcnMMMuay8neIo1fbaHpPu5fAe2tZuUoREetQUJZWhkHMhn28N+YU70SFcIanMj9qWfE3Xgpzpt3LlbC397FikSIi1qegLGWMhES+Hvs1C5c58nn8o6TTEMgYmLz7o2foO60K9wbfZ+UqRUSKDgVlKXHlm19YPvwwC78P5qjRPrO9ie8x+r1ky/+GVcbJuYAf7YiOhl9PA40z3h88CN6O4O+f8RIRKYIUlCWYkXyDvW98zYK3DT6Oe5QUagNQ1jaJzo1P0DciiHrN7i20eqKnr+DkzM+BXQBEtRqCMzfwD+uE/4whhVaHiIglFJQl0PUDx1j5ehQLvq5OlKltZns9z9O81D2VTuOq4eZe+AMDLKIv4/krEJv+EZjhJDKu0KsREckdBWVJcfMmP7/1NQtn3eCD8y1I5H8AOJJKx/pHeGliACFtg6w6MEDfIW60f+HWdn9/t8IvRkQklxSUxVzK0TOsfn0vCzbezXc3W2e23+t6nn7PJ9BtSjW87yoaw8rpVqSIFEcKyuLIZOL40m9ZNPUKS088zOU/hpUrw0063HeEfmPu4tHnA7CxCbByoSIixZ+Cshi5eS6WdcN2svAzXzanPJLZHugYS58Ol+g5rTr+d9e2XoEiIiWQgrKoMwzOrf6exePP8+6vjbnwx7ByNphpc89v9BvqTts+FbGz87NyoSIiJZOCsogyX77K5lHbWbDCjXXXW2DGDgBf+yv0DD1H72nVuKdGTStXKSJS8ikoixLD4NLmKJaOOsaifQ05afw1rFxz/6O89Ko9T4Xdg4ODtxWLFBEpXRSURYBxPYmdE7ax4F17Pr3agjTqA+Bhm0DXh0/Tb1plajxQzcpVioiUTgpKK4rffYgPhv3Cwl21+dXcLrP9gXIn6NfH4LlRVXBxLRqPdoiIlFYKysKWmsq+6dtYODedlbGPkkzGfUYXm2Q6NTpOv8mBNPhPFSsXKSIif1JQFpLkX06yauiPLNxSlR/S22S213Q7y0tdkug8sRoeXjp7FBEpahSUloqOznj9U3bDzqSnc3jBdhZOT2T5mRbE8ywADqTyTJ2j9BvvT9MOgVYdVk5ERHKmoLRQ9PQVRM9ceUv732fASDt1ns+G7mbhugB2pLXMXKayczR9/3eF7lOrc5d/nUKrWURE8k5BaaF/zoDxp3FGPF3e/5Z3Jl9kydGmXPxjWDlbTLS79zdeGulNqy7+2NpqsFMRkeLExjAMw9pFFKaEhAQ8PDyIj4/H3d3d4vWjo+Hkrzdo2soZgF0fn+XIhz/wf1u82XTjYQxsAajgcIneT8TQa1o1KlZxzNfvICIidy63eaAzSgv5+4O7rYkH2MPdnOG5jiGc5b+Zn7cK/I2XXnPhif53Y29/lxUrFRGR/KCgzIPtsw5wgAf5gRAAytldo3vLM/SdVpWqde+zcnUiIpKfbK1dQHHUsEcdHEmhKsd47/XfOHfdkzcj61K1rou1SxMRkXymM8o8KOtpzw0cOc69dHwtCScna1ckIiIFRWeUeWTW3xgiIqWCfttbKDoqlpO7Y4GMUXSiPj2Bs7s9/rW88Q/WnJAiIiWNzigttGjQYZr2/2uouab969LgxRosGnTYilWJiEhB0RmlhfrOrkH7X28NRf9aNaxQjYiIFDQFpYX8g/10iVVEpBTRpVcREZEcKChFRERyUCSCcv78+QQFBeHk5ERISAh79+7NcflPPvmE++67DycnJ+rUqcPGjRsLqVIRESltrB6UH3/8MWFhYYSHh7N//37q1atHaGgoFy9ezHb57777jueff56ePXty4MABOnToQIcOHfjll18KuXIRESkNrD57SEhICA888ADz5s0DwGw2ExgYyCuvvMLw4cNvWb5jx44kJSWxfv36zLYHH3yQ4OBgFi5c+K/7u9PZQ0REpGTIbR5Y9YwyLS2Nffv20bLlX5Mb29ra0rJlS3bv3p3tOrt3786yPEBoaOhtl09NTSUhISHLS0REJLesGpRxcXGYTCb8/LI+buHn50dMTEy268TExFi0fEREBB4eHpmvwMDA/CleRERKBavfoyxoI0aMID4+PvN19uxZa5ckIiLFiFUHHPDx8cHOzo7Y2Ngs7bGxsZQvXz7bdcqXL2/R8o6Ojjg6OuZPwSIiUupY9YzSwcGBBg0asHXr1sw2s9nM1q1bady4cbbrNG7cOMvyAJs3b77t8iIiInfC6kPYhYWF0bVrVxo2bEijRo2YPXs2SUlJdO/eHYAuXboQEBBAREQEAAMHDqR58+bMmDGDxx9/nFWrVvHjjz/yzjvvWPNriIhICWX1oOzYsSOXLl1i7NixxMTEEBwcTGRkZGaHnTNnzmBr+9eJb5MmTVi5ciWjR49m5MiR3HvvvaxZs4batWtb6yuIiEgJZvXnKAubnqMUEREoJs9RioiIFHVWv/Ra2P48gdbAAyIipdufOfBvF1ZLXVAmJiYCaOABEREBMnLBw8Pjtp+XunuUZrOZCxcu4Obmho2NjbXLKRAJCQkEBgZy9uxZ3YfNAx2/vNOxyzsdu7zL67EzDIPExEQqVKiQpdPoP5W6M0pbW1sqVqxo7TIKhbu7u/6DuwM6fnmnY5d3OnZ5l5djl9OZ5J/UmUdERCQHCkoREZEcKChLIEdHR8LDwzXGbR7p+OWdjl3e6djlXUEfu1LXmUdERMQSOqMUERHJgYJSREQkBwpKERGRHCgoRUREcqCgLKbmz59PUFAQTk5OhISEsHfv3tsuu3jxYpo1a4aXlxdeXl60bNkyx+VLA0uO39+tWrUKGxsbOnToULAFFmGWHrtr164xYMAA/P39cXR0pFq1amzcuLGQqi1aLD12s2fPpnr16jg7OxMYGMjgwYNJSUkppGqLjm+++YZ27dpRoUIFbGxsWLNmzb+us337du6//34cHR2pWrUqy5Yty3sBhhQ7q1atMhwcHIwlS5YYv/76q9G7d2/D09PTiI2NzXb5Tp06GfPnzzcOHDhgHD582OjWrZvh4eFhnDt3rpArLxosPX5/OnXqlBEQEGA0a9bMePLJJwun2CLG0mOXmppqNGzY0Gjbtq2xc+dO49SpU8b27duNqKioQq7c+iw9ditWrDAcHR2NFStWGKdOnTI2bdpk+Pv7G4MHDy7kyq1v48aNxqhRo4zPPvvMAIzPP/88x+VPnjxpuLi4GGFhYcahQ4eMuXPnGnZ2dkZkZGSe9q+gLIYaNWpkDBgwIPO9yWQyKlSoYERERORq/fT0dMPNzc1Yvnx5QZVYpOXl+KWnpxtNmjQx3n33XaNr166lNigtPXYLFiwwKleubKSlpRVWiUWWpcduwIABxqOPPpqlLSwszHjooYcKtM6iLjdB+frrrxu1atXK0taxY0cjNDQ0T/vUpddiJi0tjX379tGyZcvMNltbW1q2bMnu3btztY3k5GRu3ryJt7d3QZVZZOX1+E2YMAFfX1969uxZGGUWSXk5dmvXrqVx48YMGDAAPz8/ateuzZQpUzCZTIVVdpGQl2PXpEkT9u3bl3l59uTJk2zcuJG2bdsWSs3F2e7du7Mca4DQ0NBc/478p1I3KHpxFxcXh8lkws/PL0u7n58fv/32W662MWzYMCpUqHDLD1JpkJfjt3PnTt577z2ioqIKocKiKy/H7uTJk2zbto0XXniBjRs3cvz4cfr378/NmzcJDw8vjLKLhLwcu06dOhEXF0fTpk0xDIP09HT69evHyJEjC6PkYi0mJibbY52QkMCNGzdwdna2aHs6oyxlpk6dyqpVq/j8889xcnKydjlFXmJiIp07d2bx4sX4+PhYu5xix2w24+vryzvvvEODBg3o2LEjo0aNYuHChdYurcjbvn07U6ZM4e2332b//v189tlnbNiwgYkTJ1q7tFJHZ5TFjI+PD3Z2dsTGxmZpj42NpXz58jmuO336dKZOncqWLVuoW7duQZZZZFl6/E6cOMHp06dp165dZpvZbAagTJkyHDlyhCpVqhRs0UVEXn72/P39sbe3x87OLrOtRo0axMTEkJaWhoODQ4HWXFTk5diNGTOGzp0706tXLwDq1KlDUlISffr0YdSoUTnOn1jalS9fPttj7e7ubvHZJOiMsthxcHCgQYMGbN26NbPNbDazdetWGjdufNv1pk2bxsSJE4mMjKRhw4aFUWqRZOnxu++++/j555+JiorKfLVv354WLVoQFRVFYGBgYZZvVXn52XvooYc4fvx45h8XAEePHsXf37/UhCTk7dglJyffEoZ//sFhaIjuHDVu3DjLsQbYvHlzjr8jc5SnLkBiVatWrTIcHR2NZcuWGYcOHTL69OljeHp6GjExMYZhGEbnzp2N4cOHZy4/depUw8HBwVi9erURHR2d+UpMTLTWV7AqS4/fP5XmXq+WHrszZ84Ybm5uxssvv2wcOXLEWL9+veHr62tMmjTJWl/Baiw9duHh4Yabm5vx0UcfGSdPnjS++uoro0qVKsazzz5rra9gNYmJicaBAweMAwcOGIAxc+ZM48CBA8bvv/9uGIZhDB8+3OjcuXPm8n8+HjJ06FDj8OHDxvz58/V4SGk0d+5c4+677zYcHByMRo0aGd9//33mZ82bNze6du2a+b5SpUoGcMsrPDy88AsvIiw5fv9UmoPSMCw/dt99950REhJiODo6GpUrVzYmT55spKenF3LVRYMlx+7mzZvGuHHjjCpVqhhOTk5GYGCg0b9/f+Pq1auFX7iVff3119n+DvvzeHXt2tVo3rz5LesEBwcbDg4ORuXKlY2lS5fmef+aZktERCQHukcpIiKSAwWliIhIDhSUIiIiOVBQioiI5EBBKSIikgMFpYiISA4UlCIiIjlQUIoUIUFBQcyePTvXyy9btgxPT88Cq+dP27dvx8bGhmvXrhX4vrIzbtw4goODrbJvEQWlSC5069YNGxubW16PPfaYVevq2LEjR48etWoNfwoKCso8Li4uLtSpU4d3333X4u3Y2NiwZs2aLG1Dhgy5ZexOkcKi2UNEcumxxx5j6dKlWdocHR2tVE0GZ2fnPM2GUFAmTJhA7969SU5O5pNPPqF3794EBATQpk2bO9pu2bJlKVu2bD5VKWIZnVGK5JKjoyPly5fP8vLy8gIyLk06ODjw7bffZi4/bdo0fH19M6f7eeSRR3j55Zd5+eWX8fDwwMfHhzFjxuQ4E8TMmTOpU6cOrq6uBAYG0r9/f65fv575+T8vvf55ifKDDz4gKCgIDw8PnnvuORITEzOXMZvNREREcM899+Ds7Ey9evVYvXp1lv1u3LiRatWq4ezsTIsWLTh9+nSujpGbmxvly5encuXKDBs2DG9vbzZv3pz5+Q8//ECrVq3w8fHBw8OD5s2bs3///szPg4KCAHjqqaewsbHJfP/PS69ms5kJEyZQsWJFHB0dCQ4OJjIyMlc1ilhKQSmSDx555BEGDRpE586diY+P58CBA4wZM4Z33303y0zry5cvp0yZMuzdu5c5c+Ywc+bMHC9P2tra8tZbb/Hrr7+yfPlytm3bxuuvv55jLSdOnGDNmjWsX7+e9evXs2PHDqZOnZr5eUREBO+//z4LFy7k119/ZfDgwbz44ovs2LEDgLNnz/Lf//6Xdu3aERUVRa9evRg+fLhFx8NsNvPpp59y9erVLNNpJSYm0rVrV3bu3Mn333/PvffeS9u2bTOD/IcffgBg6dKlREdHZ77/pzlz5jBjxgymT5/OwYMHCQ0NpX379hw7dsyiOkVyJc/DqYuUIl27djXs7OwMV1fXLK/JkydnLpOammoEBwcbzz77rFGzZk2jd+/eWbbRvHlzo0aNGobZbM5sGzZsmFGjRo3M95UqVTJmzZp12zo++eQTo1y5cpnvly5danh4eGS+Dw8PN1xcXIyEhITMtqFDhxohISGGYRhGSkqK4eLiYnz33XdZttuzZ0/j+eefNwzDMEaMGGHUrFkzy+fDhg0zgBxnrqhUqZLh4OBguLq6GmXKlDEAw9vb2zh27Nht1zGZTIabm5uxbt26zDbA+Pzzz7MsFx4ebtSrVy/zfYUKFbIce8MwjAceeMDo37//bfclkle6RymSSy1atGDBggVZ2ry9vTP/7eDgwIoVK6hbty6VKlVi1qxZt2zjwQcfxMbGJvN948aNmTFjBiaTKXNS3r/bsmULERER/PbbbyQkJJCenk5KSgrJycm4uLhkW2dQUBBubm6Z7/39/bl48SIAx48fJzk5mVatWmVZJy0tjfr16wNw+PBhQkJCsnye2wlvhw4dSrdu3YiOjmbo0KH079+fqlWrZn4eGxvL6NGj2b59OxcvXsRkMpGcnMyZM2dytX2AhIQELly4wEMPPZSl/aGHHuKnn37K9XZEcktBKZJLrq6uWX7pZ+e7774D4MqVK1y5cgVXV9c87+/06dM88cQTvPTSS0yePBlvb2927txJz549SUtLu21Q2tvbZ3lvY2OD2WwGyLy/uWHDBgICArIslx8dk3x8fKhatSpVq1blk08+oU6dOjRs2JCaNWsC0LVrVy5fvsycOXOoVKkSjo6ONG7cmLS0tDvet0hB0T1KkXxy4sQJBg8ezOLFiwkJCaFr166ZAfWnPXv2ZHn/53267M4m9+3bh9lsZsaMGTz44INUq1aNCxcu3FGNNWvWxNHRkTNnzmQG2p+vwMBAAGrUqMHevXtvqdNSgYGBdOzYkREjRmS27dq1i1dffZW2bdtSq1YtHB0diYuLy7Kevb09JpPpttt1d3enQoUK7Nq1K0v7rl27MgNZJD8pKEVyKTU1lZiYmCyvP3/Jm0wmXnzxRUJDQ+nevTtLly7l4MGDzJgxI8s2zpw5Q1hYGEeOHOGjjz5i7ty5DBw4MNv9Va1alZs3bzJ37lxOnjzJBx98wMKFC+/oO7i5uTFkyBAGDx7M8uXLOXHiBPv372fu3LksX74cgH79+nHs2DGGDh3KkSNHWLlyJcuWLcvT/gYOHMi6dev48ccfAbj33nv54IMPOHz4MHv27OGFF1645fGWoKAgtm7dSkxMDFevXs12u0OHDuWNN97g448/5siRIwwfPpyoqKjbHkuRO2Ltm6QixUHXrl0N4JZX9erVDcMwjPHjxxv+/v5GXFxc5jqffvqp4eDgYERFRRmGkdGZp3///ka/fv0Md3d3w8vLyxg5cmSWzj3/7Mwzc+ZMw9/f33B2djZCQ0ON999/P0unmuw68/y904thGMasWbOMSpUqZb43m83G7NmzjerVqxv29vbGXXfdZYSGhho7duzIXGbdunVG1apVDUdHR6NZs2bGkiVLctWZJ7uOSKGhoUabNm0MwzCM/fv3Gw0bNjScnJyMe++91/jkk09uWW/t2rVG1apVjTJlymTW/c/vZTKZjHHjxhkBAQGGvb29Ua9ePePLL7+8bW0id8LGMHJ4iEtE8s0jjzxCcHCwRUPUiYj16dKriIhIDhSUIiIiOdClVxERkRzojFJERCQHCkoREZEcKChFRERyoKAUERHJgYJSREQkBwpKERGRHCgoRUREcqCgFBERyYGCUkREJAf/DxkRnk3FSHAEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))\n",
    "ax.errorbar(explained_variances, roberta_base_dirs.mean(dim=0).tolist(), yerr= roberta_base_dirs.std(dim=0).tolist(), label=\"RoBERTa Base\", color='r', capsize=2)\n",
    "ax.errorbar(explained_variances, roberta_large_dirs.mean(dim=0).tolist(), yerr= roberta_base_dirs.std(dim=0).tolist(), label=\"RoBERTa Large\", color='b', capsize=2)\n",
    "ax.set_xlabel(\"Explained Ratio\")\n",
    "ax.set_ylabel(\"Directions Considered\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a39e3e-2c84-458e-a47f-5e5a86443278",
   "metadata": {},
   "source": [
    "The above results suggest you need most of the directions to account for the explained variance in the parameters.\n",
    "As such, we finetune the models for SQuAD and review the difference in the weights of the base and the tuned model. If the difference has \n",
    "fewer principle directions with high explanation, it would mean it is possible that task-based fine-tuning can be done in a smaller subspace.\n",
    "Let's add a final touch to the above results by looking at the ratio of number of significant principle directions and all directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a1ff52-126c-4665-92fd-c3e5d8c83fb2",
   "metadata": {},
   "source": [
    "## Rank Variation During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d59c3413-b156-4dfd-a1f5-1df488ff818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Dataset\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from train.train import train_epoch\n",
    "from utils.metrics import AverageMeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "719ff899-edf9-4f7e-b665-ea440ef6bc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Training Configuration\n",
    "with hydra.initialize(version_base=None, config_path=\"../config\"):\n",
    "    cfg = hydra.compose(config_name=\"app_config\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9efb6c9-3495-4760-9c2b-094fa47b98bd",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4b82e45-bb22-4aea-b6ac-1c2ef67ab9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Data\n",
    "train_dataset = load_dataset(\"squad\", split=\"train\")\n",
    "val_dataset = load_dataset(\"squad\", split=\"validation\")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0bab19-fe5f-41d3-a4c8-282bbda8647d",
   "metadata": {},
   "source": [
    "#### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76dfbf26-bbad-4d73-933a-652dded44c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Max Length is 512\n",
      "Dataset Features are {'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model Max Length is {tokenizer.model_max_length}\")\n",
    "print(f\"Dataset Features are {train_dataset.features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c89dd9c-1957-45c8-8461-e69b41717cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to Remove\n",
    "remove_columns=['question', 'context', 'id', 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19b45799-1fa8-4ed4-a7c2-b3004997e9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 143 training instances with length longer than 512\n"
     ]
    }
   ],
   "source": [
    "cut_off_length = 512\n",
    "long_dataset = train_dataset.filter(lambda x: len(tokenizer(x['question'], x['context']).input_ids) > cut_off_length)\n",
    "print(f\"There are {long_dataset.num_rows} training instances with length longer than {cut_off_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932bb38a-5b28-4dbd-9faa-0aa9571a02e7",
   "metadata": {},
   "source": [
    "Since there are only 143 instances with the length longer than 512. I will remove those instances for the purpose of simplicity. These changes are unlikely to affect the outcome. The learned concept will not account for\n",
    "the cases in which the context may not contain the answer. Also, if there is a regularity in the placement of the answer in the question, the model may over fit to it. But given large number of samples, I assume it is not\n",
    "the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "119e8460-86c9-40d3-8fdb-2ac52d692766",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.filter(lambda x: len(tokenizer(x['question'], x['context']).input_ids) <= cut_off_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dbd6078-c403-46ae-9aee-abd56889548b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188\n",
      "['a copper statue of Christ']\n",
      "a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.\n"
     ]
    }
   ],
   "source": [
    "## Let's See how the answer looks like\n",
    "idx = 1\n",
    "instance = train_dataset[idx]\n",
    "answer = instance['answers']\n",
    "print(answer['answer_start'][0])\n",
    "print(answer['text'])\n",
    "print(instance['context'][answer['answer_start'][0]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae666051-6c8c-4e42-995e-adc84cef27fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer is not character based\n"
     ]
    }
   ],
   "source": [
    "# The above indicates the answer_start is the beginning character. Let's see if this is consistent with the rest of the results\n",
    "char_tokenizer = True\n",
    "for idx, item in enumerate(train_dataset):\n",
    "    start = item['answers']['answer_start'][0]\n",
    "    end = start + len(item['answers']['text'][0])\n",
    "    extracted_answer = item['context'][start:end]\n",
    "    answer = item['answers']['text'][0]\n",
    "    if extracted_answer != answer:\n",
    "        print(idx, extracted_answer, answer)\n",
    "    if char_tokenizer:\n",
    "        tokenized_answer = tokenizer(answer).input_ids\n",
    "        char_tokenizer = len(tokenized_answer) - 2 == len(answer)\n",
    "\n",
    "if not char_tokenizer:\n",
    "    print(\"Tokenizer is not character based\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c37f437-6dbf-4a61-a180-42285188b5c2",
   "metadata": {},
   "source": [
    "The above result confirms that the answers are made available in terms of character offset instead of tokenizer offset. This is likely the case to maintain generality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1e3db4e-f142-4acd-ae85-0ff707c3384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bisect_custom(l, r, tokenizer, tokenized_context, target, l_off=0, r_off=0, mid_off=0):\n",
    "    # Standard Binary Search with a Few Bells and Whistles\n",
    "    while l < r:\n",
    "        mid = l + (r - l + mid_off) // 2\n",
    "        partial_context = tokenizer.decode(tokenized_context[:mid])\n",
    "        if len(partial_context) <= target:\n",
    "            l = mid + l_off\n",
    "        else:\n",
    "            r = mid + r_off\n",
    "        # print(r, l, mid)\n",
    "    return max(l, r)\n",
    "\n",
    "def get_start_end_index(tokenized_context, answer, answer_start):\n",
    "    # Set Answer End Index\n",
    "    answer_end = answer_start + len(answer)\n",
    "\n",
    "    # Search for the starting index of the Token That contains the answer\n",
    "    ll, rl = 0, len(tokenized_context)\n",
    "    # print(\"Starting Left Search\")\n",
    "    start_index = bisect_custom(ll, rl, tokenizer, tokenized_context, answer_start, r_off=-1, mid_off=1)\n",
    "\n",
    "    # Search for the ending index of the tokens in which the answer terminates\n",
    "    rl, rr = start_index, len(tokenized_context)\n",
    "    # print(\"Starting Right Search\")\n",
    "    end_index = bisect_custom(start_index, len(tokenized_context), tokenizer, tokenized_context, answer_end, l_off=1)\n",
    "    \n",
    "    return start_index, end_index\n",
    "\n",
    "def validate(tokenized_context, start_index, end_index, idx, answer, context, question, ret):\n",
    "    # Test if the correct Solution is found by extracting the partial context and checking if the answer is contained.\n",
    "    # While this is not a 100% foolproof solution. Informal tests before confirmed this to be the case.\n",
    "    # You can set the extracted_answers char offset to answer_start\n",
    "    extracted_context = tokenized_context[start_index:end_index]\n",
    "    extracted_answer = tokenizer.decode(extracted_context).strip()\n",
    "    \n",
    "    if extracted_answer.find(answer) == -1:\n",
    "        failed_instance = {\"idx\" : idx, \n",
    "                           \"start_index\" : start_index,\n",
    "                           \"end_index\" : end_index,\n",
    "                           \"extracted_answer\" : extracted_answer,\n",
    "                           \"answer\" : answer,\n",
    "                           \"context\" : context,\n",
    "                           \"question\" : question} \n",
    "        ret.append(failed_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be31a5ad-b61e-475d-874e-db47e377ea5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d5abbcd72344e5ae24dfdd11a4b95e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's tokenize the start and end character\n",
    "failed_indices = []\n",
    "for idx, item in tqdm(enumerate(train_dataset)):\n",
    "    question = item['question']\n",
    "    context = item['context']\n",
    "    \n",
    "    answer = item['answers']['text'][0]\n",
    "    answer_start = item['answers']['answer_start'][0]\n",
    "\n",
    "    # Extract Start and End Index of the Tokenized Question/Context Duo\n",
    "    tokenized_question = tokenizer(question).input_ids\n",
    "    tokenized_context = tokenizer(question, context).input_ids\n",
    "    start_index, end_index = get_start_end_index(tokenized_context, answer, answer_start + len(question) + 10)\n",
    "\n",
    "    # Test if the correct Solution is found\n",
    "    validate(tokenized_context, start_index, end_index, idx, answer, context, question, failed_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d26eb5e8-1043-40ff-8920-b8693db68547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 71 failed instances by the above method\n"
     ]
    }
   ],
   "source": [
    "print(fr\"There are {len(failed_indices)} failed instances by the above method\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "726329a5-b44d-4615-9c2c-35ac09a49789",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_failed_instances = []\n",
    "\n",
    "def process_batched_training_examples(instances):\n",
    "    questions, contexts = instances['question'], instances['context']\n",
    "    answers = instances['answers']\n",
    "    \n",
    "    inputs = tokenizer(questions, contexts) # Batched Tokenization\n",
    "    start_index, end_index = [], [] # Store the start and end_index in the beginning\n",
    "    \n",
    "    for idx, instance in enumerate(instances['id']):\n",
    "        answer_text, answer_start = answers[idx]['text'][0], answers[idx]['answer_start'][0]\n",
    "\n",
    "        start, end = get_start_end_index(inputs.input_ids[idx], answer_text, answer_start + len(questions[idx]) + 10)\n",
    "        \n",
    "        start_index.append(start)\n",
    "        end_index.append(end)\n",
    "\n",
    "        # Result Validation and storing the ones that failed. - map failed instances must be cleared every time to avoid accumulation\n",
    "        validate(inputs.input_ids[idx], start, end, 0, answer_text, contexts[idx], questions[idx], map_failed_instances)\n",
    "\n",
    "    inputs['start_positions'] = start_index\n",
    "    inputs['end_positions'] = end_index\n",
    "\n",
    "    return inputs\n",
    "\n",
    "def process_training_examples(instance):\n",
    "    \n",
    "    question, context = instance['question'], instance['context']\n",
    "    answer = instance['answers']\n",
    "    \n",
    "    inputs = tokenizer(question, context)\n",
    "    \n",
    "    answer_text, answer_start = answer['text'][0], answer['answer_start'][0]\n",
    "\n",
    "    start_index, end_index = get_start_end_index(inputs.input_ids, answer_text, answer_start + len(question) + 10)\n",
    "    \n",
    "    inputs['start_positions'] = start_index\n",
    "    inputs['end_positions'] = end_index\n",
    "\n",
    "    # Result Validation and storing the ones that failed. - map failed instances must be cleared every time to avoid accumulation\n",
    "    validate(inputs.input_ids, start_index, end_index, 0, answer_text, context, question, map_failed_instances)\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5ca9b2a1-63df-4897-b8bc-a91e46ef61ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Column to remove ['question', 'context', 'title', 'id'] not in the dataset. Current columns in the dataset: ['answers', 'input_ids', 'attention_mask', 'start_positions', 'end_positions']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocess_batched_training_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:3076\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3074\u001b[0m     missing_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(remove_columns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names)\n\u001b[1;32m   3075\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing_columns:\n\u001b[0;32m-> 3076\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3077\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn to remove \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(missing_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3078\u001b[0m         )\n\u001b[1;32m   3080\u001b[0m load_from_cache_file \u001b[38;5;241m=\u001b[39m load_from_cache_file \u001b[38;5;28;01mif\u001b[39;00m load_from_cache_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_caching_enabled()\n\u001b[1;32m   3082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Column to remove ['question', 'context', 'title', 'id'] not in the dataset. Current columns in the dataset: ['answers', 'input_ids', 'attention_mask', 'start_positions', 'end_positions']"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    process_batched_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=remove_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02930ef-a55b-44fb-9795-1bb44475e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.save_to_disk(\"../data/squad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d4e98-7a06-4fdc-92d4-8177b5e558b0",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4cadb715-65dc-4ddd-a0e3-11368be102d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7cc1502d954920bb795b0be0221567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10521 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 10521\n",
       "})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset.filter(lambda x: len(x['answers']) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "72715268-e5d5-47f1-b96a-638573644aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ec4aeb6eba4ae591bd1401e5248517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/10521 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'question'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mval_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcut_off_length\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/datasets/fingerprint.py:482\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:3709\u001b[0m, in \u001b[0;36mDataset.filter\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3707\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m-> 3709\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_indices_from_mask_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3716\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3717\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3718\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muint64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3731\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffix_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3733\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFilter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3735\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3736\u001b[0m new_dataset \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   3737\u001b[0m new_dataset\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:3156\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3151\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3152\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3153\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3154\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3155\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3157\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3158\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:3547\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3543\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3544\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3545\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3546\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3547\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3551\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3553\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3554\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3555\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3556\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:3416\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3415\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3416\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3418\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3419\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3420\u001b[0m     }\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:6477\u001b[0m, in \u001b[0;36mget_indices_from_mask_function\u001b[0;34m(function, batched, with_indices, with_rank, input_columns, indices_mapping, *args, **fn_kwargs)\u001b[0m\n\u001b[1;32m   6475\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   6476\u001b[0m             additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 6477\u001b[0m         mask\u001b[38;5;241m.\u001b[39mappend(\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   6478\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6479\u001b[0m     \u001b[38;5;66;03m# inputs is a list of columns\u001b[39;00m\n\u001b[1;32m   6480\u001b[0m     columns: List[List] \u001b[38;5;241m=\u001b[39m inputs\n",
      "Cell \u001b[0;32mIn[94], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m val_dataset\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(tokenizer(\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39minput_ids) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m cut_off_length)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'question'"
     ]
    }
   ],
   "source": [
    "val_dataset = val_dataset.filter(lambda x: len(tokenizer(x['question'], x['context']).input_ids) <= cut_off_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2ddd2ee3-809f-462f-9963-2f47d26673a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_validation_examples(instances):\n",
    "    questions, contexts = instances['question'], instances['context']\n",
    "    inputs = tokenizer(questions, contexts) # Batched Tokenization\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4e4e51ad-b3b3-41c0-b0c6-637170f18a2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Column to remove ['question', 'context', 'title', 'id'] not in the dataset. Current columns in the dataset: ['answers', 'input_ids', 'attention_mask']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mval_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprocess_validation_examples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:602\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:567\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    565\u001b[0m }\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/peft-study/venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:3076\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3074\u001b[0m     missing_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(remove_columns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names)\n\u001b[1;32m   3075\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing_columns:\n\u001b[0;32m-> 3076\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3077\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn to remove \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(missing_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3078\u001b[0m         )\n\u001b[1;32m   3080\u001b[0m load_from_cache_file \u001b[38;5;241m=\u001b[39m load_from_cache_file \u001b[38;5;28;01mif\u001b[39;00m load_from_cache_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_caching_enabled()\n\u001b[1;32m   3082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Column to remove ['question', 'context', 'title', 'id'] not in the dataset. Current columns in the dataset: ['answers', 'input_ids', 'attention_mask']"
     ]
    }
   ],
   "source": [
    "val_dataset = val_dataset.map(\n",
    "    process_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=remove_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e24b2996-8eea-4b7e-8241-530ad19a4b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['answers', 'input_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "print(val_dataset[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a31482-ff23-4244-8f81-6f9656ac8a15",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ab63ac41-7dca-4d80-a70a-cbcec6a5e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from collections import defaultdict\n",
    "pad_keys = ['input_ids', 'attention_mask']\n",
    "stack_keys = [ 'start_positions', 'end_positions']\n",
    "pad_id = tokenizer.pad_token_id\n",
    "\n",
    "def collate_fn(batch):\n",
    "    tensor_batch = defaultdict(list)\n",
    "        \n",
    "    # Generate list of samples in batch\n",
    "    for sample in batch:\n",
    "        for key in pad_keys + stack_keys:\n",
    "            key_tensor = torch.tensor(sample[key])\n",
    "            tensor_batch[key].append(key_tensor)\n",
    "\n",
    "    # padding value of attention_mask is 0 since it is multiplied\n",
    "    tensor_batch['input_ids'] = pad_sequence(tensor_batch['input_ids'], padding_value=pad_id, batch_first=True)\n",
    "    tensor_batch['attention_mask'] = pad_sequence(tensor_batch['attention_mask'], padding_value=0, batch_first=True)\n",
    "    \n",
    "    for key in stack_keys:\n",
    "        tensor_batch[key] = torch.stack(tensor_batch[key])\n",
    "\n",
    "    for k, v in tensor_batch.items():\n",
    "        tensor_batch[k] = v.to(device)\n",
    "\n",
    "    return tensor_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b2f70cea-a6ee-46f2-92b8-4b944cd6d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors for Gradient Accumulation\n",
    "def get_grad_principle_directions(gradient_dictionary, exp_vars):\n",
    "    exp_dirs = []\n",
    "    for key, val in gradient_dictionary.items():\n",
    "        \n",
    "        if min(val.size()) < 2:\n",
    "            continue\n",
    "\n",
    "        curr_dirs = get_principle_directions(val, exp_vars)\n",
    "        curr_dirs = torch.tensor(curr_dirs) / min(val.size())\n",
    "\n",
    "        exp_dirs.append(curr_dirs)\n",
    "    return torch.stack(exp_dirs)\n",
    "        \n",
    "\n",
    "class GradAccumulator:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        \n",
    "        self.model = model\n",
    "        self.accumulator = self.init_grad()\n",
    "    \n",
    "    def init_grad(self):\n",
    "        accumulator = dict()\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if len(param.size()) < 2:\n",
    "                continue\n",
    "                \n",
    "            accumulator[name] = torch.zeros_like(param, requires_grad=False)\n",
    "    \n",
    "        return accumulator\n",
    "\n",
    "    def accumulate_grad(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if name in self.accumulator:\n",
    "                self.accumulator[name] += param.grad\n",
    "\n",
    "    def reset(self):\n",
    "        for key in self.accumulator.keys():\n",
    "            self.accumulator[key] = 0\n",
    "\n",
    "    def analyze_grad(self, exp_vars):\n",
    "        # Move to CPU\n",
    "        for key in self.accumulator.keys():\n",
    "            self.accumulator[key] = self.accumulator[key].cpu()\n",
    "        exp_dirs = get_grad_principle_directions(self.accumulator, exp_vars)\n",
    "        return exp_dirs.mean(dim=0), exp_dirs.std(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0a7bcbd0-1ab7-48b6-b890-79dddf7abbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Training Artifacts\n",
    "training_cfg = hydra.utils.instantiate(cfg.model.model.train)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=training_cfg.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=training_cfg.batch_size)\n",
    "\n",
    "model = roberta_base_model if cfg.model.name == 'roberta-base' else roberta_large_model\n",
    "model.to(device)\n",
    "optimizer = AdamW(params=model.parameters(), lr=training_cfg.lr, weight_decay=training_cfg.weight_decay)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "loss_meter = AverageMeter()\n",
    "acc_meter = AverageMeter()\n",
    "accumulator = GradAccumulator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1efba1f3-4678-4dc2-b887-1191ea32cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ML Flow\n",
    "import mlflow\n",
    "\n",
    "# Set Tracking URI\n",
    "uri = mlflow.get_tracking_uri()\n",
    "if uri is None or uri != \"http://127.0.0.1:8080\":\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Set Experiment\n",
    "experiment_name = f\"{cfg.model.name}-{cfg.dataset.name}\"\n",
    "exps = mlflow.search_experiments(filter_string=f\"name='{experiment_name}'\")\n",
    "\n",
    "if len(exps) == 0:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "else:\n",
    "    experiment_id = exps[0].experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "13ccdfe5-a449-4da3-8e9c-0b1517fe61c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6b01e60b344c529344dae4dc614f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32796 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Loop\n",
    "progress_bar = tqdm(total=training_cfg.epochs * len(train_loader))\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name=experiment_name) as run:\n",
    "    for epoch in range(training_cfg.epochs):\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            # Reset Optimizer to 0\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # Forward Pass\n",
    "            output = model(**batch)\n",
    "        \n",
    "            # Backward Pass\n",
    "            output.loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate Gradient\n",
    "            accumulator.accumulate_grad()\n",
    "            \n",
    "            # Evaluate Performance\n",
    "            start_position_pred = torch.argmax(output.start_logits, dim=1)\n",
    "            end_position_pred = torch.argmax(output.end_logits, dim=1)\n",
    "            correct_exact_matches = ((batch[\"start_positions\"] == start_position_pred) \n",
    "                                     & (batch[\"end_positions\"] == end_position_pred)).sum()\n",
    "            \n",
    "            # Update Meters\n",
    "            acc_meter.update(correct_exact_matches.item(), len(batch))\n",
    "            loss_meter.update(output.loss.item(), 1)\n",
    "\n",
    "            # Update Progress\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        \n",
    "        # Compute Metrics\n",
    "        match_accuracy = acc_meter.average()\n",
    "        training_loss = loss_meter.average()\n",
    "        mean_dirs, std_dirs = accumulator.analyze_grad(explained_variances)\n",
    "\n",
    "        # Reset Accumulator\n",
    "        accumulator.reset()\n",
    "        \n",
    "        \n",
    "        # Track Metrics\n",
    "        mlflow.log_metric(\"training match accuracy\", match_accuracy, step=epoch)\n",
    "        mlflow.log_metric(\"training loss\", training_loss, step=epoch)\n",
    "        \n",
    "        for i, exp_var in enumerate(explained_variances):\n",
    "            mlflow.log_metric(f\"Mean Principle Dir Ratio {exp_var}\", mean_dirs[i], step=epoch)\n",
    "            mlflow.log_metric(f\"Std Dev Principle Dir Ratio {exp_var}\", std_dirs[i], step=epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165b2f4c-7afe-4826-9302-02d4eaf27b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = None\n",
    "for params in model.parameters():\n",
    "    param = params\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50378659-1c48-4fea-9b3a-dff612d13b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "618e1ac9-77d9-4289-a7af-3b3ed5a2a073",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_position = torch.argmax(output.start_logits, dim=1)\n",
    "end_position = torch.argmax(output.end_logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "84c4645c-4f29-44ff-884c-0b4a306c0dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((batch[\"start_positions\"] == start_position) \n",
    " & (batch[\"end_positions\"] == end_position)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5935d06e-6829-4170-8382-57d203cd8467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 3972, 2661, 222, 5, 9880, 2708, 2346, 2082, 11, 504, 4432, 11, 226, 2126, 10067, 1470, 116, 2, 2, 37848, 37471, 28108, 6, 5, 334, 34, 10, 4019, 2048, 4, 497, 1517, 5, 4326, 6919, 18, 1637, 31346, 16, 10, 9030, 9577, 9, 5, 9880, 2708, 4, 29261, 11, 760, 9, 5, 4326, 6919, 8, 2114, 24, 6, 16, 10, 7621, 9577, 9, 4845, 19, 3701, 62, 33161, 19, 5, 7875, 22, 39043, 1459, 1614, 1464, 13292, 4977, 845, 4130, 7, 5, 4326, 6919, 16, 5, 26429, 2426, 9, 5, 25095, 6924, 4, 29261, 639, 5, 32394, 2426, 16, 5, 7461, 26187, 6, 10, 19035, 317, 9, 9621, 8, 12456, 4, 85, 16, 10, 24633, 9, 5, 11491, 26187, 23, 226, 2126, 10067, 6, 1470, 147, 5, 9880, 2708, 2851, 13735, 352, 1382, 7, 6130, 6552, 625, 3398, 208, 22895, 853, 1827, 11, 504, 4432, 4, 497, 5, 253, 9, 5, 1049, 1305, 36, 463, 11, 10, 2228, 516, 14, 15230, 149, 155, 19638, 8, 5, 2610, 25336, 238, 16, 10, 2007, 6, 2297, 7326, 9577, 9, 2708, 4, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "for item in train_dataset:\n",
    "    x = f\"[CLS]{item['question']}[SEP]{item['context']}\"\n",
    "    tokenized_x = tokenizer(item['question'], item['context'])\n",
    "    print(tokenized_x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd23942f-6ea1-4a79-98ae-ddaa0d6a765e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d0c2e-1193-416a-8d95-52dc9e5c3832",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c1c168-4382-4963-bab5-e723a863a4f7",
   "metadata": {},
   "source": [
    "# Introducing LoRA Weights\n",
    "This section introduces LoRA weights in our models for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9a0bca-9500-4e4f-9650-23bfc0a02439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On the surface the above results suggest you need most of the directions to account for most of the directions. \n",
    "# It will be useful to see which directions are affected and how later.\n",
    "from models.LoRA import LoRALinearLayer\n",
    "def add_linear_lora(module, rank, init_type=0):\n",
    "    for key, child in module.named_children():\n",
    "        if isinstance(child, torch.nn.Linear):\n",
    "            lora_layer =  LoRALinearLayer(child, rank=rank, init_type=init_type)\n",
    "            setattr(module, key, lora_layer)\n",
    "        else:\n",
    "            add_linear_lora(child, rank, init_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa02e6c0-2f89-40ab-b387-9c77de31b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_linear_lora(roberta_base, rank=10, init_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe6c9164-4b29-4ad1-b98f-a50c4f368e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (v_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (q_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (out_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): LoRALinear(in_features=768, in_features=3072, rank=$10, init_type=$1)\n",
       "            (fc2): LoRALinear(in_features=3072, in_features=768, rank=$10, init_type=$1)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c66542b-d1f8-417c-bae4-172a31970431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-23): 24 x TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ff436bb-df8a-4baa-af98-0be01d85c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40d88517-de50-4af3-ac05-2096882f94d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /roberta-base/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "model_config = AutoConfig.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "489ec480-9ada-4d51-8c54-a21b050de0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_config(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bb4c7-0028-4504-840b-081200450898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
