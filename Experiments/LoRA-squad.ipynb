{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e45fd35-cdca-44b8-a00f-607078ee1a67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Investigating Appropriate Rank\n",
    "In the first section, I am going to investigate what an appropriate rank to consider should be. It will make sense to look at the \n",
    "ranks of a trained matrix and a randomly initialized matrix. We will start by looking at a randomly initialized matrix and then\n",
    "look at a trained matrix. Specifically, I will look at the rank of a randomly initialized matrix. I will need to consider the sizes \n",
    "that are seen in RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f2172b3-4630-4fed-8bfd-4cf8b3ea7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Appropriate Libraries\n",
    "%load_ext autoreload\n",
    "    \n",
    "import torch\n",
    "import matplotlib.pyplot as plt \n",
    "import bisect\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25dba68b-c775-4672-8fbf-f2bb3da6f1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_principle_direction(A, exp_var):\n",
    "    U, S, V = torch.linalg.svd(A)\n",
    "    X = (torch.cumsum(S, 0) / S.sum().item()).tolist()\n",
    "    num = bisect.bisect(X, exp_var)\n",
    "    return num\n",
    "\n",
    "def plot_results(n=100, size=[768, 768], exp_var=0.99):\n",
    "    results = []\n",
    "    for _ in range(n):\n",
    "        A = torch.randn(size)\n",
    "        num = get_principle_direction(A, exp_var)\n",
    "        results.append(num)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b27c30-3205-4635-b424-9e5e80078d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([47.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 53.]),\n",
       " array([515. , 515.1, 515.2, 515.3, 515.4, 515.5, 515.6, 515.7, 515.8,\n",
       "        515.9, 516. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=3)\n",
    "ax[0].hist(plot_results())\n",
    "ax[1].hist(plot_results(exp_var=0.95))\n",
    "ax[2].hist(plot_results(exp_var=0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601559f6-0a40-40bb-830e-a836a35c5a5b",
   "metadata": {},
   "source": [
    "The above results indicate the rank is very tightly distributed based on the explained variance. The reader is encouraged to play with the explained_variance and support the claim themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c7b6d-5ccd-447e-b545-7349e19e7e90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Now let's look at how tightly the weights are distributed in RoBERTa \n",
    "roberta_large = torch.hub.load('pytorch/fairseq', 'roberta.large') \n",
    "roberta_base = torch.hub.load('pytorch/fairseq', 'roberta.base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd7956d-48ca-4f5f-96e1-72ca43118c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_tokens.weight 745 768\n",
      "embed_positions.weight 439 514\n",
      "layernorm_embedding.weight 768\n",
      "layernorm_embedding.bias 768\n",
      "layers.0.self_attn.k_proj.weight 652 768\n",
      "layers.0.self_attn.k_proj.bias 768\n",
      "layers.0.self_attn.v_proj.weight 667 768\n",
      "layers.0.self_attn.v_proj.bias 768\n",
      "layers.0.self_attn.q_proj.weight 653 768\n",
      "layers.0.self_attn.q_proj.bias 768\n",
      "layers.0.self_attn.out_proj.weight 669 768\n",
      "layers.0.self_attn.out_proj.bias 768\n",
      "layers.0.self_attn_layer_norm.weight 768\n",
      "layers.0.self_attn_layer_norm.bias 768\n",
      "layers.0.fc1.weight 748 768\n",
      "layers.0.fc1.bias 3072\n",
      "layers.0.fc2.weight 748 768\n",
      "layers.0.fc2.bias 768\n",
      "layers.0.final_layer_norm.weight 768\n",
      "layers.0.final_layer_norm.bias 768\n",
      "layers.1.self_attn.k_proj.weight 649 768\n",
      "layers.1.self_attn.k_proj.bias 768\n",
      "layers.1.self_attn.v_proj.weight 665 768\n",
      "layers.1.self_attn.v_proj.bias 768\n",
      "layers.1.self_attn.q_proj.weight 644 768\n",
      "layers.1.self_attn.q_proj.bias 768\n",
      "layers.1.self_attn.out_proj.weight 662 768\n",
      "layers.1.self_attn.out_proj.bias 768\n",
      "layers.1.self_attn_layer_norm.weight 768\n",
      "layers.1.self_attn_layer_norm.bias 768\n",
      "layers.1.fc1.weight 745 768\n",
      "layers.1.fc1.bias 3072\n",
      "layers.1.fc2.weight 746 768\n",
      "layers.1.fc2.bias 768\n",
      "layers.1.final_layer_norm.weight 768\n",
      "layers.1.final_layer_norm.bias 768\n",
      "layers.2.self_attn.k_proj.weight 639 768\n",
      "layers.2.self_attn.k_proj.bias 768\n",
      "layers.2.self_attn.v_proj.weight 661 768\n",
      "layers.2.self_attn.v_proj.bias 768\n",
      "layers.2.self_attn.q_proj.weight 638 768\n",
      "layers.2.self_attn.q_proj.bias 768\n",
      "layers.2.self_attn.out_proj.weight 662 768\n",
      "layers.2.self_attn.out_proj.bias 768\n",
      "layers.2.self_attn_layer_norm.weight 768\n",
      "layers.2.self_attn_layer_norm.bias 768\n",
      "layers.2.fc1.weight 744 768\n",
      "layers.2.fc1.bias 3072\n",
      "layers.2.fc2.weight 744 768\n",
      "layers.2.fc2.bias 768\n",
      "layers.2.final_layer_norm.weight 768\n",
      "layers.2.final_layer_norm.bias 768\n",
      "layers.3.self_attn.k_proj.weight 649 768\n",
      "layers.3.self_attn.k_proj.bias 768\n",
      "layers.3.self_attn.v_proj.weight 660 768\n",
      "layers.3.self_attn.v_proj.bias 768\n",
      "layers.3.self_attn.q_proj.weight 649 768\n",
      "layers.3.self_attn.q_proj.bias 768\n",
      "layers.3.self_attn.out_proj.weight 656 768\n",
      "layers.3.self_attn.out_proj.bias 768\n",
      "layers.3.self_attn_layer_norm.weight 768\n",
      "layers.3.self_attn_layer_norm.bias 768\n",
      "layers.3.fc1.weight 745 768\n",
      "layers.3.fc1.bias 3072\n",
      "layers.3.fc2.weight 744 768\n",
      "layers.3.fc2.bias 768\n",
      "layers.3.final_layer_norm.weight 768\n",
      "layers.3.final_layer_norm.bias 768\n",
      "layers.4.self_attn.k_proj.weight 645 768\n",
      "layers.4.self_attn.k_proj.bias 768\n",
      "layers.4.self_attn.v_proj.weight 655 768\n",
      "layers.4.self_attn.v_proj.bias 768\n",
      "layers.4.self_attn.q_proj.weight 646 768\n",
      "layers.4.self_attn.q_proj.bias 768\n",
      "layers.4.self_attn.out_proj.weight 649 768\n",
      "layers.4.self_attn.out_proj.bias 768\n",
      "layers.4.self_attn_layer_norm.weight 768\n",
      "layers.4.self_attn_layer_norm.bias 768\n",
      "layers.4.fc1.weight 747 768\n",
      "layers.4.fc1.bias 3072\n",
      "layers.4.fc2.weight 744 768\n",
      "layers.4.fc2.bias 768\n",
      "layers.4.final_layer_norm.weight 768\n",
      "layers.4.final_layer_norm.bias 768\n",
      "layers.5.self_attn.k_proj.weight 653 768\n",
      "layers.5.self_attn.k_proj.bias 768\n",
      "layers.5.self_attn.v_proj.weight 660 768\n",
      "layers.5.self_attn.v_proj.bias 768\n",
      "layers.5.self_attn.q_proj.weight 654 768\n",
      "layers.5.self_attn.q_proj.bias 768\n",
      "layers.5.self_attn.out_proj.weight 652 768\n",
      "layers.5.self_attn.out_proj.bias 768\n",
      "layers.5.self_attn_layer_norm.weight 768\n",
      "layers.5.self_attn_layer_norm.bias 768\n",
      "layers.5.fc1.weight 747 768\n",
      "layers.5.fc1.bias 3072\n",
      "layers.5.fc2.weight 743 768\n",
      "layers.5.fc2.bias 768\n",
      "layers.5.final_layer_norm.weight 768\n",
      "layers.5.final_layer_norm.bias 768\n",
      "layers.6.self_attn.k_proj.weight 644 768\n",
      "layers.6.self_attn.k_proj.bias 768\n",
      "layers.6.self_attn.v_proj.weight 660 768\n",
      "layers.6.self_attn.v_proj.bias 768\n",
      "layers.6.self_attn.q_proj.weight 647 768\n",
      "layers.6.self_attn.q_proj.bias 768\n",
      "layers.6.self_attn.out_proj.weight 659 768\n",
      "layers.6.self_attn.out_proj.bias 768\n",
      "layers.6.self_attn_layer_norm.weight 768\n",
      "layers.6.self_attn_layer_norm.bias 768\n",
      "layers.6.fc1.weight 747 768\n",
      "layers.6.fc1.bias 3072\n",
      "layers.6.fc2.weight 744 768\n",
      "layers.6.fc2.bias 768\n",
      "layers.6.final_layer_norm.weight 768\n",
      "layers.6.final_layer_norm.bias 768\n",
      "layers.7.self_attn.k_proj.weight 643 768\n",
      "layers.7.self_attn.k_proj.bias 768\n",
      "layers.7.self_attn.v_proj.weight 662 768\n",
      "layers.7.self_attn.v_proj.bias 768\n",
      "layers.7.self_attn.q_proj.weight 645 768\n",
      "layers.7.self_attn.q_proj.bias 768\n",
      "layers.7.self_attn.out_proj.weight 662 768\n",
      "layers.7.self_attn.out_proj.bias 768\n",
      "layers.7.self_attn_layer_norm.weight 768\n",
      "layers.7.self_attn_layer_norm.bias 768\n",
      "layers.7.fc1.weight 746 768\n",
      "layers.7.fc1.bias 3072\n",
      "layers.7.fc2.weight 744 768\n",
      "layers.7.fc2.bias 768\n",
      "layers.7.final_layer_norm.weight 768\n",
      "layers.7.final_layer_norm.bias 768\n",
      "layers.8.self_attn.k_proj.weight 637 768\n",
      "layers.8.self_attn.k_proj.bias 768\n",
      "layers.8.self_attn.v_proj.weight 677 768\n",
      "layers.8.self_attn.v_proj.bias 768\n",
      "layers.8.self_attn.q_proj.weight 640 768\n",
      "layers.8.self_attn.q_proj.bias 768\n",
      "layers.8.self_attn.out_proj.weight 680 768\n",
      "layers.8.self_attn.out_proj.bias 768\n",
      "layers.8.self_attn_layer_norm.weight 768\n",
      "layers.8.self_attn_layer_norm.bias 768\n",
      "layers.8.fc1.weight 746 768\n",
      "layers.8.fc1.bias 3072\n",
      "layers.8.fc2.weight 743 768\n",
      "layers.8.fc2.bias 768\n",
      "layers.8.final_layer_norm.weight 768\n",
      "layers.8.final_layer_norm.bias 768\n",
      "layers.9.self_attn.k_proj.weight 638 768\n",
      "layers.9.self_attn.k_proj.bias 768\n",
      "layers.9.self_attn.v_proj.weight 680 768\n",
      "layers.9.self_attn.v_proj.bias 768\n",
      "layers.9.self_attn.q_proj.weight 641 768\n",
      "layers.9.self_attn.q_proj.bias 768\n",
      "layers.9.self_attn.out_proj.weight 684 768\n",
      "layers.9.self_attn.out_proj.bias 768\n",
      "layers.9.self_attn_layer_norm.weight 768\n",
      "layers.9.self_attn_layer_norm.bias 768\n",
      "layers.9.fc1.weight 746 768\n",
      "layers.9.fc1.bias 3072\n",
      "layers.9.fc2.weight 746 768\n",
      "layers.9.fc2.bias 768\n",
      "layers.9.final_layer_norm.weight 768\n",
      "layers.9.final_layer_norm.bias 768\n",
      "layers.10.self_attn.k_proj.weight 646 768\n",
      "layers.10.self_attn.k_proj.bias 768\n",
      "layers.10.self_attn.v_proj.weight 675 768\n",
      "layers.10.self_attn.v_proj.bias 768\n",
      "layers.10.self_attn.q_proj.weight 646 768\n",
      "layers.10.self_attn.q_proj.bias 768\n",
      "layers.10.self_attn.out_proj.weight 688 768\n",
      "layers.10.self_attn.out_proj.bias 768\n",
      "layers.10.self_attn_layer_norm.weight 768\n",
      "layers.10.self_attn_layer_norm.bias 768\n",
      "layers.10.fc1.weight 745 768\n",
      "layers.10.fc1.bias 3072\n",
      "layers.10.fc2.weight 745 768\n",
      "layers.10.fc2.bias 768\n",
      "layers.10.final_layer_norm.weight 768\n",
      "layers.10.final_layer_norm.bias 768\n",
      "layers.11.self_attn.k_proj.weight 652 768\n",
      "layers.11.self_attn.k_proj.bias 768\n",
      "layers.11.self_attn.v_proj.weight 666 768\n",
      "layers.11.self_attn.v_proj.bias 768\n",
      "layers.11.self_attn.q_proj.weight 650 768\n",
      "layers.11.self_attn.q_proj.bias 768\n",
      "layers.11.self_attn.out_proj.weight 684 768\n",
      "layers.11.self_attn.out_proj.bias 768\n",
      "layers.11.self_attn_layer_norm.weight 768\n",
      "layers.11.self_attn_layer_norm.bias 768\n",
      "layers.11.fc1.weight 735 768\n",
      "layers.11.fc1.bias 3072\n",
      "layers.11.fc2.weight 716 768\n",
      "layers.11.fc2.bias 768\n",
      "layers.11.final_layer_norm.weight 768\n",
      "layers.11.final_layer_norm.bias 768\n",
      "bias 50265\n",
      "dense.weight 717 768\n",
      "dense.bias 768\n",
      "layer_norm.weight 768\n",
      "layer_norm.bias 768\n"
     ]
    }
   ],
   "source": [
    "for key, param in roberta_base.named_parameters():\n",
    "    with torch.no_grad():\n",
    "        key = \".\".join(key.split(\".\")[3:])\n",
    "        p_size = min(param.size())\n",
    "        if len(param.size()) < 2:\n",
    "            print(key, p_size)\n",
    "            continue\n",
    "        print(key, get_principle_direction(param, 0.99), p_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec9a0bca-9500-4e4f-9650-23bfc0a02439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On the surface the above results suggest you need most of the directions to account for most of the directions. \n",
    "# It will be useful to see which directions are affected and how later.\n",
    "from models.LoRA import LoRALinearLayer\n",
    "def add_linear_lora(module, rank, init_type=0):\n",
    "    for key, child in module.named_children():\n",
    "        if isinstance(child, torch.nn.Linear):\n",
    "            lora_layer =  LoRALinearLayer(child, rank=rank, init_type=init_type)\n",
    "            setattr(module, key, lora_layer)\n",
    "        else:\n",
    "            add_linear_lora(child, rank, init_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa02e6c0-2f89-40ab-b387-9c77de31b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_linear_lora(roberta_base, rank=10, init_type=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe6c9164-4b29-4ad1-b98f-a50c4f368e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaHubInterface(\n",
       "  (model): RobertaModel(\n",
       "    (encoder): RobertaEncoder(\n",
       "      (sentence_encoder): TransformerEncoder(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "        (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\n",
       "        (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x TransformerEncoderLayerBase(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (v_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (q_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "              (out_proj): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (activation_dropout_module): FairseqDropout()\n",
       "            (fc1): LoRALinear(in_features=768, in_features=3072, rank=$10, init_type=$1)\n",
       "            (fc2): LoRALinear(in_features=3072, in_features=768, rank=$10, init_type=$1)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lm_head): RobertaLMHead(\n",
       "        (dense): LoRALinear(in_features=768, in_features=768, rank=$10, init_type=$1)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (classification_heads): ModuleDict()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c66542b-d1f8-417c-bae4-172a31970431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
